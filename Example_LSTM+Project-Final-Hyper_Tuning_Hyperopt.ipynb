{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = pd.read_csv('example_1.csv', parse_dates=['time'], index_col='time', squeeze = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "1979-01-01    4419\n",
       "1979-02-01    4336\n",
       "1979-03-01    4214\n",
       "1979-04-01    4294\n",
       "1979-05-01    4650\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(data, n_test):\n",
    "    train, test = data[0:-n_test], data[-n_test:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is pd.Series else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform series into train and test sets for supervised learning\n",
    "def prepare_data(series, n_lag, n_seq):\n",
    "    # extract raw values\n",
    "    raw_values = series.values\n",
    "    raw_values = raw_values.reshape(len(raw_values), 1)\n",
    "    # rescale values to -1, 1\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_values = scaler.fit_transform(raw_values)\n",
    "    scaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "    # transform into supervised learning problem X, y\n",
    "    supervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "    supervised_values = supervised.values\n",
    "    \n",
    "    train = supervised_values\n",
    "    return scaler, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_lag = 6\n",
    "n_seq = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(series, n_lag, n_seq):    \n",
    "    \n",
    "    train1, test = train_test_split(series, 18)\n",
    "    scaler, train = prepare_data(train1, n_lag, n_seq)\n",
    "    \n",
    "    val_size = int(train.shape[0]*0.2)\n",
    "    train, val = train[0:-val_size, :], train[-val_size: , :]\n",
    "    # reshape training into [samples, timesteps, features]\n",
    "    trainX, trainy = train[:, 0:n_lag], train[:, n_lag:]\n",
    "    # reshape validation data into [samples, timesteps, features]\n",
    "    valX, valy = val[:, 0:n_lag], val[:, n_lag:]\n",
    "      \n",
    "    trainX = trainX.reshape(trainX.shape[0], trainX.shape[1], 1)\n",
    "    valX = valX.reshape(valX.shape[0], valX.shape[1], 1)\n",
    "    \n",
    "    return trainX, trainy, valX, valy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_lstm(trainX, trainy, valX, valy):    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM({{choice([6, 12, 20, 25])}}, batch_input_shape=(n_batch, trainX.shape[1], 1), stateful=True))\n",
    "    #model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    #model.add(LSTM(64, stateful = True, dropout=0.2, activation = 'relu'))\n",
    "    model.add(Dense(trainy.shape[1]))\n",
    "    model.compile(loss='mean_squared_error', optimizer= 'adam')\n",
    "    # fit network\n",
    "    for i in range({{choice([10, 20, 40])}}):\n",
    "        model.fit(trainX, trainy, epochs= 2, batch_size=n_batch, validation_data = (valX, valy), verbose=2, shuffle=False)\n",
    "        model.reset_states()\n",
    "        \n",
    "    val_loss = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return {'loss': val_loss,'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from matplotlib import pylab\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from datetime import datetime\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import math\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error\n",
      "except:\n",
      "    pass\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from statsmodels.tsa.seasonal import seasonal_decompose\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from stldecompose import decompose, forecast\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from stldecompose.forecast_funcs import naive, drift, mean, seasonal_naive\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'LSTM': hp.choice('LSTM', [6, 12, 20, 25]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'range': hp.choice('range', [10, 20, 40]),\n",
      "    }\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d1eeba3028c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                       \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                                       notebook_name='Example_LSTM+Project-Final-Hyper_Tuning_Hyperopt')\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Evalutation of best performing model:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                      \u001b[0mfull_model_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                                      verbose=verbose)\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mmodel_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_model_string\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mmodel_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hyperopt_model_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[0mtemp_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./temp_model.py'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mwrite_temp_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mget_hyperopt_model_string\u001b[1;34m(model, data, functions, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[0mfunctions_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretrieve_function_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m     \u001b[0mdata_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretrieve_data_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhyperopt_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maug_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mretrieve_data_string\u001b[1;34m(data, verbose)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[0mdata_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[0mfirst_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_string\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[0mindent_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetermine_indent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m     \u001b[0mdata_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_string\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'^\\s*return.*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "X_train, Y_train, X_test, Y_test = create_data(example, n_lag, n_seq)\n",
    "\n",
    "best_run, best_model = optim.minimize(model=fit_lstm,\n",
    "                                      data=create_data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='Example_LSTM+Project-Final-Hyper_Tuning_Hyperopt')\n",
    "\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, Y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forecast_lstm(model, X, n_batch):\n",
    "    X = X.reshape(1, len(X), 1)\n",
    "    forecast = model.predict(X, batch_size=n_batch, verbose=2)\n",
    "    #model.reset_states()\n",
    "    return [x for x in forecast[0, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_forecasts(model, n_batch, points, n_lag, n_seq):\n",
    "    forecasts = list()\n",
    "    X = points[-1][len(points[-1])- n_lag:]\n",
    "    forecast = forecast_lstm(model, X, n_batch)\n",
    "    forecasts.append(forecast)\n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_transform(forecasts, scaler):\n",
    "    inverted = list()\n",
    "    for i in range(len(forecasts)):\n",
    "        forecast = np.array(forecasts[i])\n",
    "        forecast = forecast.reshape(1, len(forecast))\n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0, :]\n",
    "        inverted.append(inv_scale)\n",
    "    return inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_lag = 6\n",
    "n_seq = 18\n",
    "n_batch = 1\n",
    "nb_epoch = 10\n",
    "neurons = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_data = pd.read_csv('LSTM_M3_Monthly.csv', parse_dates=['time'], index_col='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LstmDict(lstm_data):\n",
    "    lstm_dict={}\n",
    "    keys = list(lstm_data.batchID.unique())\n",
    "\n",
    "    for i in keys:\n",
    "    \n",
    "        value=[]\n",
    "        value=lstm_data[lstm_data.batchID == i]\n",
    "        value = value.drop(['batchID'], axis =1).squeeze()\n",
    "        lstm_dict[i]=value\n",
    "    \n",
    "    return lstm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Lstm_errors = {}\n",
    "keys = list(LstmDict(lstm_data).keys())\n",
    "#LstmDict(lstm_data)['N2780']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1835205f550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#log_train1 = log_transform(train1)\n",
    "#data_diff = train1.diff().dropna()from stldecompose import decompose, forecast\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomposition = seasonal_decompose(train1)\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(train1, label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23448c82908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train1, test = train_test_split(LstmDict(lstm_data)['N1413'], 18)\n",
    "#log_train1 = log_transform(train1)\n",
    "#data_diff = train1.diff().dropna()from stldecompose import decompose, forecast\n",
    "from stldecompose import decompose, forecast\n",
    "from stldecompose.forecast_funcs import (naive,\n",
    "                                         drift, \n",
    "                                         mean, \n",
    "                                         seasonal_naive)\n",
    "\n",
    "\n",
    "stl = decompose(train1, period=12)\n",
    "seas = stl.seasonal\n",
    "tr = stl.trend\n",
    "res = stl.resid\n",
    "stl.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8iIiIQiCIORFREIQBEHIy/8PnK3dRvm9bzIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23445888710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = res.ewm(alpha = 0.3).mean()\n",
    "res.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsvXl4ZFd95/05tVdJKm0tdUvq3e72\n2sbubswWDA4YDAmYJQmQTDAhwUkIM/NOJpOQmTdDhmxkm2SYJCQsBpOXkLDjEBtjOwYDXru9tu22\ne3G3uyV1a5dKqr3qvH+cc6tuVd1bi1RSqUvn8zx6SnXr3tKtq1vne37rEVJKDAaDwWCw42n1CRgM\nBoNh/WHEwWAwGAwVGHEwGAwGQwVGHAwGg8FQgREHg8FgMFRgxMFgMBgMFRhxMBgMBkMFRhwMBoPB\nUIERB4PBYDBU4Gv1CSyXTZs2yZ07d7b6NAwGg+GC4vDhw1NSyoFa+12w4rBz504OHTrU6tMwGAyG\nCwohxOl69jNuJYPBYDBUYMTBYDAYDBUYcTAYDAZDBUYcDAaDwVCBEQeDwWAwVGDEwWAwGAwVGHEw\nGAwGQwVGHAztwbkj8NJDrT4Lg6FtMOJgaA/u+2O447dafRYGQ9tgxMHQHqRjkF5q9VkYDG2DEQdD\ne5BJQjbV6rMwGNqGmuIghLhVCDEhhDhi2/YvQogn9M8pIcQTevtOIUTC9trf2445IIR4WghxXAjx\nSSGE0Nv7hBB3CyGO6cfe1fighjYnm4BMotVnYTC0DfVYDl8AbrRvkFK+R0p5tZTyauDrwDdsL5+w\nXpNS/ppt+6eAW4A9+sd6z48C90op9wD36ucGQ2NkkpBNtvosDIa2oaY4SCnvB2acXtOz/58Dvlzt\nPYQQQ0BUSvmglFICXwTeoV++CbhN/36bbbvBUD9ZLQ5StvpMDIa2YKUxh9cC56WUx2zbdgkhHhdC\n/EAI8Vq9bQQ4a9vnrN4GsFlKOQ6gHwdXeE6GjUgmATIPuUyrz8RgaAtWup7D+yi1GsaB7VLKaSHE\nAeBbQogrAOFwbMNTPCHELSjXFNu3b1/G6RraFsullE2AL9DaczEY2oBlWw5CCB/wLuBfrG1SypSU\nclr/fhg4AexFWQpbbYdvBcb07+e128lyP024/U0p5aellAellAcHBmouZGTYKEgJmbj63WQsGQxN\nYSVupTcCR6WUBXeREGJACOHVv+9GBZ5PandRTAjxSh2neD/wbX3Y7cDN+vebbdsNhvrIZZRLCUzG\nksHQJOpJZf0y8CBwiRDirBDil/VL76UyEH0d8JQQ4knga8CvSSmtYPavA58FjqMsijv19k8ANwgh\njgE36OcGQ/1kbYJgMpYMhqZQM+YgpXyfy/YPOGz7Oiq11Wn/Q8CVDtungTfUOg+DwZWMTRCMOBgM\nTcFUSBsufOyWQ8aIg8HQDIw4GC58jOVgMDQdIw6GCx8TczAYmo4RB8OFjz1DyWQrGQxNwYiD4cLH\nLgimzsFgaApGHAwXPnZXUtZYDgZDMzDiYLjwyaxRttLk87AwVns/g6ENMOKwUXjsH+Frv1x7vwuR\n7BplK33tg3DP/1q99zcY1hFGHDYKLz0Ex+9u9VmsDpllZislFxr7O4lZSM41dozBcIFixGGjkE20\nb4HYciyHc0fgT3fA1LHa+1pkEsUGfwZDm2PEYaOQSUIuBflcq8+k+ViWgz9SvwDOvaSa9c2faezv\nmFRZwwbBiMNGwcriaccisUwCPD4IdNSfrWRZAPWKiZRmnWrDhsKIw0bBGgTb0bWUTYIvrH7qrXOw\nRLJeN1Gj+xsMFzhGHDYK1oy6HQe3TAL8IfAF65/ZZxq0pKz9jeVg2CAYcdgoWBZDO7qVLMvBH2pg\nsLfcSg2KSTuKq8HggBGHjcKGsBzCy7AEGnUrGcvBsDEw4rBRaPeYgz+s3UqNikODlkYuDbls4+do\nMFxgGHHYKLS75eALK4FYLcshY/o3GTYWRhw2Cu0ccyi4lZYRc2h0f2hP68tgKKOmOAghbhVCTAgh\njti2/b4QYlQI8YT+eavttd8VQhwXQjwvhHizbfuNettxIcRHbdt3CSEeFkIcE0L8ixAi0MwPaADy\neVUAB+1pOWS15eALrV6A2S4i7XgNDYYy6rEcvgDc6LD9r6SUV+ufOwCEEJcD7wWu0Mf8nRDCK4Tw\nAn8LvAW4HHif3hfgT/V77QFmgTbtDtdCSga2Npz1ZpLKcvCHllHn0KCYNHKMwXABU1McpJT3AzN1\nvt9NwD9LKVNSyheB48C1+ue4lPKklDIN/DNwkxBCAD8JfE0ffxvwjgY/g6EW7T7rLRTBhZZRIb0c\ncWjDa9hqvvVhOPT5Vp+FwcZKYg4fEUI8pd1OvXrbCGBvVnNWb3Pb3g/MSSmzZdsNzWStWlq3CnvM\noeFspTrFIWssh1Xl+Tvh9I9bfRYGG8sVh08BFwFXA+PAX+rtwmFfuYztjgghbhFCHBJCHJqcnGzs\njDcy7e4SKRTBhVVsRbreQkUaDki3+TVsJVJCasFc13XGssRBSnleSpmTUuaBz6DcRqBm/ttsu24F\nxqpsnwJ6hBC+su1uf/fTUsqDUsqDAwMDyzn1jUmJW6nNvoBSastB1zlAfQN+oe6j3lRW41ZaNbJJ\nyGfNdV1nLEschBBDtqfvBKxMptuB9wohgkKIXcAe4BHgUWCPzkwKoILWt0spJXAf8DP6+JuBby/n\nnAxVyLSxOOQyIHPFCmmoUxwadCsZy2H1sBZdMtd1XeGrtYMQ4svA64FNQoizwMeA1wshrka5gE4B\nvwogpXxGCPEV4FkgC/yGlDKn3+cjwF2AF7hVSvmM/hO/A/yzEOIPgceBzzXt0xkUdn95uxVwWZ/H\n6q0ESgzDNY5rNCDd7kH9VpKKqUdzXdcVNcVBSvk+h82uA7iU8o+AP3LYfgdwh8P2kxTdUobVoJ0t\nB+uzWQFpqE8AG7Yc4uDxQz7Tftew1aTm1aO5rusKUyG9EWjnTBu75VAQhxq1DtbCPdBAQDoJkX79\nu5nhNhXjVlqXGHHYCFiz60BX+30BnSyHWp8xl1ZLhApPAwHpOISiILztdw1bjeVWSi+19jwMJRhx\n2AhYs+RIb/vVOTjFHGp9RksQQj0qSyaXqePv6M6v/ogRh2aTMpbDesSIw0bAml2He9vvC1hiOdSZ\nrWRdg0hf6fOqx8SLtRTGrdRcLMshm1B9wAzrAiMOGwFrdh3ua0Nx0AO1P1Ksc6hVJV0Qh/7S51WP\nsSyHBpr7GerDijlA+1m2FzBGHDYCdsuh7VJZ9WfzhdTgbd/mRsYmllB/dpPlVmq3a9hqUjZxMMK7\nbjDisBHIJlQaZqCj/b581ufx27OVVsFyyFriEG6/a9hqSsTBuOzWC0YcNgLZVPsGU+2WQ73ZStYA\nFOktfV71GGu1uTa8hq3GijmAuba1eO5f4U93weQLq/6njDhsBDIJ7XZpQ3+53XLw11nnYAmK5Vaq\np5Nrxm45mNltU0kay6Fu4tOQmIFAZNX/lBGHjUDWWgwnorqWtlNGSInlYMUc6rUcGglI67bgxq3U\nfFIxVT8CRhxqkZhTj6GeVf9TRhw2ApZLpJH2EhcKhVTW8DKyleoMSFsV1f6IdiuZAayppBagc1D9\nbq5tdZJz4PGp+OEqY8RhI2C3HKC9lgrNJtSs0+sHIfRqcHUWwdVrOVhuKp+xHFaFVAw6N6vfzbWt\nTmJOWQ3CaSmc5mLEYSNgjzlAe83OMomi6IGyHmqKQ3nMocb1sNdSmIB080kuGHGol+QchFffpQRG\nHDYG2aQWh0jxebtgxQIsfOFlVEjX2D9rq8I2Aenmks9BOgZdljiYa1sVy3JYA4w4bAQKK6W1oeVg\nLRFq4a9jHelMXPltg9Hi86r72/s3hevvx2SoTXpRPRrLoT6M5WBoKgXLQQ+i7RRzqLAcQnVkKyVs\n7TZE/ZaGVSsC7SWwrcRKY+00lkNdJOeN5WBoIoW+QJY4tNEX0BI+C1+ojjoHHYMRoj43UYk4hEu3\nGVaGVQDXsUm3UDfXtSoJYzkYmok1GNbbXuJCwnKZWdSTTWQ/xldHYWDWWA6rhtU6IxhV1zZtrqsr\nUhrLwdBkCpZDGw5sFZZDPdlK8eK18Efqr4vwGcuh6ViWQzBqgv21SMVA5taP5SCEuFUIMSGEOGLb\n9udCiKNCiKeEEN8UQvTo7TuFEAkhxBP65+9txxwQQjwthDguhPikECpRVwjRJ4S4WwhxTD/2rsYH\n3dBky1NZ28lyiJdaDvVmK1nHNOpW8hlxaCpJvX50KFqf1beRSa5ddTTUZzl8AbixbNvdwJVSyquA\nF4Dftb12Qkp5tf75Ndv2TwG3AHv0j/WeHwXulVLuAe7Vz9cPUsLpB1t9Fssnl1XZNe1qOVhWkYUv\nWIclYDvGX0/RXKK4bzvGbVpJwXLoAn+Hua7VsFpnrBfLQUp5PzBTtu17UsqsfvoQsLXaewghhoCo\nlPJBKaUEvgi8Q798E3Cb/v022/b1wYv3w+dvhLHHW30my8Opa2k7xRwqUlnDtQPSdmujnnYYhZhD\npD2rzFtJSczBWA5VWYeWQy0+CNxpe75LCPG4EOIHQojX6m0jwFnbPmf1NoDNUspxAP042IRzah5L\nk+pxYby157FcCgVcdn95Gw1sy05lbSAgXYg5GMuh6aRiKksp0GGqz2tRaLrXvSZ/zreSg4UQ/wPI\nAl/Sm8aB7VLKaSHEAeBbQogrAKdGIHIZf+8WlGuK7du3L++kG8Uq0knMVN9vvWIf2Lx+VfzVTgNb\nueXgq7MIzh6QTszW2N9uOZiYQ1NJLiiXkpVWHJ9u9RmtX5LrzK3khhDiZuCngV/QriKklCkp5bT+\n/TBwAtiLshTsrqetwJj+/bx2O1nupwm3vyml/LSU8qCU8uDAwMByT70xUlocLtSb1m45gF7mso0t\nh3piCPYMp3pTX4VHiWs7xm1aSSpWrFQ3bqXqrGG7blimOAghbgR+B3i7lDJu2z4ghGrMLoTYjQo8\nn9TuopgQ4pU6S+n9wLf1YbcDN+vfb7ZtXx+kL3BxsFsO1mO7DGy5jErt85VlK+UzqmePG/Zmff46\nspuySbW/Nbu13sOwclILNnEw7dCrkpxTHYiDXWvy5+pJZf0y8CBwiRDirBDil4G/AbqAu8tSVq8D\nnhJCPAl8Dfg1KaXlj/l14LPAcZRFYcUpPgHcIIQ4Btygn68frGyK+AXqVrIHpEHPztrEcih0Sy2r\nc4Dqg3dJQLqeVNZ46fWr9f6G+knOqzRWMHUOtUjMqXjDGrTrhjpiDlLK9zls/pzLvl8Hvu7y2iHg\nSoft08Abap1HyyhYDheoONjTMKG9voCZMuGD4uCdTUGws/KYXEan9kaKx9Z0KyWL+3v94PG3zzVs\nNalYcaEfE5Cuzho23QNTIV2b1AUekC5YDraZcrvEHOwpphaW5eCWsVQhlnpAklXyIzLxsriGGcSa\nht2tFNBupWr/i43MGrbrBiMOtWmXmIM1uPnaKOhXWCK0bD0HcK91sFc7F46V1WsjsmWFdu1kfbWa\nVKzoQ/eHQeYhl27tOa1XjOWwzmiXbKVGsnMuFCzroHw9B3D/jPZV3eyP1WojMvHKQrt2uYatJrlg\nizmYTLCqGMthnZHWAenELOTzrT2X5VAxU26jgc3RcqhRBe50Pezb3f5OieVgsmqaQjYFuVSp5QDt\nc382G2M5rDMsy0Hmi0UoFxJOlkOtCuILBSfLoZY4lB9TTyO97DLaghtqU+irpCt+C5aDubYVSGks\nh3VHerF4016IGUvlM+V6snMuFJwsh1otQpZlOSQqM6La5Rq2kkJfpXLLwVhlFaSX1rRdNxhxqE1q\nEXp0q44LMWOpwnJoo0wbaxApsRzqzVayFcHZtzseY0tltY4xA9jKsZYItdc5gFnwx4k1broHRhyq\nk89DZqkoDhdiUNpqFWEVzvjbyHIobw0CdWQrWQHpMsuhVkC63Dppl2vYSuztusEEpKuxxu26wYhD\ndaw01p4d6vFCFIdM+UppYRUEXM/B9Wwavv4rMPlC9f3KXURQu0I6U95rqp6Yg0NAul3iNq3E3q4b\nTEC6GsZyWGdY4tBricOF6FZyCKZa29cr08fh6a/Cye9X36/cZQa2z+cWcyizHHw1/NxSmlTW1aLC\ncuhQj8ZyqMRYDusMK1Opa0i1TGgHy+FCWNMhptfOqJUdVm4FwApSWd2ym1KVf6Od4jatpBBzsLKV\njOXgirEc1hlWjUOgEyL9F6Y4uFkO63l2VhCH+er7ZROqS6XXX9xmiYNrtlJ5EVyN61FuaVi/mzYP\nKyel/78VMQcjDhWs8UI/YMShOpblEOyESF/tRWHWI5lk0Q8PtoBtm1gO9kEblFAIT5U6h6RemyGg\nntdyQzkFvU2bh+aQioE3WLw/L4SJS6tIzgGiGJ9ZA4w4VMOKOTRqOZx5FGZOrt55NYLTGsuwvmdn\nsXPqMVFLHOKlLjNQWVm+Ks0FMwnwhclLeOD4FLJWzKGwHkaZW6naMYb6sLfOAJvVV8e9GZ+BY/es\nznmtR6x23Z61G7KNOFSjYDl0KcuhXnH42gfh+3+6eufVCE4rpVnb1yuWONR0KzlYDqBmotV6K/nD\nPHRymp//7MP84IReQMV1f4eMqAtBYC8E7E33QA18vrBKH6/F4/8IX/qZ4ne03Vnj1hlgxKE69phD\nuK++bKV8DhZG10/BXIXlUEejuVazoFeQrSUOmYSzOPjD1buy+iOcnVOf/4fHpnSAuXYA++c/8xB/\ncudzxjfeLOztui3qzQSLzwCymA7b7qxx6wyoY7GfDU1JzKFfDfj5fHXTbmlKlblbaXqtptxyaMR0\nbxUFy6GGWymbrHQrgbIcqlVI+8NMxpR4/Pj4lC4MdHER6feZSXt54MQ0yUwOdhrfeFMotxyg/kww\nSxTWy/dstTGWwzojvaiCl/6IcivJfDHDwo2YNetdJzMaN8thvYpDPgeL59Xvy7UcfLUsh1BBHI6e\ni5Hz1ohRAI+NqddfmkkYt1KzSC5UZt8E6ux4a4nCevmerTYtsByMOFQjtahcSkIoywFqu5asWe96\nmdFcaDGHpUlleUX61Re/WiW3m+VQrUVIJg7+CJOxFD6PaikSl1WW/dTv88ioepxaTJHEqsI2lsOK\ncLQc6nQrWaKwUdxK69VyEELcKoSYEEIcsW3rE0LcLYQ4ph979XYhhPikEOK4EOIpIcR+2zE36/2P\nCSFutm0/IIR4Wh/zSSHWaAXtWqRjShzAJg41gtKWv3y93LTlA+h6jzlYaawDl1HTp+xqOYSqWwL+\nMBOxJNds76Er6GM+66sZkH7w9BLRkPLCnkt4Sl4zLJPUvEPMoV7LYQO5lVrQrhvqtxy+ANxYtu2j\nwL1Syj3Avfo5wFuAPfrnFuBToMQE+BjwCuBa4GOWoOh9brEdV/63WkNqsbhIfbhPPTZiObS6SErK\nygF0vcccrOs3cIl6rOZaKm+lbVFNHLLJguWwpTvMK3b3M52qkq2kRfRcwsO7D2wFYNRKkDGWw/KR\ncmWWgyUKG0EcMnHIZ9an5SClvB8oHxVvAm7Tv98GvMO2/YtS8RDQI4QYAt4M3C2lnJFSzgJ3Azfq\n16JSygellBL4ou29Wkt60WY5WOJQw3KwYg4y1/rBI5cB5Nq1z0jO144T1MKyvAYvK76nG26prP5w\n9QppX4iJWIrBriCvubif+YyXVMIlfVIPVCkC/MIrVHfeMzFZ8pphGaSXVAwv5GQ5NOJW2gDikFj7\n1hmwspjDZinlOIB+HNTbR4Aztv3O6m3Vtp912F6BEOIWIcQhIcShycnJFZx6ndgth3rdStbMF1of\nLLNcR/YB1OsHj291hOtbH4Zv/OrK3iN2TiUB9F+snlfLWHK1HKpnK2W8IeLpHANdQV5z8SYSBEnE\nXfLl9UC1e3gTFw100hX08dKCEYcVU950z6LetTI2klspufZN92B1AtJO8QK5jO2VG6X8tJTyoJTy\n4MDAwApOsU7SixDQN2+wSw2qteoXFsaLv7f6xrVmz+UDqD+yOu0zZk/B3OmVvUdsHDoGi2Jc03KI\nVG6vmq0UJy5V64zBriB7BjuRvjDppLPlkErGyUnBq/cMIYRge3+Ek/P5wnsZlkl5u24Lf7j2Yj+W\nS8r+Pu2M9R24gCyH89olhH6c0NvPAtts+20Fxmps3+qwvfWkYkXLwcpYqmk5jEO3Xhyo1Teuk+UA\neqnQVRjYErMr7z8VOwddW4opjrViDv5Gs5WSLOWVOAx0BRFC0B3tgkwC6RAjGpucIUmA6y5RhvH2\nvggnZrOF9zIsk6SbONThVrKWzITWT8DWgha064aVicPtgJVxdDPwbdv29+uspVcC89rtdBfwJiFE\nrw5Evwm4S78WE0K8Umcpvd/2Xq3FHnMALQ5VLIdMUlkWA3vV81aLg6vlUMUnvxKaIg7jEB0ufhHc\n+ivlMmqA8LllKzlYDvkc5FIs5lTW0WCXui6bensIyBTPn68caM7PzJIkyP7tKndie1+E03NppDdo\nLIeVYH03KmIOdbiV7ILQ6u/YWtCCdt1Qfyrrl4EHgUuEEGeFEL8MfAK4QQhxDLhBPwe4AzgJHAc+\nA3wYQEo5A/wB8Kj++bjeBvDrwGf1MSeAO1f+0ZqAPeYAtVtoLOp4wyadadPqWY1lOTiKQ5MHtmxK\nvWc2ubI1gGPjynIIdAHC3XIotLVQn+3T95/gD7/zrNrmC6nPXm4J6GPms0ocBrpUvcKW/l7CpPnx\n8VKrUErJzNw8+EIEfOqrsq0vQjqbVw37TMxh+bi6lTpUZk4uU/tYaP13bC1okeVQV/sMKeX7XF56\ng8O+EvgNl/e5FbjVYfsh4Mp6zmXNyGXUcpoBW8As0geTz7sfY8UbLMuh1QHpwmI4DuLQ7JiDfYaf\nmFWVro2STSm3XdeQalESirqLQ9kqcN89co6xuST/709frrbJvPof+gLFY/RgPpfx4fcKesJqHYiu\nriiIDA8em+CXf2JXYfcXp5bIpxP4oh2FbTv61efKekMEjOWwfKoFpEH9r+zrdNhJbjBxKLTrXru1\nHMBUSLtTuHnL3UpVYg5WAde6sxzKYw6rMOu1u5OW61qyMr26tqjHUE8Vy6F0EZ7x+STnY0kyuXxR\nDMsFsNAnycemziAeXSFtvceTp86RzRUrsu9/YZIQKUKRojhs71PikBJVOr8aapOs4laC6tfWshw6\nBlr/HVsLEnPqOq1hu24w4uCOfS0HC2vBH7eWDgVxWGcxhwrLoUrAdrk0VRyG1WOo2z2V1RZPyeby\nnF9IIiWcm7dVhJeLg/7M0ylPwaWk3kMNSLlUnCfPFsXo/mNT9PhzBEPFe2C4J4xHQEIGjDisBGtQ\nt3+/oL61MqzvVXRkY4hDcm5NV4CzMOLghr0jq0WkX3dcdZnNxsbVwBTpU77TVt+4bpbDaqyB3BRx\n0OJasBy6q7iViplYE7EUeR1eGJ1LuFeB6wFnIull0C4OerYaIs0Dx6cASGVzPHhimsFQvkRc/V4P\nwz1hlmTABKRXQmpBuWw93tLtdVkO+nvVvbX1E7C1oAWtM8CIgzsFy8Eec6jRfG9hXPnLhVBmYKtv\nXDfLwQrYNpOmisOQegxXcysVl+8cmyt+lrE5W7uQ8owlPeBMJESp5aD3v3LQz49PKHE4fGqWRCZH\nTyBXUUuxvS/CQtZvLIeVkFooiTfk85J8XtZnOSTLLIdWt6lZbVrQdA+MOLjjFHOo1V8pdq44sAW7\nWh+QdrUcViGVtVni4A0UW5WEut1TWW2fbWy++FlGZ22WQ7kA6gHnfNLDQFdlS5Frt4Z57PQciXSO\nHxybxO8VdHrSFdleO/ojulmfsRyWTdkSoe/61AP82V3P17eOdMGtNKQSD9J1rBx3IWMsh3WGY8yh\nRguN2Ji6YUGJQ6vdStWylZo9sCXnVNsLb2BlMYeuLcryghoB6eJnG9eWQ0fAy9i8XRzKLQd1TFIG\nymIOav/9wyHSuTyHTs9w/wtTHNjRiyebqrActvUpccivJGV3o2NrupfLS54Zm+fe587Xt95IKqYs\nessP3+rv2WpjLId1hmPMQc9onVpoSFlmOawDt1I1y6HpqayzajAP967McrCuH6j3yyw557zbPtv4\nfJKuoI+LBzsZnUu6r1mhnycIlMUc1IB02SYfPo/gW4+P8dz4AtftHdDrP5SK6/a+CAkZJGfEYfnY\nlgidWkyRyUmOTSwS09XrNd1KoWixRqLdxcFYDusMx5hDlc6syXl1Q3etM8tBeCrzxX1aHKotpNMo\niVklDOG+5a+fvVAuDlVaaNiK4EbnEgz3hBnu0fEH12wlNeAkZNAx5hAmwzXbe/jm46oP5HV7Bhw7\nv27vi5AggDTisHxsloM9ZnRkMq1+qZXKGowWYxat/p6tJpmEqrcylsM6winmEIyq5ntO4lCRox9d\nBzEHvURo+dpJhYBtE62Hgjj0uscJamG3vKA+cfCFGZ9PMNQTYrgnzOhsAunTA79LKmul5VD0c7/6\nok3kJWzqDHD5li7d4rtUHHb0dZAgiGc1mhduFGwxh3FbzOjxMe0KrBVzCHbZxKGNM5Za1K4bjDi4\nk14Ej1+1f7YQwr2FhrWOQ1Tn6AejrZ/RZJOV8QZYnTWQS8RhGW6lVEytvGeJKxRnS061Dll7zCHJ\nULeyHBKZHAu6PUZF0F27opIE2NTpIA7ZJK+5eBMAr90zgCefLn1d0x3xgy+EL99k62sjYXMrWZbD\n9r4Ij47q/1m1e7PgVtoAlkOL2nWDEQd3yvsqWbhVSZdbDsGoGuxaOXhkks6N6QqDYZUvYD4PD/9D\nMfZSi8SsuoGXKw6F6+dgOThZIlZwmQDTS2mGu0OM9KjPdc5KXqnIVlLPQ6EIIb8tv95XFMtrtvdw\nw+Wbed+12yuqsO0EI/reMNZD4+Sy6toWxCFJJODl+ksGeFSv1V0zIB3cIDEHYzmsQ+xrOdhx68xq\nrWBmjzmAEohWkXVpae2rw3I49xTc+dvw/B31/a3EnLYcepYpDrrGIVqnWymbAOFlPKZaNw/3hAvi\nMLqk894rspXipEWQTVGHAL1+3e/18Jn3H+TaXX0266RSHDo6jDgsm0LTvWLMYbgnzIGdfSxmIO8J\nVE9PrXArtbE4GMthHWJfy8GRlg1hAAAgAElEQVROpNc54Bo7p9TdGkjWw42bSVbk6AP1uZXiqhiM\nxQn3fSzyOTWAW26lTLzxOgpHy8FyKznFHFSg2PJXq5iD+qzFNZ4rLYckwdJ4A7gvnZpxyfYCOjuV\ncOVSbZ5jvxpY34lCzCHBUHeIgztUW/SMp0bfqgq30gUQc/juf4dTP278uLKFfuLpLFOLKce1R5qN\nEQc3ytdysHB1K40X4w1QLPBpZVA6W8zcyecl6ax2cbmletqJ69m/JRLVSM4DsigOUH15TycKlpct\n5lCwHJxiDuqzWQVww91h+joChPwezizohWAqAtJJkvhLM5VAtXDwOrTDKGREVYpDd1SnYc4uM/i+\nkSlr1z02n2RYx4yGukMkqLJWRi6j/vfBqMrC84XXvzhkU/DQ38Jztzd+bKFdt/pe3Xd0koN/eA/P\nja/+pNOIgxtVYw4zlSX71joEFuvFctAD21/fe4yf+uQP1YzDKjSqFnOwBHCpjrW6LTeSXRwadS3F\nzik3nr2Fsz+skgLcspVsrTO2dIcQQqiMpfmMOq5MHGQmzlI+wEBnsPL9nGo/qohDb7cSrnPTK1zc\naCNia9edyuaYjKUY1i7B/Tt6ieWqtCYpHBstvMe6dyst6QlWPd+lcgoL/aj7bXROieZIr0MssckY\ncXDDzXII96nme+UDli1Hf3oxRcKj2zy38sa1WQ7PjM5zbGKR09Nx98Z0dgriUIflYJ/dLFscysQV\ndHaYS5V0Rn228fkEmzoDhQDzSE+Ys1atQ5mbKJdaIi4DDEYdxMHnUDXutlgSavU4gKkZIw4NY2vX\nfX5exYWGtEvwwPZeYrkAibhLIkT5CnIXhDhMlj42QmJOp9Cr+3t0NkFX0Ed32GWtiyZixMGN1GLl\nQiTg3EIjn4PF8wVx+Nl/eJC/e0D76t06uK4FmWIq66ieYT/y4kx9LQpaYTmUiwO491fSabpjOo3V\nYrhbWxP+UIUlkE4ukSBY6VYC3VKkPEZhBaQrFy7q61UzuZm5Fv5/1yv5PIwedn/dNvu37ksrmeDg\nzl4SBFhcdHEVJUuD2ReEOFiu2XomWuUkS6ujR+eSBStrtTHi4EY65h5zgNKMpaVJZU10bWF8PsHJ\nySUeGdctH1puOagbyXK/PPziTH0xByvo3og4hHpsVeQNVknHxkqD0RZubbsziWIBXHdxZj/cE2Yy\nlkL6KsUhl0qQkIHC2tElOLUxL6SyVu7vCyrLcHbeiEMFx++Bz/yku0BYE6ZglPF5dc2t/+FlQ1FS\nIkhiqYblYLmVQuugnqgWSw1MtMpJzEG4uJbD6FxiTVxKsAJxEEJcIoR4wvazIIT4f4QQvy+EGLVt\nf6vtmN8VQhwXQjwvhHizbfuNettxIcRHV/qhVoyUVWIODv2VCmmYwzx2Ws1yn7FebmVAWlsOi6ks\nC8ksAI+cmm4w5lBPQHqFbiWrL1XUSRxc3Eq6rcVY2UzK+uJkReViPPl0nCQBF8vBYQGkKqms1jVc\niK3zYGgrmH1RPZ55xPl1W8yhkG2mrT+/10Mg1EEm6ZIFVpbptC6KTWthWQ7x6cbrnsoth9l4IStv\ntVm2OEgpn5dSXi2lvBo4AMSBb+qX/8p6TUp5B4AQ4nLgvcAVwI3A3wkhvEIIL/C3wFuAy4H36X1b\nRzapLAFHy8Ghv5KtAO7QaaUKSzKIRKwLy8HqWnrN9h7OzCQYt753Vd1KWt0y8dotkQtupR51zTy+\nxsQhMQu5dBXLwakILkHGE2QxlS35sli/p0Swos5BZpQ4VKSyghrsXXoxVSskXFpc5wNTK1gYVY9u\nlkNyQd0j/jCjcwn6OgKEA8WixI7OLsgmiKezzsdCaUC61W1qamFNsGS+cXdrorgKXCyZYSGZZaRn\nGeuzL4NmuZXeAJyQUp6uss9NwD9LKVNSyheB48C1+ue4lPKklDIN/LPet3UUOrJWiznYLIdCGuYw\nj52eZXtfBImHjK+ztWl22nKw/LrvvGYEgEfOxouvuxGfVhk/UNscTsyqTCOvXweRG6ySdkpjtXBz\nK2WTaqlOKIk5WL7rJP4Ky8iTTZASIedgni/kkMpa23LIp+PEkg5dYzcyC9qSHn3M+XWriE0IxudK\n3YIA3dFuwiR58ozD/73crRTsWv+prPZ08EZdS7Z23WNz6n5c926lMt4LfNn2/CNCiKeEELcKIbSf\ngRHgjG2fs3qb2/bWYVU1O1kOTs33YudAeEgE+nhmbIGfumqI7rCfuAi3znLI51U3R1+4cFNdf8kg\nXSEfD52Oqc/glksupRK//ovV81quJauvkkWj4lC+drQdK1upPHU4k2AprwZ5u1tJpbRCIu+vED9v\nLoXwhxHljQjBJSDt3j6j2Mk1xUszpjtrCZabdeaE831gtb+ACrcgQH9PN2HSPPaS07EuAen1vBrc\n0grEwdaue6wQvF/nbiULIUQAeDvwVb3pU8BFwNXAOPCX1q4Oh8sq253+1i1CiENCiEOTk8sI7tSL\n01oOxZPQzffs4jAGnZt5amyRbF5ycEcvVwxHmcu3sEAnp10qfpXu6fUIhrpDvHxnHw+/OF1s2+1E\nekkdP3CJel6P5WAv729YHMrWjrYT6lYuJ4dq58WcarBndysFfV4GOoPqtbLP58sn8QRcTHKngHQ2\nWVzAqByd3hoWac4YcShlYQwiqoEhY49Xvp60Nd2bTzBcZjkEw51ERJrDpx3uoeSC+n9YSQLBLuUC\nXkkTyekTxQnKarA0BR2D+vcGxq1sSlm/+rt1tiAOF45b6S3AY1LK8wBSyvNSypyUMg98BuU2AmUR\nbLMdtxUYq7K9Ainlp6WUB6WUBwcGBppw6i44rQJnJ9JfFpA+p+MN6ma+ZrsSh5lskHyr/KG21g+j\ncwm2REP4vB6u3dXHyckl8j6HAKyFJXwDl6rHVReHsqaFdtz6K2WTzGe9eD2iIvtouCdMrFwc8nmC\nMoUv6CYODtdDZ0RVtDwHEALpjxAylkMpUiqx33ujeu7kWkrFIBQllswQS2YZKk/NDHQQJM1jp6bV\nutLlx1ouJVh5semZR+HvXwt3/s7yjq+H+JRtotVAOmtZ073R2QR+r3COma0CzRCH92FzKQkh7FHF\ndwJH9O+3A+8VQgSFELuAPcAjwKPAHiHELm2FvFfv2zqqxRxABaVLYg7jhXjD7oEO+joCXD4cZSEf\nJrXYovYKtpbWqrGZGkCv3aUC6kkqs3kKFMRhr3qsKQ5zDm6lBj53bEwJrs/hpnfrr5RJMJf2srkr\niNdTOniP9ISZz3hLxUH/7g93OJ+DY0A64exS0ghfiG5f1oiDHWvRq8FLlVvSURzmSzKVKvL29TVP\nJZc4OVWW0mrFKyxW0pn1/DPwpZ9Rqw1aGVarwdI0bNoLiPra0VjYswBRbqUt3SE8HidnS/NZkTgI\nISLADcA3bJv/TAjxtBDiKeB64L8ASCmfAb4CPAt8F/gNbWFkgY8AdwHPAV/R+7aOajEH0OJgdyuN\nI7u2cPil2ULzsCuGu4kRJhtvUR68zXKwF4rtG+km7PeymA+4p7JaVlF0RAWa1yLm4JSpBM79lXIZ\nkDlm0h7HgqCR3jCzaS/SFnPIpNQAHgy5/E8dA9LVxQF/hE3BnKo6Nyjs3YmH98OYi+UQjBZ86OVu\nJSvYH8bBtWRbJAiwiUODFvrMi/CP71T/34veUDzvZpNNKzHs3KwmQI24lcoth7lEIeFiLViROEgp\n41LKfinlvG3bL0op90kpr5JSvl1KOW577Y+klBdJKS+RUt5p236HlHKvfu2PVnJOTaFazAFK23Zn\nkpCYYcbbz1w8wwEtDrs3dRAXkda17Naz4Lw3yLn5YtDP7/VwYEcvcxlvFctBf7ZIP3TUuKGlLIhD\nJpcnm8srcUjHnNd+dsKpdYaFk+Wgz3sy5a10SaAGm3jeh7R9PqtYLdxRxXLIZ0vPOVtLHML0+rMm\n5mCnsOjVCIwcUP/b8oE3qWb/VqKEm+WwOZzn0KkycXB1KzUgDgvj8MWb1P/6F78F216h7vHyFu/N\nwJpEdvRDx0Bj4lDWrttqbb5WmAppJ2wxhxenlrjxr+8vHQCsgLSUsKj85ScS6ia1xMHn9RDo6MWf\nrXOxnGajZ80LOS/pXL4kw+HaXX3MZXyF2XQF1g0dqeOGTi9BPgPhXj74hUf58Jcea7wQbqGKOIQd\nxEEL32TCUznrRA02SQIlbqJZ3eYi0uHiKnRqY55JOLc8tx0T9ec4O5sgV+4b36hYaazRIRjZr363\nu5akLMQcxucTeASuLdQPDAU5XJ6xpFeQe+DEFP/wgxNIawJXr1spPqMshvg0/IevKfeX1U15NawH\ny43UMQAdm5Ydc8jk8pxfSLLViEOLSRXF4fDpWY6ei/Glh18qvh7pLzbf01+Gp+YjdIf97N5UtDY6\no72EZAqZTa/l2Su0y2gqqf7F9hnHtbv6SEo/cbcCrvi0ytIJdWtxcGhRbqEF4FQ8wA+PTfGj41Pk\ngj0lr1Ull4WlCec0VnBeDU4P4Et5n+NMargnTIoAnlyqkOI4t6DEoaszWrE/4NxSJJNw7KtUPCZC\nlydNNi8LbSA2PIXMsyHYsk+lTNtdS9mkmkwEo4zNJdmsEyVK0Nf8qi0BTk4uMbNU/P7kEvM8PJ7l\n5z/zMH9y51EeHdeFcvWIQ2oRvvSzMHMS3vdlZdkAdOvM+dUQB2tiFdmkxWF5lsO5+SR5uXY1DmDE\nwZl0TGWpeH2Mzqov/dcOnyWT06Xv9hYa+svw0FSA/dt7SoJFPb1qv7GJVUy7dUNbDhMJdT72QrGr\nt/WQEiGSCZfK5/iMcud4vLVvaC0AdxxXJnk8neNMMlTyWlWWJlXlqJvlYLkQHNxKSRmoKKAC2Nob\nJiV1oZu2HhZiavDoirqJg0NLkYzLSnqFY8JEhBq4XjJxB8WCLbnAH4bBy0srpW2tM1zdJNpyuHJA\n/Q8fOz1LNpfn1h+9yOL8DC/MwX96wx4GuoJ8/tB06fu6ISV89WaVWvuzn4dd1xVfi66mOFhupU16\norUcy6G7UMhq3EqtxtZXyQqaTS2muO+o7rRqr5LW4vDIdJCDO/tK3mZQp9seP7NKwa5q6EHuXFyJ\ngz2QFfJ7CUc6yFVzK1mfsWNAmcZuPWH07Ob+MxnevX8rAM/M6tuqHnGIlS2vWo4voAZue0Baf7Yk\nAccvS3fYT86rXRVaHBZ1D6Rol4tbyamNeba25RBCi4OJOygWxkqtwJH9akC2itQK7bq7K5omFtDX\n/KIeDz6P4F8OneFtf/NjPv6dZ+gUCd527aX85g17uflVO7j3pL7utWIO8RnVEPC634JLf6r0tYJb\n6WyDH7YOLLdSRItDck4FqeshOa+SYrz+wiT1gglIty22tRxG5xLsG+lmsCvIVw7pQm572+7YODlv\nkAU62L+9t+RttgyowpfT4+fX7NQLaMthfAk6Al6iYV/Jy9FoFJFLsphy6F9TLg75rPvKbloA4t4u\n/vtbL2VzNMjhidLXqmLVOJQ13ZtYSBZz3Mub7+nPlsTZchBCEIp0luwbX1Izy0CoSkAaSjOW6og5\n+PNJfB5hxMEiNla6IuLwfvW/mzmpnutBXAY6GZtPOg922nIIyhRXDEe5+9nzzMXTfOa9l+ElT0+v\nujd/4RU78PiDZESgtuWwpG9Kq97ATrALgt2rZDlMKRdtuFdZD+C8kqQTtqZ7xnJYL5RZDtv7Irz7\nwFb+/egE5xeSxYBrfAYWxlnwDeD1eHjZtu6Stwl2qn/s+LkWiIOeXZ+NSYZ7KltGqBYFKR5zqkKN\nz5SKA7iaw/Mz6kt33VV76e8McmBHLw+MaSujLnGw+ag1z44t8OpP/Dtfe0zP5Mqb7+nPlvME6etw\nqF4GOiJaBLKl4uBqCRRiDrZaB9tKes7HhBEZ1ULZiINmYbxU6C2/vuVa0uIwLyOks/mqlgOZBP/l\nhr38tzdfwj2/+Tpu2K236wyl3o4AP3tgG/P5MPFa9UTWWuhWpXI50WGYH6316RonPoUM9/HBLx7m\n0KSeoNUbd0jMlWQq2Re1WguMODiRXoRAF1LKQv/0nzu4jbxUsYdSy+Ec52QPlw9FiQRKZ+fWTTw5\ntYxFPlaKHuTOLErHdM+Bvh5CpFUrjXISMxDRAmjNdlxu6MeOqhnhe6+7CoD923t5fg6k8NRvOQhP\nUYSAv77nBbJ5yZ1Pa+Eob76nP1tXV5dznySgs1NbDlocUlZ8xW2wd1oAKROvWedAJs72vghPnZ3n\n8OmZyorejUQ2pdwodrfSwKUqfmdlLGm30kRaxROc7k27Fff6Swb5jesvpiPoq2y6B3zwJ3YRkyFO\nj9Zof2Hdv50u4tA9Uuwm20yWpkgF+/j3oxN87flk6bnUosxyWEuXEhhxcCYVg2AnU4tpUtk8w90h\ndm3q4BW7+vjKoTPIYBSEF+LTyNgYJ5PRQgprCUFlSaTj8yUZF2uCnl2fns85NuoKBDsIiQyPniwT\nLikr3UrgeEPPJzKcPHOWjPCzdVDtf2BHr+pI64/WJw4L46pASC+DeGR0nu89e56eiJ8fn5hWbZvL\nlwrVny3a5RJcBqJdShwsUUhb6wM4td+GogjYA9LZZE23EpkEb7h0kLG5BO/+1INc+8f38rvfeIr7\njk6QzOSqfPA2xMlF6PXB8NXFjCXt/hlPKouvmlupog6nsJZD0ULftakDTyjK5NQkiXSV621ZDm7i\nEB1epVTWaabyapL48HlPYVtd2CyH0TWucQAjDs7omEOhC2Kvmsm85+XbOD0d56EXZwtV0nJhnLF8\nj4s4qJsiKuI8O7bGPZb07Hp0STDc7f4FPHp2qnQQSy+qRnd1iMM/PfwSkVxMudn0DP6K4W4CPg8x\n0VW/W8nmUvo/9x6jK+TjE++6inQ2z4+OTVUuFao/W2+3uzj0aOGYmltASkk2WaXDKhRFwxqQpNSW\nQ/WANLkUH3jVdg7/3g38n/dezSt293H7E2P80hce5cAf3M3vfuMpVRi4EbC1ri9heD+MP6mKzvTs\nfzSurOzqbqUyV501QShra9Pb108wH+frj1UJKC+eVw37bAvnlBDdquISzS6EW5rkpVSEkZ4w0zJa\n2FYXSbWWg5SSMWM5rBN0zKEYBFI38FuuHKIr6FOB6Ug/zJ7Ck01wTvZWFYdOEjwztsZtNLJJpMdP\nHucWE9Yg6c0leOKMbeC1F8CBKvhDVMQckpkct/74RS7uyuDvKGZpBXwerhrpZirXUb9bSYvDkdF5\n7n72PL/yE7t5w2Wqvfg9z52vcCvl9OJDfVXEwRKOmfl5Yqks/nyVtRns260BKVvsauuKbYbbHfZz\n09Uj/O3P7+ex/3kDn/+ll/OGyzbz5UfO8MPjLXArtoJCdXRZ5tnIfmWFTTxXmP2fXvQS9HmcY0Ze\nv7LMy8XBtva0na7uXgb8KW790Yvubr2lSTXRcXFDFoLosXHn15dJfmmKE0sh3nHNMHu3j5DB11jM\nIdTD9FKaZCa/pjUOYMTBGR1zsCyHrbpFbjjg5aZrhrnj6XGyoV44r3oKpsOb3Qdgj4+hUJpn1tpy\nyCYL6ZxDTv3frfUIRIaHT9qaCNpbZ4ByC0T6Km7obz4+ymQsxZ5otrSvEsq1NJ4Ok1+qYx3p2Fih\nxuGv7zlGNOTjl35iJ36vh9ftHeDfj04ig91qxqnTaRcXVZHipl6XWSDQ36MGkLmFBSYWUoREmpwn\nUHBfuV2PQkDaci9VtRyc3R9Bn5frLxnkL372ZfRE/HzzsSb4spMLtVfkazWF6ugyy6FQKX1Yibwv\nzNlY1jFRAlADuFML9fK1HKzdg1E2BzOcnFriXivdvJzFiZK4VgWrUSWdy+BJzjEtu3j9JYO87eoR\npmSU+ak6/kYuoxoChnuKPaiM5dBi8nklDsFOzs4mKtJA33NwO6lsnrF0pDDL7t2yw/m9hIBgF9si\nubW3HDIJsh4lDo7mqHajXD7gV+tKW1jiELbVbJS10MjlJZ+5/yT7RrrpZrFCHPbv6GVGdpBZrOFb\nzSSVdREd4umz89zz3Hk+9NrdREMqWHnD5ZuZWkwxmgqqQjndp2pRV3YP9Ha7vnV/j3ptPrbIZCxF\niDSyVvwAirPVQuPCase4uD80AZ+Hn75qiO89e27lq8V95f3w7Y+s7D0aRUrV0vpf/zM88pna+8fG\n1X1V7rrp3aXukbHHCq0zxhxWgCvBH3ZwK1k1EmUWY7CLiIwz0hPmsz886fx+SxPu8QaAblWj09SM\nJf1dWvL1cM22Ht66b4gZ2cXU+Tr+hq11RitqHMCIQyUZPTvTMYeR3tLZzZUjUS4bivLsXFEwtm3f\n7f5+wShDoTQnp5ac18RdLbJJUihx2OLo11U32sHhEIdPzxbjDuVuJaio7Lz72XOcnFri1153EaK8\nXTcqY2ledkCyhltp0VrHYYi/vucFusN+PvCanYWXX793EK9HcMTSGO1aWlpaIicFw33ubiW/Xrch\nFosxEUsSJlU988gSAasfU6Yey8GhcK6Md+3fSjKT584jK1xM5vwR5ZZZC+Iz8NCn4FOvhs+9EQ5/\nAR74v7WPWxiD6BCPnJrlV247VEzCEAKGr4HRxwstt8cdVoArwWllPsutFCgrZAxGEakYv/TqHTz8\n4gxPn3WYiC1Ouqexgs1yaJ44SD2hGtyyFZ/Xw0BXkFx4E6n5CWStletsrTNG54w4rA9sHVmdMgSE\nELzn4FZOLBWbhV26d6/7+wWj9PtTSAlHz61hh9ZMghR+BrqCBH0OrhQ9sL1mR4RkJs///PYRdcMW\nxMFuORRbaKSzef72vhPs6I9w45VbKtt1AwNdQWS4l2B2UfVOckO7IU4mu7j36AQfeu0uukLF9Z27\nI34O7ujlkXEd0NXikIgvqgK43ioDtx7sl5aWmIylCIs0otpAL4Sa9ZZbDlVjDtUtB4BrtvWwa1PH\nylxL6bi6/quRamln/En4+q/AX14K3/2ouoZv+z/wmv8Mc6dru7Vi48T8A3zg849wz3Pnuf0J2/mO\nHICJZ2FxgnwwykQs6dg0sUCgwyHmsKCEwVM2bAW7IJ/hPfsH6Qz6+OyPyqyHfF5dv84qbqVgl4pl\nNPEav3RWFc1evHNnYVt00xCd2VmeHq3hSbBbDnMJIgEvPRGHtc9XESMO5RQ6sna5Zgi845oRYkL7\ntGUHl26rMiMJRYl61Gx0TeMO2STxvN/9C6jdSvs2B/nI9RfzlUNn+cIDp1SNg/CUuga0Wymfl/zW\nV5/k6dF5/uubLsGbTxf8ouX09KlrIt0qq6HwRbz16TQ9ET83v3pnxS5vvGwzz81py01/YdLJJVIi\nQGfQV7F/AT2oJxLKrRQRGTxuq8AVjrHNVguLJTUec7AjhOAdV4/w4MnpwgywYeZ1ZX5qoXLRo2Yh\nJfzju+CF78H+98Ov/QhuuQ8OfABGDqp9Jp+v+hapmTP84JyfLVGV+n2H3Voa3q+aVZ49RNrbQV7W\n8KE7WQ7lazlY6BhEFwne+/JtfOepcf7hByeKnZSTc6rZX+fm6tcgOtLUmMMLJ9UCQvv2XFTYNjS0\njX6xwL8+WePv2C2HWTUOudX0rBZGHMrRpmvKG2Y2nnG8gXsiAbaOKB/lgn8Af3lXSTvBLoLZRbrD\nfp5dy7iDXmPZ9QtoC8D+5g17ueHyzfzBd55lfHxUWQL22ZnuCfPxbz3B7U+O8Ts3XsrbXzZcnN2E\nKzO1BjerjJXx8SrZH9PHkQi+etLHh167u8RqsHjDZYMsSF3trAfGTDJORtRYZF1bDulEnPMLSaK+\nDMKtxsHCHy4GpK1Zaz0xB7dFkzTvvEY1dvvW48uclc7ZOgKvRhUvKAswPgWv/x34qb9QHVUtBi9X\nj5NHXQ9/6swsYvEcC4EB/ulDr+QdV4/w6KkZJhb09bSC0rkUcY/6fzoWwFm4BaSDTuJQXA3ulut2\nc9XWbv7kzqO89s/u46f/7w/5p38/pF63BaQzuTzj8wkef2mW7x45x1cPnWFM9jI5dpK//8EJPnnv\nMf7iruf57pHlZy+dPav+b5s2jxRPtWczHSLFPU9WyayCEsthbH7taxwAqky9NijacphK+4EsW13S\nx/ZfejGcg1xHjdlIsAuRinHFcHRNLQeZTRKrSxzieDyCv3rP1bz77x7g6WMn6e/tpSTBUMcf7njk\nGX71dQf49dfrmVCyeAOXs31kBJ6CF06/xPDF+ypeB2DqGFPezUQiHY5WA8DugU6ivZsgTkEccuk4\neW994uCTaZ4bj9HlzYDfpemehT0ImmmO5QCwvT/Cy3f28s3HR/nw6y9qfAY4d7r4+8IobL68sePr\n+htagLq3Vb7Wtwu8QeUWcuDI6Dz/6XP38H2yvPXVB+jpDvHWfVv4q3te4K5nzvGLr9qpMtKiqgo5\nJtV1q+pW8ocrUz7Llwi1sC34M9h/Ed/88Gs4MxPnu0fOcceRcf71gSf4+QD81p3jHP3+Dzm/kGJq\nMUW52/9PfEHe6B3lE3cWRbAr6OPNV2xp+H8WS2ZYnD2P9AqE3UUbUR0HMrFJDp2eLSzbW0GJ5XCK\nq7a6Z+atFsZyKEfHHMaTahbrFgS6dLfKUNo8sqv6+wWjkFrgiuEoR8/F1qwgKpeKs5T31xYH7T7p\nDPr47M0H6SXG8wsBFmzZNfe8pM75F66M8NEbLy2+h1XH4GA5jAypAN9Lo+4z3aXxozyXHuBD1+2u\n6iI6eKm6xqlFlf0h04nqmUcAQpDzBgmS5oWJGB0iXX2gB3VNsmWWQ10xh9ruondes5XjE4u1fc1O\nzNrEYX4VOodC0XXV4yAOHq9aA3mi0nI4em6BX/zcw+zwq8/Vs3k7AHs2d7FnsJN/e9o28x6+Rv2p\nnLqm1S2HsIq12NGZThUUxKEY09vWF+FD1+3mmx9+DX/3DvWZvNHNbOoM8oZLB/mPP7mHP37nPj53\n80G+8x9/gh/+9vW87bUHGRDzPPux6zn+R2/h4zddQSyV5fxC44VxD5yYplfOkw32lKZPa+tli2+x\numtJWw5xbyez8cyaBwHGOxsAACAASURBVKPBWA6VaMthPKEujdvg6ulQs+lI/9bq7xfsglSMy4ej\npLN5TkwuccmWGjPYJpBLJ0jSXzPmYA/6beuL0NeT5cczXfzvLz/OZ29+Od98fJR/PrTAG4PwkVf0\nlM6gqoiDVxfGnT/nnKWTzeYQ0ycY91/Pza/aWfWz/MQVu8gfFrw0Nsa2TA5PLokI1PFl8YZUCqtU\n9RxVs5WgNCCdrVE0Z3+tSkDa4qf2DfH7//oM33hstPFZ4NxL0LtTPa5WUNoSne7tFS+NzyeQgR30\njB7mO4+eIZXNkcrmSWXVGgtBn5c/f9MAfIeS6ui37Bvib/79GJOxFANdQeVaOvodpnMhoiFfjZiR\ng1spuQA9lefnJA52evNqoP3T97+xNNGinAH13pHkBIR3cvGgasFyfGLROeOvCt9/fpLrvYv4usri\nkVocfnKb4HNPj/Oxt11eudgRqO+WP8JYTGURtkIcVmw5CCFOCSGeFkI8IYQ4pLf1CSHuFkIc04+9\nersQQnxSCHFcCPGUEGK/7X1u1vsfE0LcvNLzWjb6Bjuz5MHrEWyOutwUXUPqH61nQ66EopBLc+Vm\n9T5rVe+QTydIuax3AFQWfWk6svPs3r6N+56f5Fdue5Tf+fpT7NqxEwBvoqzSt4o4WNviC5OObcG/\n/oNDREhwxb4DqqlaFQ7s7GdRRBg/f57x+SQhkcFbhziIQIggygIKkarPcrAGpELMoR5xqG05dEf8\nvPGyQf71ybHiolH1MvcS9O1W99xqWQ5zZ9RndRg8f/trT/H/nYwQSYzzv77+ML/37Wf4w397jj+/\n63nCAS//9KFXMIjOcrNVR//UviHyEu56Rk8QdIfWyXSV+9LCqc7BNeZQXRxYnFAr0rm1zrAoW/TH\nEodjE41lGUopuf+FSXaGEwircaWFfv7aYZheSvPACZdaoJmT0LuTs1aNwxpXR0Pz3ErXSymvllLq\ntAY+CtwrpdwD3KufA7wF2KN/bgE+BUpMgI8BrwCuBT5mCcqaoy2H04setkRDeD0uvsZABP7bcbjs\np6u/n76Zd3XmCPo8axd3yCZIynrEwTaw6VTWi3fs4D+8cjv3PT/JvpFufv99r1evl/uAq4lDqBuJ\noIdFnjxTmrE0EUty1/0/AuCKqw7U/Cg+r4eMv4uF2UnOzMQJkS7UMVRD+MMq1gAEZKq6iwjKxKEe\ny6F2Kqudd16zlemlNPe/0ODKgHMvqRlzdGQV3UovKZeSg2/9+MQinduuBOC+m4d49H+8kSc/9iaO\n/sGN/PC3r2f3QKdKSxaekoygvZs72T3QwZ1WUHfkAGzex6H0zjrEwSkg7eJWshrxuYnDkq6OLk+B\nLadMHAY6g3SH/RyfaGwd+OMTi4zOJdjsXSytF4KCOFzalaIr6ON2N9fS1AuwaU9L1nGwWK2Yw03A\nbfr324B32LZ/USoeAnqEEEPAm4G7pZQzUspZ4G7gxlU6t+qkFgHBi3NNUms9q/FlFrl0KMpTZ2v0\nnW8SnmyStCdAv8t6B3j9ajZlz7RJxVTKX6Sfj73tCv7iZ1/Gbb90LR3RPvD4ncVBeJxncx4vMtRN\nj1jkcNmaEX/8b8+xNa/cI2LTnro+jy+i6ibuPDJOiDSBsMuiPTaEL0S3X83Sffnk8iyHauLgDajP\nX4flAPC6vQP0dQT4RiNZS+kllUXUs3312kqDEh2HYHQyk2N8PknnVpVUMJg4yUCXGjRDfm/RzRgb\nU0Vm3mLGmRCCt145xIMnppleTKnvwq//iO/FL65eHQ1Fy8GKGucy6nk1y8EtzbdW6wwLqxBOC7AQ\ngosHOxsWh+8/r74nnbm5Yst7i0AH+CP4k9O86Yot3HXkHKlsWTfZbBpmT0H/HsbmEsqD0RVkrWmG\nOEjge0KIw0KIW/S2zVLKcQD9aDneRoAztmPP6m1u29ce3ZF11G2VqkYppNkt8MZLB3n01Kx7iX8T\n8eVT+IORkjWtK3cqyyVPFPsq+b0efubAVrojfjWbLGuhofZXXSPdZmSecC/bQqkScXjgxBTfemKM\nm7bqjqflHTxd6Ojup1vE+dbjY4REmlAd4oAvRNSfBSTeXI2Fe0CdjxVryCbVwO91EVdw7wHkQsDn\n4W1XDXH3s+eZT9TZTmPOChTvUC0eFsaoSLNpBnNnii0kbJzWa2P3bN2jMsDc0lnLF/nRvFW7lr73\nrFrwKpHOMeeSIl6CPwLIYgNEl6Z7gFqv2ltlNbjFido1DqCskmC0pNbh4oHGxeEHL0xyyUAYb3K2\nkJ1UQscmWJri7VcPE0tl+cHzZd+r2RdVTcimvYzOJtgSDTnHJVaZZvzF10gp96NcRr8hhLiuyr5O\nI5Wssr30YCFuEUIcEkIcmpxs0DSvl1QMGezk3EKzxKHoD/3w9Rfz1n1b+MN/e45vP7GK1a65LF5y\n7ktiWpQXGjlVR1voG7oEh+roEsK9jISSPPbSLPm8JJ3N83vfOsK2vjBXRyah/6Lapr7GF+lhKJAk\nkckRFhm8gdpuJXwhOr1ZAmQRMl9HQDpUWiHtC7t38bRw8o1X4Z37t5LO5osLGdXCSjHt2a7aSmeT\n9a8HUC/puLZOKi2HU9OqKnrnpi6dseTSwiM27ij0lw11sbM/wh36847Nl3Y6dqXcZefSdK+ATvxw\nZGmyel8lO9HhEutsz+ZOppfSda/HspTK8siLM9x4UQCQlZYDFCZar76on76OAN9+osy1NHVMPW66\nmLG5Jo1Dy2DF4iClHNOPE8A3UTGD89pdhH60WiWeBex34FZgrMr28r/1aSnlQSnlwYGBOszE5ZBe\nJOvrIJeXzfHzWT7S5AJej+B//9zVXLurj9/66pP8eLVaOevZb7jW7NofKhOHso6sdhwth9riMOCN\nE0tmOT65yGd/dJITk0t8/O1X4p05Dv31uZQACPXQ61XnGhbp2gM9gD9Ety/HcETPM+oqgrPcSona\nMYryY+rgZVu72b2po37XklXjYLmVoJh22iyswdAhU+m0Focd/R0weFkVy2HU0XIQQvDWfUM8cGKa\n2aV0scOo0xojdspjYm5N9yzcxEHKYrvueoiWuu4usmUs1cNDJ6dJ5/K8bqseWquIg9/r4R1Xj3DX\nM+eKxYKg4g0A/XsKK1G2ghWJgxCiQwjRZf0OvAk4AtwOWBlHNwPf1r/fDrxfZy29EpjXbqe7gDcJ\nIXp1IPpNetvak1ok7VGzlmbGHKwbN+T38pn3H2T3pk5+9R8Pr0r2UjalZluRjs7qO/ojpTEHp6Z7\nFssUhy6pvlS3PzHG/733OG++YjPXX9ytZsT9F9f6KLb36iGSV+8VlKnqlcsWvjD9oTx3fUTnSdR0\nK+mBXkotDnVYJ3qp0HoRQvCu/SM88uJMsb1DNeZeUp+1c3MxYNrsKulCAVylW+nFqTh9HQG6w361\n5OfCaKVvPx1X28pbdWveum+IXF5y97PnGZ9Tg2B9biWK4lDNrQTu4pCcU4tXNWQ5FOelexoUh+8/\nP0kk4OXKHu02rOJWAvjFV+0gm5d8+RGb4E8fh84tZP1N9GAsg5VaDpuBHwkhngQeAf5NSvld4BPA\nDUKIY8AN+jnAHcBJ4DjwGeDDAFLKGeAPgEf1z8f1trUnvUhcqH+G0/KaDROszKToDvv5wgdfTlfI\nxwc+/yjnj3wf/uk9KujWBKbm1Je3s7NGPYXPzXJonlvJl56jryPA39x3HID/+bYrVJqezEOdwWgA\nQt14Mku8e18/XupwEQH4gohMkqDULoF6AtKWnzubqE+AGrQcAN7+MjXI36398FWZe0kFioUoDt7N\nDkpXKYA7Pb3Ejn593QYvU4/lPZasBXJc4kdXDEfZ1hfm354eZ3QugRC4p4hbFCwH3eyvplsp6iwO\ni3pCU60jq53oiIpRZNU9M9wdJuz31iUOUkq+/8IEr76on0BKf5ecLIeIbmQpJbs2dfC6vQN86eHT\nxRRnnal0PpZqngdjGaxIHKSUJ6WUL9M/V0gp/0hvn5ZSvkFKuUc/zujtUkr5G1LKi6SU+6SUh2zv\ndauU8mL98/mVfawVkFpkUaobtyn/lKCevadKZ1tD3WFu++C1pDI57vv2F+CF76oMhSYwOasyoqx1\nlF0pD6bGp3X2kcM6CR0DaoZs78xZhziIxBwHtqnZ3n9+4x41C5pWQtGQ5aDTFf/yLTqwWO/AnU3Z\nOqzWOVvNJrTlUI8ANS4O2/sj7B7o4Pv1pLRaaaygBhVvoPnprHNn1MprDoP7qakldvVr96QlDuVt\nNKyZtoNbCYqupR8fn+LouQUGOoMEfDWGHle3kssaHroTQQVL1trRdbqVukcAWRA8j0dw0WBHXbUO\np6bjnJlJ8Lq9thb3jpbDgMoK1Od786t3MBFL8b1nziurdeqYSmNtYY0DmPYZlaRjzOWC9Eb8RAJN\nKCD3BVVfGodZzd7NXXzuAy+nP6W+7Ceff2rlfw+YmtWtDKK1egmVWw7TapEfpyBx+VrS+bxyJdQQ\nB5C856pu3nT5Zj74Gt1qxAq4NSQOuoBpUc+26xq4Q8WBvp5jLMHJNCAODQakLV63d4CHTk6TSOeq\n72gXB4+nwifeFObPKneKt/R+T2ZyjM0nVbwBVEzCH6lso1HDcgB465VDZPOSe56bqN42w8I1IN2g\nW8m6X+q2HCpXhNsz2MWJOiyHR19U1sKrLrJZ2Y5WuPVdUvu8bu8g2/rC3PbgKbUtOacylebUZ2+K\nB2MZGHEoJ7XIbDbQXLUORYsznzJevrOPV/Womf4X7/g+v/DZh/jRsanai4FUYXZe/a3eqPtKaUBp\n6iYocXCKN0DFDa0sIVm96lR/Md64M8Cn33+wOFvUPlXX4KIT1owxpqtt64o5hLTlUEfNApT6ubN1\npL5a79mg5QDw+ksGSWfzPHSySuaRvcbBontr8y2Heec0VismsnOTvi4eDwxcApNlGUs1LAeAq7Z2\nM9ITJpeX9Q125ZZDXdlKDt8xy61UTyor2ArhigJ88WAnY/NJx0p/O4+emqE34ueigQ71fwv1lNR9\nFLBcTXqi5fUIfvGVO3jkxRlOvfCEeq1/D2P1xmdWCSMO5aQXmUz7a2dTNEK1NLt8ns4lFRB8964M\nx84v8h8+9zA3/e2PufPpcXLV2vq6MLegg9+RGtlK9tRNUG4iV3EovaGrVkdbWK/Fy1aE02ZzQ5SL\nQ53ZSoWBvp5j7Cu7ZeK1s5ug4YC0xSt29RHye/j+8y5rHkNJGusXHzzF1w6f1VXSzQ5In3EsgHtx\nSqex9tvuo4HLKi2HhTE1o3cbuLFcS2qt8KF6vltOAWlvwD2DzO07tjShXGbV7lM7LuIA1LQeDp+e\n5cCOXlUYuDTlniFVboUDP3dwG0Gfh8cOP6I2bNrD2dkEfR2B5ngwloERBzu5LGSTTCT9zbUc3IJl\nAAtnIacKffaFp7n/t6/nT961j4VEhl//0mO8+a/vZ2qxsa6QsZieQTWyfgFoy8GlMVn5Dd2IOCTK\nxGH6WGMuJSguKGS5MOp1K+UzxWtfMyBtG5AyjVgOydr7lRHye3nV7n5+UC3uoMVhKTLCH9/xHH98\nx3PkuobVNcjXcEfVSz6nBkLHYLS2HOziMHipWt7V/j+Njam+TzV4yz61T13ZN4Eyt1LSpV23RbBL\nZSVly74rVnV0nfU0hKJqtTl7IVyhx5K7OEwvpjg5tcSBHfr7E592DkZD5UQLtUbMO64eYe7Ms6rj\ncPc2xuYStetBVhEjDnb0AvazuWBz08fcTF6A6RPqMdIPMy8S8nt537Xbufe/vp4/e/dVHJ9Y5L6j\nVWaXDsQW9U1cVy8h26y3qjhYN7R2Ky1XHJam1fPlWg6WD7let5L979c6ptDGvJGYQ/0V0uW8/pJB\nTk3HOTXlsvymFof/v70zj46rOBP971NrlyVZLUuWLduSvBsMwQvGhiQ4ISwhCYGQDGRhwksOk5dA\nZhImmUlO5k1WZvKyAVmAQ0jIMpMFJmGG5EE2QiYDhmADZjG28Sbb8iprs/a13h91q/v2fm+rW92W\n6neOjlpXt7urq++tr779sWOlDI1O0Nk/wp7hap09azSoydJ7TL9eHLNSa0c/s8uLdJa8oc44pV3a\nQ4Ls6GjWLJzNHdedxzvWeih+EKM5JCi6Z3A1/IkgVXvQeFRH1rBqCpZTFJCkEUumCsD6Zuea7z+V\nWAs3Tur+SJPiDZuaaFJH6CxdCAUFOschRyYlsMIhEqeXQx+lGRYOSTSHTkc4LLlERys5O8JAgXDt\nugWUFBaw22fv6cEB5yJOtRgWloZNLqZ/dKILuqgMime5hEPiLnAh4gmHjjSc0eAyK/nQHMw5Zqyp\nNIdCl517LLsOadBOaSCxaan7IBSW8pMdgzTXllNTXsQfjzrlPDLllDblOeIkwLV29EdqDaA1B4j0\nOyTIjo5GRLh6TSOzy5OUJDFEl0NPVHTP4Gr4E0HfSe/OaENUrkNhoICWORUphUNxoIBzGp3rdOBU\nYs2hsFhfz1F5Q6sbqzmr+AQvDtYxMaE40pWbDnAGKxzcOBVZ+1VZZr+UJA5pOvbrRavpQm0Ccd30\ngQJh+dxKdp/wLhz6hseY8BO6OTakI4+Ge2FiLLFwACfXwYdZyTirI4RDGmGsZqwFRdDrR3NwipWZ\nmlFekuBAL0ijXvMcyvX3lkaOSvOcCppryxOHtHYfYrSykacPdHHt2gW89dz5PHrIaRyTKae0eZ14\npTNODdBcGyVQqxfqTYLRHCYcLcaD5uALM/cjbrNSEuFQmkBz6DvpPQHOEFVCA3AK8CW+D7e2dnLO\ngmpKiwL6fhroiB/GaoiXVDo2TMP4cV4cnsvDLxxlcHTcag55g6M59FOaYZ9DMrPSXl2rP7hY/915\nIOLfKxoq2XnMu3A41j1IKU7SV0ozivN/d72epMLBdUEPhtsYJiRQqG9ot3A4tUcv8rObko8tGhG9\n2+rz4ZA2moB5f18Oaa8Z0t57OsRj84p6ntrXwdBoHB9C9yGOOjUrr17TyNVrGjk45gjjjAmH+NnR\nOox1MBzGahCJjFjqO6nNUgmyo9MmVNTQFcqa1KwUp6eDUuFy3X6oWhCRCAewtL6SQ50Dcb+nodFx\nXj5ymvVNLk1ZTSTWHCC+cOg8gDBBe/EivvY7nWiYqE3xVGCFgxvH5zBSUJ641HU6GLNSvPDUzn1R\nwiGyYuvKhkpO9Q3rksceONI9SKnT4MZ70tdQODu6LEmnrIq6SJ9D8az4oXpuymbHag7BxTEx9Z4o\nrfbuP4DwYj/QqcuTpxqrmY8hJ0zXa20lSFs4XLyijuGxCf5yILYggOo+xAu9VVzQEmRhsJy1i2ZT\nE5zDoJRl1qxUFtSlpF20dQ2gFLTMiRPx5o5Y6nXMLx6r6/rCHSY8fNqbWcmtoQ/1OKUzPIaxGqrm\nAyq8EUFrDhMqHMHl5qUjPYyMT7DOCIcB5x5JJpTKa2MrDjg1lVaesy7U5MealfIFR3Mor4xqhzlZ\nSir17iraNj0+5tRtX+IkIRXrcr0uTEtRr36Ho91DlIhHzSGU9DXgUXOIMit5CQ8sq4nVHPw6o0Ov\n5dJSvEYrQajloufzjaD0WlsJ0vY7bFpcS0lhnJDW4T5koIOdgzVcu1bv6rXNfgFt40GGOg6l9X4x\n9LQlNCkB4dIZbupX6h15f4d2RkPmzUoQ6exPGa0Ux6xkrlXfZqXYGlZL6xLXWNrWqq/vkHAIJcCl\n0MIHooSD44+77HUXUeiU2rdmpXzB8TlUzc5wE7pE9tCeQ9rOX7tUNyGf3RSjORjhsMujcDjWM0iZ\njOpwuJTlps3CNuTq5ZBCcxg4pW2qg13JTUoGt3AYH9Ofz6+/weAuneBbOPiIrTeC0muJDkhbcygt\nCrBxcW1sTX+n3tGxgnre7OQHgDYvHVNBTp9oTev9YuiJn+MQKtUdbVaCcMRS+05P2dFp4274M9zr\n0azk0hz6HIHr16xUHZvrsLiuggKJLxyePdjJ4roKamc5Pq6Q5pDCrDTQERmSfGoPVM6nfs4crljd\nQGVpIcFMWjB8YoWDG2fxnl2dYeFgLupop7QJYw0ucX4vhs7WiFPqZpVQW1HsWXM40j1IsHgc8WN2\n8aw51GlhNtTtQ3MIhgVP90HtvE1Xc3ALBy8JaiHh0OlNOASKdMLUYDqaQ3rCAXTU0v5T/RzqCGsf\nox2tACxsWUlladgc1jKnguGK+RT2JWgv6QelEibAtXb0U11WRE28xSlUY2mnjuopKPS/AHvBaA6j\nA1rzTpXnAFGag6mrlIZDGiKEQ2lRgIXB8hjhMDGhePZgV9jfAMnrKhkq6rRfIkar1hun2645hwc+\ntCmzFgyfWOHgYnRQL961tUkWyHRI1ADdCIdaIxxanIqlYd+EiLCioZJdx731nj7aPUhNsceqpaG4\nfschLYHEhc0gsoRGOmalUKTSJIWDFKT2H0BY+A12exMmInpOQmYlP5pDemYlgM0rnJDWV8OmpT27\ndXG7jWvXxJxf17iYoOpmV9skG14NdumqpwkS4GIilQxV8/WGp32XFg6zGrwnmfnBOKRT9XIAvREo\nKIy8x/xWZDWUVsckwoEu3x0tHPaf6qNrYJT1TS6N26uJFsKmr1DBveWArty8ap6P8jJZwAoHF/2n\nuxlVAebWpKhJ5JeQPTSqDn7nPn0RmkU3uFjfrFFRDCsaKnn1RB8TKUppTEwodh7rJVg8Hg7jTEah\na2EzCXDJdiruC3qo259wmJhIP4zVYEJjvXRoM+eB3nV6EZagz5tizaFlTgWLguURpqXDB3YxRDEX\nrF4Rc/7SZTrX4PFntqf9nkC4VHeC0hkxkUoGEd3b4eQu7ZDOdKSSwTikU/VyMGOKLqHRd0JvJJKZ\nShMRJ5x1Sf0s9p/qY8yU1sblb2h2aw7turJxYRKTUHTFgf52vT6ku3HKAlY4uBjs63HCWD0sCn5I\nqDns1VqDWehqnKqlUeGsKxsqGRwd51CK5jB7TvbRMzhKfZnyWBfICAcnWinZTgdcF/RJveAnK7pn\nKKvR6vNIr94ZldVARZqamdEcvOzoIVJAelnoQc/bgJ+IqMlrDiLC5hV1bHFCWjv7R1BdrfSVzqOw\nMBBz/qw6HQb80iuvpFV7K0QoAS4yjHV4bJyj3YM0x4tUMtSv1D4Hj9nRaWF8Dqkqshqik037T2rT\nTkHsHKakan5MDauldbMYHVcR9+G2g10EK4pZ7J6r/iQJcIZozcF0f0vX5JoFrHBwMTzQQx9lmY8Q\nSOSQ7tgXNimBNitBnHBW/fxUTulnWvWOt7Zkwr9JxI9w6D6kQwS9ag6ghUmHz9ag0Rjh4EXwQaS2\nkJbm4LG4H0xKcwBtWhocHWdraye/fvEo82mntK4l/snOYl4ycCx5VddUhJr8RGZHt3UNMqFIbFYC\n7ZQe6NDRddlwRkPYrDTswawEsT0d+tr9h7EaqhtjzUpz9SbPXWMpotieIVl2tCG00XK+v1DfaCsc\n8pLRgdP0q1IaqjNc7CpeDPbYiL45gy7hMHuRVoOjwlmXz61EhJR+h60HOqmvLKFURvxpDsbnkGqx\nLwsCEt7l+BUOkwljhXB0lGfNwXWe1+e4y2H4iXCahOYAsHFxLcWBAv60u51fPHeEpkAHs+Yujn+y\nE2rZXNTFQ157Ucejp01fJ1GbAlPrKaFZCcJlNCbGsqw5DIbvm5SaQ2Ws5uC3rpKhqlGbpVyZ70vq\n9HwYv8OpvmEOnOqPdEaDXvCTOaNB3xdS4NIc9ujvoiq2xlWusMLBhRruYyRQnrpLlV+K45iVulq1\nucWtORSW6IsjSnMoKw7QFCxPGrGklGJrayfntwSR0SFvi2GMzyGF5hAo1PZbs8vxIxy6D+mkonT9\nDeBfc4gQDh7NSm6BMAWhrIby4kIuWBzkoeePsPfwMarV6ZgdfYjicigLckFwgN+8fDx1w6BEdB/S\nzugo/02rEzUVNwHOYMJZIcuaw2DqXg6G6EoEfe3+ndEGkwhnQnWBytIi5lWXhkp3G3/D+uao+2Dg\nVGrTaUHASYRzhIOpVJwNx36a5M9I8gAZ6WO8MEUPhHQIFEJRReSFm8g5G2yJ8TmAdkonEw5tXYMc\n6xliQ3NQawK+fA6D2pSSSjiAVofT0Rzaturfk9EcjI/Dq4koUKR3Z36eE2GK8uGQHpuccAAd0trZ\nP8LCAicUMpFwAKhuZEX5afqGx/jDTg+9qOORoMlP66l+KksLqSlPEhFW2RAW1ll1SA+EN1UpzUou\nzcGUzkhbczD9uiNNS0vrZ4XMSs8e7KS4sIDVja4AllAByxSaA0SW0HD6RucTaQsHEVkoIo+LyE4R\n2SEif+cc/5yIHBGR7c7Pla7nfFpE9orIbhG53HX8CufYXhH51OQ+UvoUjvWHez5nmuhdjanGGowy\nHQRbYsxKoP0OrR39CXeJ2w5qO/n5zUGnLpCPXW/fidRF9wwVdd6K7hnMOYcd4TApn4NPs5JIWEj6\ncUgbvLxPoEiHUE5ScwBdZwngskYnwz1Z/amqBcwePcm86lJ++VyadZZ62hLmODTXViSPsRcJaw9Z\nMyuV6+vShIYWp7g33cJhuFdvkialORBTw2pp/Sz2tevIwW0Hu3jNgmpK3EEDQ916zKl8DhAuoTE6\npLW46SIcgDHg75VSq4CNwM0icpbzv9uVUuc5P48AOP+7HjgbuAK4S0QCIhIAvgO8GTgLeLfrdaaM\niQlFycQABaUpVNd0ia7M2rFPL5zRYXY1LfpmGIoMe13ZUMmEImGj82cOdFFZWqgzqr1qDmZhM1EZ\nXkL+3Be91wxpgGPb9S4+mMDJ6gW/ZiUIRyx5MRGBf83BnJcB4bCkroJb3rCUv1rqhEqm0Bzk9BGu\nO38hj+9u59cvekuK23Oil6u/8yTb9x/Tu9ZEOQ7JTEoG43fw0OgnLUzDn94T2jSbKurILRz60kyA\nM4SypGM1h4GRcQ509PPykZ5wcx+DlwQ4g6k40Llfm5idHId8IW3hoJQ6ppR6znncC+wEknXxeDvw\nM6XUsFLqALAXZCVTqQAAFotJREFU2OD87FVK7VdKjQA/c86dUk71DVPBIMXlWUo8iXaWde6LdEYb\nklRnhcQRS1tbO1nfVEOgQLxrDqAXWhPP7UVzcF/0XjSHwmK94xsb0oudl/yLRPgNZYXwYu/b5yC6\n1pXX50zSIQ06pPUTl69gAe36e0mWdVzVCEM9fGTTXNY11fAP//Fiyiz69t5hbrx/K9sPd/PzP2zR\nB6M0h5GxCdq6kiTAuTn/Jrj8X7yb7Pzi1my99BsvrdLX2dhIODs63cztkip93UYLB6fG0kPPHWF0\nXMVxRnsonWEwZiVjpp2MPy4LZMTnICLNwBrgL86hW0TkRRH5voiY2WsEDrue1uYcS3R8SjnSNUAF\nQ5RWZDgBzhAdg92xL/7FkCCctam2gtKi+I1/OvtH2Huyj/NbnF3M2JC/nXKPD+FgbrZAsfcF1wiR\nySb4FDrvmY7m4NfnUFTuLdHOPCcDmkOI7kNO5FqS93cW9eL+Y9z13rVUlBTyoR9vo2cwfl+JodFx\nbvrRNjr6h7nynAbaWl+NeB1DW9cAEypFpJKhYTVsutnTR0oLc331HU/tjIZwNNNIn0tzSDOUVcRJ\nhIs0K5lw1ge26SVrXbRw8FJXyVBRpy0EJ3U2/LQTDiIyC/gF8DGl1GngbmAJcB5wDPi6OTXO01WS\n4/He629EZJuIbGtvn2TpgCiOdXZTKBOUV3owlaSD2+cwMqB367VxNAeTCBfldwgUCMvq4zultzr5\nDRuag9oh5rXFJehduCm77MesVFbjffE05qdM2FTrVvq7iUI+B7/CwY92Up4RzSGEEQ7JCJk92phb\nVcrd711LW9cgt/58e0wm/cSE4tYHtvNCWzd3Xr+Gz111NgsLHDt+lFnpYChSKcOJoOlgvoveE6nD\nWMEVMt6TfkVWN1WxuQ7BimKCFcWc7B1mSV1FbO0pX2Yl55yDW/R7ZcvfmSaTEg4iUoQWDP+ulPol\ngFLqhFJqXCk1AXwXbTYCrRG4r8QFwNEkx2NQSt2rlFqvlFpfV5fZQl8n2/XNUpnponsGt+ZgFv5o\nZzToC6SiPkZzAO13iGdW2npAR02cs6DaictWPjSHcm3vhOS9HAxGc/BiUjKENIcM7Ixu+iNc/Env\n55tF3q9D2uv5kD3NIRlRZaXXNwf57NvO4rFdJ7nzsT1w5Dn44dtgoJOv/m43j7x0nM9cuYrLz26g\nvrKUzXOHGVfC6aLIReyAlxyHqcJ8B/3t3sxK7koEfSed0hmTqJMWbNElQqJ6PS+t14v4+c1x7hdf\nmoNzTtu2vHNGw+SilQT4HrBTKfUN13G3d+oa4GXn8cPA9SJSIiItwDLgGWArsExEWkSkGO20fjjd\ncaWDUor/fkkvxmXZMiu5HdLRBfeiCbbEVGcF7Xc41TfMqajGP1tbOzlv4WwdNWFCKr3ulI0QSVV0\nzzAZ4ZCJG8BvlUrz+fwkwbmf5+k5mXFIA3phG+z0IBzmAxJR/+d9G5t457oF3PnYHjoe/ic48Gde\neuir3P2nfbz3gkV88LXhYIDza/o4TpAHn48Mgz3Y0c+sksLMNrtKl9A1rDyalVzCof+kFgzplM4w\nbPiQvp/+/NWIw0Y4xJiUQAuS4kpvvjVzL40N5lVNJcNkNIeLgBuAN0aFrX5FRF4SkReBNwAfB1BK\n7QAeAF4BfgPc7GgYY8AtwG/RTu0HnHOnjL8c6OTEKUfipwqXS5eSSl1fyF2ALp5DGrRGkSCcFSIb\n//QPj/Hy0dPapAQ6LA78R+eU13pbeCelOeTgBij0qTmY8/w4WTPkkAbC9Y5SCYdAkbanu+r/iAhf\nuno1V889Qe2JJxkNlNP46o9509JKPn/V2RGhqTWjJ+kpbuCHW1oj6jO1dgzQPKc8p6WiQ7i/Az9m\nJaM5pBvGaqhfCWtugK33RWjyq5zgkA0tCTQHr7XD3M7yPItUgslFKz2hlBKl1LnusFWl1A1KqXOc\n41cppY65nnObUmqJUmqFUupR1/FHlFLLnf/dNtkP5ZcfPNnK3NIx/UfW8hyMs6xXRypV1CdWlWta\n9I4wajcaL2Lp+UPdjE8olzPaeU46wsELRhX2UnTPUH8W1DTrxKmppsivz8EIE7/CIUOaQ/dB/dtL\nj+3qBTEO09KiAP8y5/ecpoKbBm8hKL18e9UOCgNRt3rPIaoaFnOoc4DHd4VLhbd2JKnGOtW4Bbof\nh7QRDukmwLnZ/GktiB/7QujQu9Yv5MH/vSn+PPW3e4+Qcpue5uSXMxpshjRtXQP87pXjXLncEQrF\nWcpzcO9qOvYnNilB2BfRdTDicF1lCXNmFbPbVWPpmdZOCgTWLnIWa6M5+AllBe9ljUur9U3rxaZq\nuOBD8NHn/ZuEMkEoWimLmkNZjd7BRzdzSodup/1nKs0BtFM6KkmL9lcp3/cop8+5EbX0UobnnU/p\nM3dF1AhiYhxOH2XeoqU0VJVy/xatpY6OT9DWNegtjHUqcH9nXkyeIeFwWpuVJqs5gE7w23QL7HhI\n+wbQAjiuvwG81VVyj9eES08nzWG68OOnDyIiXLLYuRCzpTm4K7MmynEwJAhnBZzGP2HNYeuBTlbN\nqwp3CwtpDj6jc7wKBxF43y/hwo96O9+Qq5oxhT59COY8P+Gya9+vNcK/3ONvbPHoPuTkOHhYYKoW\naKHkag7Fk3dAYSkLrriVH35gAyUX36rb0e54KHxO73GYGCNQs4gbNjXx5N4Odh/vpa1rkPEJFb81\naC6I0Bz8mJVOOxVZMyAcAC76W60N/P6fI+c6Hn7MSiJakBSVZ68+1SSY0cJhcGScnz1zmMvPnkuw\n0ClZkE2fA2hzUd8Jj5pDnBpLc6t49UQv4xOKkbEJnj/cFbmL8as5mPP8RHU0bcrcjZdt0s5z8CEc\nGtfCiithy7d117nJ0H0wdY6DobpRbwZMOZPuw/Diz2Hd+8PCZfkVOvz3yTvDC1uoyc8i3rNhESWF\nBfxgS2u4b7SX7OipIMLn4EGjLyrTgRW9x/W8ZOoaLamEzZ+Cg0/Cq79JfJ5SOpTVq+YA+nvKs4J7\nhvwb0RTyn9uP0DM4yo0XtujEGci+z+Go070rmXAoq9GdpOIU4FvZUMnQ6ASHOgd4+WgPQ6MTkY4x\n35qDszubTMhfPuM7QzoNsxLoxWO4B56+y9v5Y8ORzeUNXsJYDaFwVse09NS39e9Nt4TPKSiAi/4O\nTrwMe//gvEe4yU9NRTHXrGnkoefbeOGwFmxNeWNWcn0HXkJZTTc4E/CRCbOSYe379SL++8/C+Fj8\nc4ZP6x7pfkyur/+k9mvkITNWOCil+MGTrZw1r4rzm2brqqFSkEWfg3NxH3OEQzKzkggEm+PnOszT\n49t9/DRbD7iK7Rl8+xyc87zkOJyJFPp0MKfjkAaY9xpY9TZ46q5wD+pE7H0M/m8zfKEWvtwE31wD\n330j/Nu10L7bu3Aw2c2nj+gd67M/hHOvi62XtPqdWpA8cYf+O9TkR59340XNDI1OcN//HKCiOEDd\nrEmUOMkkBQEIOGPxYlYy55lQ8Uw4pA2BInjT5+DUbnj+x7H/V0ons4E/zeGsq2DllanPywEzVjg8\ntb+D3Sd6ufGiZuSxz2ub7Ov+XpfXzgZGLTaaQ7wEODcJwlmX1evGPzuP9bK1tZOWORXUVbpuZqs5\nRFJeq+fCr+bgJ8/BsPnT2vdgdvDx6D4Ev/igjka6+B/g3L+C+Wt19NdAh45AWnapt/erdmkOT9+t\ny6Zc9LHY8wqLdZmLg0/o6rg9h/VmoFibj1Y2VLFpcS19w2M0parGOtUYIe3FrGTOM079TGoOACvf\nCgs3wp/+FYYdS8PoEGz/Cdx7Mfz0ev09zl+T2ffNEVlaCfOf+59sJVhRzDX9D2on3voPwhs+k703\nNGpxz2HtfCpOsVjVtMDOX2kV1iWwyooDNNdWsOv4aba2dnH52VG1Y6bC53Amse5GWPLG5M3e3fjV\nNNzMPRvOvgaevgc23hzrmBwbhgf+WpuTrv/35KZFL1TUQ0ERtO+CFx+EVW+FugRRL2vfD//9FX2t\njw3H9HH4Xxc189T+juQNfnJBUbkug+0lWgm0cFCOuS7TfjERuOyL8L1L4Y9f0sL12fu1UK9bBW+9\nQwv74jybwzSZkcLhcOcAf9h5gntWvUTR4/+q1e4rv5bdUMuiCnQZKeVtUQgu1nXhew7HlLleMbeS\nP716kqHRidiQOqs5RFJcHi4t7YV0fQ6Giz8FO/4TttwJl34h8n+P/iMcfR6uy4BgAO1PqJoHz/1I\n9/R+7a2Jzy2ZBRtugj9/Tde6aroo4t+XrJrL65bNYfOKzJalmTTpaA4AiD/zjlcWboBVV8Ff7tbv\nseJKHard8vrchGpnkRkpHH70VCtvDTzNZfu/Bcsug2vuyX60QEFBuPieJ+HgKsAXLRwaKvnNjuNA\nnCxNv5qDseVm0j57JlM2G+aeAw2vSe/59SvhnHfCM9/VjmGze93+E73LvOhjeoefKaoWaDPK4jfo\nqKlkbPgQbPmWjm6KqsYaKBB+/MELMjeuTGGEtVefg9HQy2uzZyK+8qt6rs+6enL9SfKcGedz6B8e\n4/DWX3F74V3Ioo3wrh9qZ9NUYC7wZM5oQ03iXIdVjlO6vrKERcEo85RfzeGst8N7HvTuBJ3uBIrg\nw0/Asjel/xoX/6O2/z95p/77+Evw649D8+vgjf8nM+M0GL/D65JoDYZZdbDmffpxnCY/eUlxuVMe\n3utmx9EcshlqXdkAr/34tBYMMAOFwxN//DW3q68xElwO7/5Zatt/JjEXrhfNoXKetn/H7Sethcz5\nLcFY5+HYsI668irwisth+WXezrV4Y84yHTW09T4dffTzG3R48jvvz/xu9tzrYONHtODxwoV/qzcC\nCzakPjcfKCrzblKC8LnpNvmxhJhZZiWlWPD81+gI1NH4gf/y1uYykxiV10vp6oICXY8ojnBYFCxn\n87Ig166N0xNpdFBrDdPM/nnG8fpPwosPwHcv0drcjY9kx3S37FLv0U0ANU3wsZcyP45sUVTu3aQE\nLjPpGZKkmcfMLOEgwpKPPkxHRweSi4unpFLv6muavZ0fL5y1/xSBLd/iB8e/C3uvg+Vfj/SXjA35\na1RjyQ61S+C8d8Pz/wZv/gosykN7/pnAOe+KabiTlJDmYIXDZJlZwgEorQzSWJmjhK9ZDdrf4LWP\nck0L7HtcJ9gMdMKWb2pH5+gANK6Dbd/XjXrecntYQIz6aBFqyS5XfFlHtiyzZru0Wf0Of+eHfA7W\nrDRZZpxwyCmXfj6yj3Qqgi3aJPHIJ2D7T7VQWH2tTp6as1yXEX7iG4DAW76hBcTYoBUO+UJJJSy/\nPNejmFlYzSFjWOEwlVTM8Vd3xURDbP1eWCjUrQj//5J/BhQ8cbv++y3f0JpDujH6FsuZjkmWmzU3\n+XmWlFjhkM+0XAyX3aYdjm6hYBCBSz6rHz9xu/57dMBqDpaZS9NF2pzX8vpcj+SMxwqHfCZQBBfe\nkvwcIyCU0qURpCAm+9VimTEEimDjh3M9immBFQ7TARFdMRJCzV4sFotlMuSNcBCRK4A7gQBwn1Lq\nyzke0pmFERCVDd76D1ssFksS8kI4iEgA+A5wKdAGbBWRh5VSr+R2ZGcYIlaltlgsGSFfymdsAPYq\npfYrpUaAnwFvz/GYLBaLZcaSL8KhETjs+rvNORaBiPyNiGwTkW3t7e1TNjiLxWKZaeSLcIhXCEjF\nHFDqXqXUeqXU+ro6mwFpsVgs2SJfhEMb4K4hvADwUVDFYrFYLJkkX4TDVmCZiLSISDFwPfBwjsdk\nsVgsM5a8iFZSSo2JyC3Ab9GhrN9XSu3I8bAsFotlxpIXwgFAKfUI8Eiux2GxWCyW/DErWSwWiyWP\nEKVigoLOCESkHTiY5tMXAYcyNJRqoCePXifTr5WpucrHz5eP8wT5+fnyca7y9fNl6rWydU01KaVS\nh3sqpWbcD9Cewde6N59eJwuvlZG5ysfPl4/zlMefL+/mKo8/X6a+v5xeUzPVrNSdwdf6VZ69TqZf\nK1NzlY+fLx/nCfLz8+XjXOXr58vUa+X0mjpjzUqTQUS2KaXW53ocZwJ2rrxh58k7dq68ket5mqma\nw725HsAZhJ0rb9h58o6dK2/kdJ5mpOZgsVgsluTMVM3BYrFYLEmYFsJBRL4vIidF5GXXsdeIyFMi\n8pKI/EpEqpzjxSJyv3P8BRHZ7HrOOuf4XhH5pojEKwh4RpPBubpNRA6LSF8OPkbWycQ8iUi5iPw/\nEdklIjtEZFo2sMrgNfUb59gOEbnH6fMyrcjUXLme+7D7tTJKpkKlcvkDvB5YC7zsOrYVuNh5/AHg\ni87jm4H7ncf1wLNAgfP3M8AmdJXYR4E35/qz5fFcbQTmAX25/kz5Ok9AOfAG53gx8D/2mkp6TVU5\nvwX4BXB9rj9bvs6Vc+wdwE/cr5XJn2mhOSil/gx0Rh1eAfzZefx74Frn8VnAY87zTqLDxdaLyDz0\nxfmU0jP/I+DqbI99qsnEXDl/P62UOpb1AeeITMyTUmpAKfW4c3wEeA5dcXhakcFr6rRzTiFamE47\nh2im5kpEZgG3Al/K1linhXBIwMvAVc7jdxEuCf4C8HYRKRSRFmCd879GdOlwQ9yGQ9MUv3M1U0l7\nnkRkNvA2nJt9BpDWXInIb4GTQC/wH1M33JySzlx9Efg6MJCtQU1n4fAB4GYReRaoBEac499HL/zb\ngDuALcAYHhsOTVP8ztVMJa15EpFC4KfAN5VS+6d0xLkjrblSSl2ONleWAG+cygHnEF9zJSLnAUuV\nUg9lc1B5U5U10yildgGXAYjIcuAtzvEx4OPmPBHZAuwBuohU+WdMw6E05mpGMol5uhfYo5S6Y+pG\nm1smc00ppYZE5GF0H/nfT9WYc0Uac3UxsE5EWtFreL2I/EkptTmT45q2moOI1Du/C4B/Au5x/i4X\nkQrn8aXAmFLqFcd+3isiG50opb8G/is3o59a/M5VzgaaY9KZJxH5Erro2cdyMugc4XeuRGSW4/cz\nmtaVwK6cDH6KSWOtulspNV8p1Qy8Fng104IBponmICI/BTYDc0SkDfgsMEtEbnZO+SVwv/O4Hvit\niEwAR4AbXC/1YeAHQBk6WunRrA9+isnUXInIV4D3AOXO69ynlPrclHyIKSAT8yQiC4DPoBe55/Se\ng28rpe6bqs8xFWTomqoAHhaREnTDrz/iLJLTiQyuVdkfqxMSZbFYLBZLiGlrVrJYLBZL+ljhYLFY\nLJYYrHCwWCwWSwxWOFgsFoslBiscLBaLxRKDFQ4WiwdEZLaIfMR5PF9EZkppB8sMxYayWiweEJFm\n4NdKqdU5HorFMiVMiyQ4i2UK+DKwRES2o0sYrFJKrRaRG9HVewPAanQxtGJ0wtIwcKVSqlNElgDf\nAerQxdJucsomWCx5iTUrWSze+BSwTyl1HvDJqP+tRmeLbwBuAwaUUmuAp9BlWEDXV/qoUmod8Ang\nrikZtcWSJlZzsFgmz+NKqV50ba4e4FfO8ZeAc53a+xcCD0q4uWDJ1A/TYvGOFQ4Wy+QZdj2ecP09\ngb7HCoBuR+uwWM4IrFnJYvFGL7rWvm+cDmcHRORdAKJ5TSYHZ7FkGiscLBYPKKU6gCedZu5fTeMl\n3gt8UEReAHagexVYLHmLDWW1WCwWSwxWc7BYLBZLDFY4WCwWiyUGKxwsFovFEoMVDhaLxWKJwQoH\ni8ViscRghYPFYrFYYrDCwWKxWCwxWOFgsVgslhj+PxiZ0aJdfvKiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23448c89400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(tr + seas + res).plot()\n",
    "train1.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 102.2732 - val_loss: 100.8863\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.9297 - val_loss: 100.9631\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.8236 - val_loss: 101.3970\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9050 - val_loss: 102.2249\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.6483 - val_loss: 102.0645\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2841 - val_loss: 101.5605\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0014 - val_loss: 101.5059\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2904 - val_loss: 102.5554\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7660 - val_loss: 102.0075\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2210 - val_loss: 102.0272\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3433 - val_loss: 102.0292\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0218 - val_loss: 101.5982\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.0974 - val_loss: 101.7482\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.6949 - val_loss: 102.1118\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1233 - val_loss: 102.5541\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7295 - val_loss: 103.3643\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7525 - val_loss: 103.6370\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3125 - val_loss: 104.5105\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.3093 - val_loss: 105.7326\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0947 - val_loss: 106.0362\n",
      "MAPE:  337.0726170137134\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 102.8763 - val_loss: 96.3500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6082 - val_loss: 90.7805\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.5551 - val_loss: 84.3335\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.7410 - val_loss: 76.0865\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.6051 - val_loss: 67.8395\n",
      "Epoch 2/2\n",
      " - 0s - loss: 76.6847 - val_loss: 61.9406\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 74.3623 - val_loss: 60.3629\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.9192 - val_loss: 63.5441\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.6270 - val_loss: 58.5155\n",
      "Epoch 2/2\n",
      " - 0s - loss: 73.7647 - val_loss: 59.4879\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.3426 - val_loss: 59.2848\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.9435 - val_loss: 60.5488\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.1483 - val_loss: 58.7929\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.9386 - val_loss: 60.6393\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 71.9046 - val_loss: 61.0331\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.5753 - val_loss: 60.9325\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 72.5137 - val_loss: 57.7214\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.3031 - val_loss: 56.7397\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 71.6149 - val_loss: 57.5641\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.9353 - val_loss: 58.5912\n",
      "MAPE:  212.55418930643066\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 103.5140 - val_loss: 101.7751\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.2406 - val_loss: 101.7703\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4816 - val_loss: 101.5457\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.6636 - val_loss: 101.9307\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7998 - val_loss: 103.0309\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.1519 - val_loss: 102.9470\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9837 - val_loss: 103.1227\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4159 - val_loss: 104.2320\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.0271 - val_loss: 104.0979\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7070 - val_loss: 104.9367\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8900 - val_loss: 105.0453\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5415 - val_loss: 105.2722\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9436 - val_loss: 105.9313\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4114 - val_loss: 106.1147\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3019 - val_loss: 105.7773\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.8757 - val_loss: 106.0948\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9317 - val_loss: 106.5104\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7888 - val_loss: 106.5244\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.3336 - val_loss: 108.2576\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.0302 - val_loss: 107.9758\n",
      "MAPE:  33.35299416933379\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 100.5541 - val_loss: 106.3757\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8281 - val_loss: 104.8823\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.0427 - val_loss: 109.4517\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6112 - val_loss: 114.5638\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.6630 - val_loss: 117.9609\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.0594 - val_loss: 119.7815\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.0885 - val_loss: 122.1088\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.0699 - val_loss: 126.7061\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.8507 - val_loss: 132.1444\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.4734 - val_loss: 131.8464\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.0227 - val_loss: 129.3290\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.1828 - val_loss: 127.0741\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.1641 - val_loss: 127.0424\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.8356 - val_loss: 127.4376\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.0893 - val_loss: 129.6337\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.7187 - val_loss: 135.2201\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.5277 - val_loss: 134.8178\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.6083 - val_loss: 132.9938\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.0978 - val_loss: 131.3897\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.7924 - val_loss: 128.1284\n",
      "MAPE:  44.71762810161807\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 102.2990 - val_loss: 99.0511\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.6297 - val_loss: 100.7519\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1663 - val_loss: 101.9732\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0824 - val_loss: 103.2236\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2597 - val_loss: 104.5702\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.1101 - val_loss: 105.6677\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5490 - val_loss: 107.2341\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.0403 - val_loss: 108.5964\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.0386 - val_loss: 109.8857\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.1374 - val_loss: 110.8069\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.7972 - val_loss: 110.6277\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.2737 - val_loss: 111.0532\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.6411 - val_loss: 110.8526\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.9347 - val_loss: 110.4409\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1090 - val_loss: 110.8576\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6012 - val_loss: 111.9619\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.5444 - val_loss: 112.6485\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6796 - val_loss: 113.2636\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.4247 - val_loss: 113.3355\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.4832 - val_loss: 113.9666\n",
      "MAPE:  34.65730671320451\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 102.1522 - val_loss: 94.1796\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.0035 - val_loss: 92.6068\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.1658 - val_loss: 87.2420\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.0368 - val_loss: 84.2844\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.2307 - val_loss: 83.7562\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.7809 - val_loss: 82.8112\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.2766 - val_loss: 85.4249\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.5350 - val_loss: 83.5709\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 83.4558 - val_loss: 80.7883\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.8648 - val_loss: 81.7873\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.8387 - val_loss: 81.0354\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.3312 - val_loss: 82.0137\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.6736 - val_loss: 83.7795\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.0767 - val_loss: 83.7047\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.0817 - val_loss: 83.8984\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.9767 - val_loss: 85.3919\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.7505 - val_loss: 82.4489\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.5747 - val_loss: 81.7353\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.0381 - val_loss: 84.8254\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.1346 - val_loss: 85.6706\n",
      "MAPE:  213.6395243025414\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 2084882.7934 - val_loss: 1678274.2250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1904115.6523 - val_loss: 1185753.7297\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1408521.9506 - val_loss: 1089307.2563\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1196668.1157 - val_loss: 807384.4094\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 917856.8925 - val_loss: 715040.0375\n",
      "Epoch 2/2\n",
      " - 0s - loss: 700122.6427 - val_loss: 667449.3945\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 570020.4150 - val_loss: 1010452.3875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 787208.5854 - val_loss: 904967.7156\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 785916.4653 - val_loss: 760494.8301\n",
      "Epoch 2/2\n",
      " - 0s - loss: 884713.4652 - val_loss: 675763.4406\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 414006.9508 - val_loss: 916767.4875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 800984.4906 - val_loss: 874832.6594\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 842061.9403 - val_loss: 834145.4734\n",
      "Epoch 2/2\n",
      " - 0s - loss: 597323.6335 - val_loss: 784282.3750\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 598539.9279 - val_loss: 685559.5578\n",
      "Epoch 2/2\n",
      " - 0s - loss: 522713.2790 - val_loss: 773187.5750\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 468057.6708 - val_loss: 765001.2516\n",
      "Epoch 2/2\n",
      " - 0s - loss: 471688.9696 - val_loss: 724842.8031\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 390391.9044 - val_loss: 800743.7000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 587669.8917 - val_loss: 757642.9004\n",
      "MAPE:  29.73784230312802\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 2s - loss: 101.0390 - val_loss: 98.7833\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5381 - val_loss: 95.8627\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.8526 - val_loss: 92.7224\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1040 - val_loss: 88.7945\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.7307 - val_loss: 85.3788\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.3870 - val_loss: 82.2681\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81.8092 - val_loss: 88.4862\n",
      "Epoch 2/2\n",
      " - 0s - loss: 77.5349 - val_loss: 83.8379\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 75.3449 - val_loss: 84.7521\n",
      "Epoch 2/2\n",
      " - 0s - loss: 76.5740 - val_loss: 80.7289\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.8502 - val_loss: 85.3960\n",
      "Epoch 2/2\n",
      " - 0s - loss: 75.0973 - val_loss: 82.2730\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.0372 - val_loss: 87.6447\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.8168 - val_loss: 81.1633\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 72.2976 - val_loss: 86.3827\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.3738 - val_loss: 83.4120\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 71.4953 - val_loss: 82.3846\n",
      "Epoch 2/2\n",
      " - 0s - loss: 70.0717 - val_loss: 83.4056\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 68.8116 - val_loss: 83.6186\n",
      "Epoch 2/2\n",
      " - 0s - loss: 73.5974 - val_loss: 87.9486\n",
      "MAPE:  52.75268274343541\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 119.1741 - val_loss: 107.7357\n",
      "Epoch 2/2\n",
      " - 0s - loss: 109.8711 - val_loss: 101.3446\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 106.6865 - val_loss: 100.1898\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.4076 - val_loss: 99.2978\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 106.1103 - val_loss: 100.6066\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.9905 - val_loss: 103.5746\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 105.2967 - val_loss: 103.9961\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.8595 - val_loss: 106.8793\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.5661 - val_loss: 108.2274\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.0466 - val_loss: 113.2159\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 103.6087 - val_loss: 113.6803\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.2745 - val_loss: 114.4207\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.8516 - val_loss: 113.4501\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.4747 - val_loss: 114.4314\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.2742 - val_loss: 115.4773\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.0041 - val_loss: 115.9918\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.9166 - val_loss: 114.7166\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.2247 - val_loss: 114.7117\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.8189 - val_loss: 116.4267\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.6438 - val_loss: 116.6230\n",
      "MAPE:  50.09470086613976\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 103.8787 - val_loss: 103.9567\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.9836 - val_loss: 105.5112\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.2036 - val_loss: 106.6316\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1663 - val_loss: 107.3695\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7768 - val_loss: 107.3615\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5318 - val_loss: 108.1053\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9376 - val_loss: 108.1973\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5197 - val_loss: 108.1654\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8281 - val_loss: 109.1675\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6849 - val_loss: 109.9688\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.2171 - val_loss: 109.5462\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7345 - val_loss: 108.6282\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1468 - val_loss: 109.5598\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4636 - val_loss: 110.1298\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.6748 - val_loss: 109.9057\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5111 - val_loss: 111.0634\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.8664 - val_loss: 111.6267\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.8696 - val_loss: 111.2814\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9844 - val_loss: 112.9726\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5465 - val_loss: 112.5393\n",
      "MAPE:  22.745087401135596\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 924367.0341 - val_loss: 102.5005\n",
      "Epoch 2/2\n",
      " - 0s - loss: 955724.8445 - val_loss: 101.8455\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 479053.8042 - val_loss: 99.9642\n",
      "Epoch 2/2\n",
      " - 0s - loss: 521671.8736 - val_loss: 98.5527\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 366468.9153 - val_loss: 99.2897\n",
      "Epoch 2/2\n",
      " - 0s - loss: 565404.1432 - val_loss: 100.1640\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 467247.7570 - val_loss: 100.8103\n",
      "Epoch 2/2\n",
      " - 0s - loss: 430019.0810 - val_loss: 100.6253\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 437503.7202 - val_loss: 98.0792\n",
      "Epoch 2/2\n",
      " - 0s - loss: 462671.7496 - val_loss: 101.3059\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 284279.6699 - val_loss: 98.9139\n",
      "Epoch 2/2\n",
      " - 0s - loss: 427518.9554 - val_loss: 101.2636\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 319593.1767 - val_loss: 100.5188\n",
      "Epoch 2/2\n",
      " - 0s - loss: 392128.0150 - val_loss: 100.9961\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 287709.4923 - val_loss: 98.6358\n",
      "Epoch 2/2\n",
      " - 0s - loss: 255230.5617 - val_loss: 100.1190\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 342951.7573 - val_loss: 99.2871\n",
      "Epoch 2/2\n",
      " - 0s - loss: 299852.5547 - val_loss: 100.5314\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 255676.4436 - val_loss: 98.9915\n",
      "Epoch 2/2\n",
      " - 0s - loss: 323383.1582 - val_loss: 99.2546\n",
      "MAPE:  32.90830938880524\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 101.3558 - val_loss: 97.3824\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.7189 - val_loss: 95.1207\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4095 - val_loss: 92.2473\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0336 - val_loss: 89.9341\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.5004 - val_loss: 87.7747\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.3043 - val_loss: 88.6146\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.8126 - val_loss: 91.4305\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.7367 - val_loss: 102.3193\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.5691 - val_loss: 100.1852\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.8321 - val_loss: 102.8981\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.7078 - val_loss: 100.6971\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.4223 - val_loss: 103.6331\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.3563 - val_loss: 108.8205\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.4120 - val_loss: 101.4194\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.0562 - val_loss: 101.8538\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.8576 - val_loss: 105.5321\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.4959 - val_loss: 102.7645\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.6717 - val_loss: 97.3784\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81.3796 - val_loss: 98.4336\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.9363 - val_loss: 109.9085\n",
      "MAPE:  910.8153966299291\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 100.2292 - val_loss: 99.5439\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.9769 - val_loss: 99.7830\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.9789 - val_loss: 100.2353\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3483 - val_loss: 100.2190\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.2147 - val_loss: 100.0367\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.9790 - val_loss: 100.0866\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.5566 - val_loss: 99.9954\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.4755 - val_loss: 99.3704\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.3961 - val_loss: 99.6095\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.9879 - val_loss: 99.6524\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.6531 - val_loss: 99.2471\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.7703 - val_loss: 99.4011\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.1215 - val_loss: 99.7013\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.0135 - val_loss: 99.9276\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.7801 - val_loss: 100.7168\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.1272 - val_loss: 101.1709\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81.6750 - val_loss: 101.9512\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.2302 - val_loss: 102.2631\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.0033 - val_loss: 103.9573\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.0653 - val_loss: 104.8907\n",
      "MAPE:  41.86157766101559\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 109.4198 - val_loss: 102.8865\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.2334 - val_loss: 102.3139\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.9248 - val_loss: 108.7938\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.0237 - val_loss: 109.0076\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7263 - val_loss: 104.7569\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3914 - val_loss: 104.2959\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9171 - val_loss: 107.7727\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2694 - val_loss: 105.5532\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1637 - val_loss: 106.9367\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4436 - val_loss: 104.7240\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4050 - val_loss: 104.6900\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.2019 - val_loss: 109.8035\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1728 - val_loss: 106.2482\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.0488 - val_loss: 114.0273\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.7916 - val_loss: 110.1963\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1457 - val_loss: 109.7222\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1236 - val_loss: 111.4257\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1004 - val_loss: 108.0364\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.0564 - val_loss: 109.3836\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.0756 - val_loss: 108.1610\n",
      "MAPE:  97.73884498981835\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 104.8183 - val_loss: 96.7213\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.1716 - val_loss: 94.2988\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9960 - val_loss: 92.2539\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5288 - val_loss: 90.5169\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.5003 - val_loss: 89.3751\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.8604 - val_loss: 86.9031\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.2105 - val_loss: 86.7771\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.6261 - val_loss: 85.8663\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.2174 - val_loss: 86.4173\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.0594 - val_loss: 86.5569\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.7134 - val_loss: 85.9115\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.9954 - val_loss: 86.2130\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.5334 - val_loss: 84.5557\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.2883 - val_loss: 84.6724\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.6178 - val_loss: 85.2439\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.2262 - val_loss: 83.9060\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.3745 - val_loss: 83.4596\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.1300 - val_loss: 84.5390\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.7853 - val_loss: 83.8483\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.5739 - val_loss: 84.0291\n",
      "MAPE:  115.61154561450928\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 3s - loss: 160.4252 - val_loss: 163.7260\n",
      "Epoch 2/2\n",
      " - 0s - loss: 137.7798 - val_loss: 175.3971\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 136.3547 - val_loss: 187.7028\n",
      "Epoch 2/2\n",
      " - 0s - loss: 123.1575 - val_loss: 192.2888\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 116.8959 - val_loss: 193.1751\n",
      "Epoch 2/2\n",
      " - 0s - loss: 112.2323 - val_loss: 204.8255\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 105.6707 - val_loss: 217.6163\n",
      "Epoch 2/2\n",
      " - 0s - loss: 107.3575 - val_loss: 228.1734\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.9108 - val_loss: 234.7710\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.3392 - val_loss: 248.2362\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.3907 - val_loss: 259.4144\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.6856 - val_loss: 269.7484\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0215 - val_loss: 279.5061\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.5020 - val_loss: 289.2839\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.1275 - val_loss: 293.2618\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4414 - val_loss: 303.1283\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.0895 - val_loss: 306.7013\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1718 - val_loss: 318.9740\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.2415 - val_loss: 325.1039\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.0755 - val_loss: 327.4710\n",
      "MAPE:  258.62754046322294\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 102.6492 - val_loss: 102.7271\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.8766 - val_loss: 99.9027\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.8940 - val_loss: 98.0996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 0s - loss: 96.7621 - val_loss: 98.2273\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9926 - val_loss: 96.9888\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.2969 - val_loss: 97.1678\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9536 - val_loss: 97.5082\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.3776 - val_loss: 98.1356\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4569 - val_loss: 99.0406\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.2083 - val_loss: 98.7478\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.0867 - val_loss: 99.0058\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.2944 - val_loss: 97.8146\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.7405 - val_loss: 96.5910\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.1777 - val_loss: 97.4498\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.4420 - val_loss: 98.6626\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.3949 - val_loss: 96.5790\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1010 - val_loss: 96.1935\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.1278 - val_loss: 96.5258\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.2932 - val_loss: 96.5712\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.8984 - val_loss: 97.2345\n",
      "MAPE:  41.38332111056356\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 98.1872 - val_loss: 93.1020\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6639 - val_loss: 96.1778\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.9906 - val_loss: 100.0537\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.9393 - val_loss: 100.1418\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.3567 - val_loss: 99.4092\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.5184 - val_loss: 99.7543\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.4677 - val_loss: 100.7135\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.6667 - val_loss: 100.8320\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.7561 - val_loss: 100.2745\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.3656 - val_loss: 99.9186\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.4796 - val_loss: 99.8929\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.4819 - val_loss: 100.4507\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.1426 - val_loss: 101.0941\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.5022 - val_loss: 99.9585\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.1795 - val_loss: 99.7161\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.4971 - val_loss: 100.6576\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.2264 - val_loss: 101.1420\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.5059 - val_loss: 100.9295\n",
      "Train on 22 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.5484 - val_loss: 100.2074\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.3583 - val_loss: 100.5084\n",
      "MAPE:  30.906469014875153\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 101.6165 - val_loss: 97.1853\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4071 - val_loss: 96.6997\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8985 - val_loss: 96.5328\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6926 - val_loss: 96.0889\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1465 - val_loss: 95.4360\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.7009 - val_loss: 95.0713\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.7071 - val_loss: 95.2237\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.1013 - val_loss: 95.2826\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.0078 - val_loss: 95.1124\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.9763 - val_loss: 95.1237\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.4869 - val_loss: 94.8585\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.6250 - val_loss: 94.0109\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.6778 - val_loss: 93.5621\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.5435 - val_loss: 93.6592\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.5438 - val_loss: 93.9867\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.0556 - val_loss: 93.0906\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.4725 - val_loss: 94.3362\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.2829 - val_loss: 94.1449\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.3581 - val_loss: 94.1231\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.3375 - val_loss: 94.2793\n",
      "MAPE:  84.03525788149351\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 101.0381 - val_loss: 97.3426\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.7080 - val_loss: 93.9044\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.3809 - val_loss: 90.8628\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.7314 - val_loss: 87.0547\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.5101 - val_loss: 83.8100\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.9753 - val_loss: 78.3563\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.8499 - val_loss: 74.7325\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.1154 - val_loss: 68.0837\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.0999 - val_loss: 57.7226\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.3990 - val_loss: 57.8301\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 71.9361 - val_loss: 49.4627\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.1490 - val_loss: 50.7815\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 70.2426 - val_loss: 49.1176\n",
      "Epoch 2/2\n",
      " - 0s - loss: 71.8250 - val_loss: 53.0348\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 66.7100 - val_loss: 49.4556\n",
      "Epoch 2/2\n",
      " - 0s - loss: 70.6539 - val_loss: 47.3341\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 71.1691 - val_loss: 48.5835\n",
      "Epoch 2/2\n",
      " - 0s - loss: 69.0145 - val_loss: 50.3339\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 70.0679 - val_loss: 47.9102\n",
      "Epoch 2/2\n",
      " - 0s - loss: 71.2324 - val_loss: 49.4994\n",
      "MAPE:  67.524090664959\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 97.7941 - val_loss: 103.7440\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.1061 - val_loss: 101.7183\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.6565 - val_loss: 98.5933\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.2903 - val_loss: 96.5792\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.4707 - val_loss: 95.1450\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.3800 - val_loss: 94.7786\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.9594 - val_loss: 93.8922\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.7882 - val_loss: 93.9922\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.9498 - val_loss: 93.9215\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.2996 - val_loss: 93.4039\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.6776 - val_loss: 93.7783\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.3675 - val_loss: 94.0476\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.4400 - val_loss: 93.5163\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.2421 - val_loss: 92.0572\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.4303 - val_loss: 93.1914\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.6206 - val_loss: 93.1567\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.6126 - val_loss: 92.0055\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.1441 - val_loss: 92.2138\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.4053 - val_loss: 92.1084\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.6002 - val_loss: 92.0168\n",
      "MAPE:  99.9931800543388\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 97.5348 - val_loss: 107.0209\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.8269 - val_loss: 106.3951\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.3238 - val_loss: 104.6222\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.1325 - val_loss: 104.3004\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.8887 - val_loss: 103.7038\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.4177 - val_loss: 101.3204\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.9598 - val_loss: 102.4036\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.0101 - val_loss: 102.2549\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.2314 - val_loss: 102.4890\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.6244 - val_loss: 103.4430\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.0984 - val_loss: 101.7878\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.3723 - val_loss: 102.9225\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 86.7719 - val_loss: 103.3875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.6678 - val_loss: 101.7164\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.6072 - val_loss: 101.3521\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.5650 - val_loss: 100.4157\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.4279 - val_loss: 97.4947\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.0720 - val_loss: 89.4583\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.1849 - val_loss: 98.5488\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.0316 - val_loss: 96.9270\n",
      "MAPE:  229.27509788172023\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 98.8767 - val_loss: 96.7677\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.7186 - val_loss: 87.6048\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81.0472 - val_loss: 79.3589\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.6162 - val_loss: 74.4517\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 69.0354 - val_loss: 76.0102\n",
      "Epoch 2/2\n",
      " - 0s - loss: 68.0545 - val_loss: 76.3813\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 66.1401 - val_loss: 76.7335\n",
      "Epoch 2/2\n",
      " - 0s - loss: 68.6855 - val_loss: 76.0578\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 67.0641 - val_loss: 73.9976\n",
      "Epoch 2/2\n",
      " - 0s - loss: 67.2761 - val_loss: 73.5648\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 64.9626 - val_loss: 75.1970\n",
      "Epoch 2/2\n",
      " - 0s - loss: 67.2462 - val_loss: 73.0841\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 65.3985 - val_loss: 71.7828\n",
      "Epoch 2/2\n",
      " - 0s - loss: 66.6336 - val_loss: 74.1653\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 64.5470 - val_loss: 75.0393\n",
      "Epoch 2/2\n",
      " - 0s - loss: 64.7762 - val_loss: 74.0677\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 65.0114 - val_loss: 72.0096\n",
      "Epoch 2/2\n",
      " - 0s - loss: 63.9461 - val_loss: 77.5098\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 64.8524 - val_loss: 74.0899\n",
      "Epoch 2/2\n",
      " - 0s - loss: 65.4770 - val_loss: 75.6963\n",
      "MAPE:  52.836105565552316\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 97.7389 - val_loss: 91.5665\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.6808 - val_loss: 89.4012\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.0021 - val_loss: 88.1869\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.8199 - val_loss: 86.1219\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.9474 - val_loss: 84.6560\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.4208 - val_loss: 83.6593\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.1250 - val_loss: 82.7484\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.0166 - val_loss: 82.1239\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.5136 - val_loss: 82.5997\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.8449 - val_loss: 81.6704\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.4704 - val_loss: 80.0405\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.1388 - val_loss: 80.1973\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.7489 - val_loss: 79.7511\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.9793 - val_loss: 81.0785\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.2815 - val_loss: 78.9191\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.2147 - val_loss: 79.0356\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.8535 - val_loss: 79.4002\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.1433 - val_loss: 80.1293\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.9962 - val_loss: 78.0964\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.3117 - val_loss: 80.1716\n",
      "MAPE:  245.0476713132888\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 112.0327 - val_loss: 106.1358\n",
      "Epoch 2/2\n",
      " - 0s - loss: 110.7623 - val_loss: 105.1625\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.1972 - val_loss: 105.7149\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.4928 - val_loss: 105.1755\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.9337 - val_loss: 105.4402\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.8934 - val_loss: 103.6671\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.4233 - val_loss: 103.6176\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.3242 - val_loss: 102.9582\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.5179 - val_loss: 102.6887\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.3948 - val_loss: 103.0680\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.3060 - val_loss: 102.4073\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.1316 - val_loss: 101.6622\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.8799 - val_loss: 100.6718\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.3434 - val_loss: 101.3677\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.5822 - val_loss: 100.8283\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1126 - val_loss: 100.2609\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.7818 - val_loss: 101.0182\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.9721 - val_loss: 100.8505\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.7204 - val_loss: 101.3286\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.7732 - val_loss: 99.6978\n",
      "MAPE:  14.41860089709862\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 110.5556 - val_loss: 100.5667\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.7251 - val_loss: 100.9221\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1246 - val_loss: 102.4484\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.0224 - val_loss: 101.4615\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7093 - val_loss: 102.7324\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4457 - val_loss: 101.2378\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4013 - val_loss: 102.3411\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.3210 - val_loss: 103.4695\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4456 - val_loss: 102.8758\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5274 - val_loss: 103.1682\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.0920 - val_loss: 102.3111\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.4124 - val_loss: 103.7622\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.3212 - val_loss: 105.6815\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.7273 - val_loss: 104.4350\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.7886 - val_loss: 105.5637\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.5326 - val_loss: 105.3821\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.3635 - val_loss: 105.3063\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.8984 - val_loss: 104.1551\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1081 - val_loss: 104.7936\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.4030 - val_loss: 104.8984\n",
      "MAPE:  263.8804467735494\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 116.9254 - val_loss: 101.5019\n",
      "Epoch 2/2\n",
      " - 0s - loss: 107.7460 - val_loss: 100.4389\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 109.1962 - val_loss: 99.2344\n",
      "Epoch 2/2\n",
      " - 0s - loss: 107.7479 - val_loss: 99.9375\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 103.6406 - val_loss: 100.1234\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.5020 - val_loss: 100.5475\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.7042 - val_loss: 100.6487\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.1506 - val_loss: 101.2955\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.5978 - val_loss: 102.8766\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.4397 - val_loss: 101.8739\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.4194 - val_loss: 102.0397\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.8349 - val_loss: 103.3077\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.5281 - val_loss: 102.4528\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.4083 - val_loss: 103.2355\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.8628 - val_loss: 101.3977\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.7767 - val_loss: 102.2139\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9519 - val_loss: 102.8862\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.3950 - val_loss: 103.3720\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.6488 - val_loss: 102.3916\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.8194 - val_loss: 102.4424\n",
      "MAPE:  37.08467344328791\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 778477.6158 - val_loss: 2204100.4059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 0s - loss: 556979.4017 - val_loss: 1968738.9858\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 403786.8508 - val_loss: 1727097.8682\n",
      "Epoch 2/2\n",
      " - 0s - loss: 284936.2631 - val_loss: 1582953.0675\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 378765.5337 - val_loss: 1405193.8128\n",
      "Epoch 2/2\n",
      " - 0s - loss: 254087.9539 - val_loss: 1391666.3588\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 318789.4738 - val_loss: 1360797.3491\n",
      "Epoch 2/2\n",
      " - 0s - loss: 201470.5920 - val_loss: 1276527.2513\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 330636.0343 - val_loss: 1232519.6082\n",
      "Epoch 2/2\n",
      " - 0s - loss: 244352.1182 - val_loss: 1072425.6602\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 276785.9859 - val_loss: 998461.1463\n",
      "Epoch 2/2\n",
      " - 0s - loss: 297835.1820 - val_loss: 911210.8805\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 325901.0446 - val_loss: 838685.2036\n",
      "Epoch 2/2\n",
      " - 0s - loss: 290854.8118 - val_loss: 923865.6046\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 249135.6051 - val_loss: 772078.9281\n",
      "Epoch 2/2\n",
      " - 0s - loss: 196579.7428 - val_loss: 761183.0755\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 295768.6771 - val_loss: 910252.0801\n",
      "Epoch 2/2\n",
      " - 0s - loss: 198713.9950 - val_loss: 1024364.0406\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 202321.7824 - val_loss: 886161.9632\n",
      "Epoch 2/2\n",
      " - 0s - loss: 305432.0810 - val_loss: 943379.9197\n",
      "MAPE:  64.41380591393921\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 599941.6284 - val_loss: 591078.4706\n",
      "Epoch 2/2\n",
      " - 0s - loss: 513429.7860 - val_loss: 590041.4187\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 304371.0295 - val_loss: 399774.1224\n",
      "Epoch 2/2\n",
      " - 0s - loss: 236603.1188 - val_loss: 420796.9542\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 261625.7764 - val_loss: 416136.4866\n",
      "Epoch 2/2\n",
      " - 0s - loss: 251121.5849 - val_loss: 348633.6301\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 312791.2472 - val_loss: 286416.8815\n",
      "Epoch 2/2\n",
      " - 0s - loss: 241659.7793 - val_loss: 238604.8185\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 210941.8329 - val_loss: 202427.9496\n",
      "Epoch 2/2\n",
      " - 0s - loss: 273887.5255 - val_loss: 155530.3723\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 175640.2378 - val_loss: 197040.5282\n",
      "Epoch 2/2\n",
      " - 0s - loss: 333153.0232 - val_loss: 203489.7183\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 221767.8187 - val_loss: 183072.9767\n",
      "Epoch 2/2\n",
      " - 0s - loss: 339576.5674 - val_loss: 195166.1454\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 227955.8581 - val_loss: 172371.4053\n",
      "Epoch 2/2\n",
      " - 0s - loss: 254527.2498 - val_loss: 177077.5785\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 209436.5754 - val_loss: 234866.4139\n",
      "Epoch 2/2\n",
      " - 0s - loss: 313914.4233 - val_loss: 196451.9445\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 253532.3393 - val_loss: 155586.1048\n",
      "Epoch 2/2\n",
      " - 0s - loss: 282953.9317 - val_loss: 220110.8002\n",
      "MAPE:  14.083275295290774\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 107.1221 - val_loss: 99.2547\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.1582 - val_loss: 97.3841\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.6590 - val_loss: 103.5785\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.0095 - val_loss: 103.9927\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.7352 - val_loss: 102.9839\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2242 - val_loss: 103.0280\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.6848 - val_loss: 103.1299\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.0777 - val_loss: 107.9663\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.5061 - val_loss: 109.6704\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2821 - val_loss: 108.4743\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.2967 - val_loss: 112.4789\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5280 - val_loss: 110.1082\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.8726 - val_loss: 109.3935\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.6208 - val_loss: 108.8743\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7309 - val_loss: 108.9889\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.4710 - val_loss: 106.5691\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.0334 - val_loss: 106.6877\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.9683 - val_loss: 109.9366\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9957 - val_loss: 110.6086\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3132 - val_loss: 108.0479\n",
      "MAPE:  21.87491395694423\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 101.1524 - val_loss: 101.3107\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.9345 - val_loss: 98.7022\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1121 - val_loss: 95.7033\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5771 - val_loss: 91.5920\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.7226 - val_loss: 86.0949\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.6290 - val_loss: 80.4226\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.6825 - val_loss: 73.3104\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.0373 - val_loss: 66.0933\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 79.3518 - val_loss: 59.8315\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.3850 - val_loss: 62.0748\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.0325 - val_loss: 61.2483\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.3524 - val_loss: 62.7043\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 78.6100 - val_loss: 62.7073\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.2646 - val_loss: 64.0082\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 78.2517 - val_loss: 65.0977\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.1908 - val_loss: 62.5721\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.3305 - val_loss: 63.6140\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.1798 - val_loss: 63.3479\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.7630 - val_loss: 64.0265\n",
      "Epoch 2/2\n",
      " - 0s - loss: 78.3649 - val_loss: 62.8524\n",
      "MAPE:  214.9923190516511\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 102.3088 - val_loss: 103.7006\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1929 - val_loss: 102.7267\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3976 - val_loss: 101.6985\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1863 - val_loss: 100.8457\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.3596 - val_loss: 99.9159\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.3709 - val_loss: 99.1384\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.6717 - val_loss: 98.7445\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2299 - val_loss: 98.2778\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.9433 - val_loss: 98.3319\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.3375 - val_loss: 97.9759\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.9180 - val_loss: 98.0361\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.3987 - val_loss: 97.9993\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4403 - val_loss: 97.7182\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.9002 - val_loss: 97.8437\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.7868 - val_loss: 97.5980\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.7598 - val_loss: 97.9722\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.8410 - val_loss: 97.7782\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.1033 - val_loss: 97.6613\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.5691 - val_loss: 97.5126\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5425 - val_loss: 97.7907\n",
      "MAPE:  219.4915353012889\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 107.8300 - val_loss: 97.3157\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.1249 - val_loss: 96.1961\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.8590 - val_loss: 95.1339\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1649 - val_loss: 94.3305\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.6796 - val_loss: 93.8904\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1002 - val_loss: 93.1878\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 96.3111 - val_loss: 92.4955\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5718 - val_loss: 91.7581\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.0116 - val_loss: 91.5234\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.9257 - val_loss: 91.7946\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.5381 - val_loss: 91.5035\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.2888 - val_loss: 91.4144\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4394 - val_loss: 91.3306\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1069 - val_loss: 91.3803\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.5410 - val_loss: 91.7385\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1279 - val_loss: 91.6137\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.5383 - val_loss: 91.2197\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.0836 - val_loss: 89.9816\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.6070 - val_loss: 91.1119\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.9984 - val_loss: 91.6151\n",
      "MAPE:  103.6688816566093\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 103.6528 - val_loss: 120.8981\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.1237 - val_loss: 118.4848\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.3798 - val_loss: 116.2457\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6505 - val_loss: 115.7644\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.7696 - val_loss: 115.1648\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9875 - val_loss: 113.7464\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.0659 - val_loss: 113.9683\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.3045 - val_loss: 112.3447\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.8097 - val_loss: 112.0939\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3461 - val_loss: 112.4435\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.1565 - val_loss: 111.7331\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2188 - val_loss: 111.0790\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3497 - val_loss: 112.0128\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.9709 - val_loss: 111.4323\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.8386 - val_loss: 111.8067\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1664 - val_loss: 114.5815\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.0680 - val_loss: 114.3601\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.2236 - val_loss: 114.6788\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8414 - val_loss: 115.0818\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0742 - val_loss: 117.5980\n",
      "MAPE:  84.9346967002043\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 126.5549 - val_loss: 102.9362\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.0997 - val_loss: 99.4405\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.1730 - val_loss: 96.4557\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.4644 - val_loss: 95.0217\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.3398 - val_loss: 94.0627\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8333 - val_loss: 92.4980\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.0374 - val_loss: 90.2130\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.8290 - val_loss: 89.1064\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.5915 - val_loss: 86.8727\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.5540 - val_loss: 85.2797\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.7675 - val_loss: 83.7723\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.0488 - val_loss: 82.8640\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.8145 - val_loss: 81.3980\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.0307 - val_loss: 80.1830\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.4086 - val_loss: 79.6643\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.2524 - val_loss: 79.1739\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.0851 - val_loss: 78.2004\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.8021 - val_loss: 76.4801\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.1205 - val_loss: 76.4990\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.1640 - val_loss: 75.0415\n",
      "MAPE:  154.4154167444984\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 101.6609 - val_loss: 98.7423\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.6751 - val_loss: 98.4652\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7448 - val_loss: 96.4732\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5276 - val_loss: 96.8375\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3117 - val_loss: 94.3669\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6307 - val_loss: 94.7335\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.9350 - val_loss: 95.3234\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.1062 - val_loss: 97.1256\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.8048 - val_loss: 93.5141\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6576 - val_loss: 95.6886\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.0059 - val_loss: 100.4502\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.1553 - val_loss: 90.3592\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.1524 - val_loss: 91.9977\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.7643 - val_loss: 88.2138\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.5937 - val_loss: 90.5740\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.9754 - val_loss: 91.2656\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.6373 - val_loss: 89.5303\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.8992 - val_loss: 85.7006\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.9726 - val_loss: 93.0747\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.4205 - val_loss: 84.3063\n",
      "MAPE:  58.10419974298097\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 97.6792 - val_loss: 108.2716\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.9427 - val_loss: 109.1428\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.7934 - val_loss: 110.1420\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.1014 - val_loss: 109.3841\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.7749 - val_loss: 107.6112\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.2392 - val_loss: 106.7594\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.1590 - val_loss: 105.8781\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.1223 - val_loss: 105.1379\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.8872 - val_loss: 105.1998\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.2224 - val_loss: 106.9099\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.3402 - val_loss: 107.0547\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.8667 - val_loss: 108.2324\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.2134 - val_loss: 108.7912\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.0532 - val_loss: 108.6508\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.1324 - val_loss: 110.7363\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.4997 - val_loss: 110.2884\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81.2452 - val_loss: 111.8827\n",
      "Epoch 2/2\n",
      " - 0s - loss: 80.5457 - val_loss: 112.9254\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 78.9508 - val_loss: 114.0430\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.3189 - val_loss: 114.9425\n",
      "MAPE:  93.94943100028634\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 97.1229 - val_loss: 87.3077\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.2750 - val_loss: 76.6404\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.3144 - val_loss: 68.8627\n",
      "Epoch 2/2\n",
      " - 0s - loss: 80.2754 - val_loss: 65.2701\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 78.3268 - val_loss: 64.4602\n",
      "Epoch 2/2\n",
      " - 0s - loss: 76.9887 - val_loss: 64.5759\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.0185 - val_loss: 65.1730\n",
      "Epoch 2/2\n",
      " - 0s - loss: 75.0460 - val_loss: 66.1308\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 75.3860 - val_loss: 66.8497\n",
      "Epoch 2/2\n",
      " - 0s - loss: 76.0069 - val_loss: 67.9471\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 75.2604 - val_loss: 67.8253\n",
      "Epoch 2/2\n",
      " - 0s - loss: 75.2815 - val_loss: 68.5697\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 74.8739 - val_loss: 68.1441\n",
      "Epoch 2/2\n",
      " - 0s - loss: 75.5069 - val_loss: 67.7471\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 74.3765 - val_loss: 67.2688\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.6129 - val_loss: 67.5341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 74.4890 - val_loss: 67.2906\n",
      "Epoch 2/2\n",
      " - 0s - loss: 75.1037 - val_loss: 67.4878\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.8318 - val_loss: 68.2850\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.8651 - val_loss: 68.0087\n",
      "MAPE:  87.94635449683115\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 108.6081 - val_loss: 101.7515\n",
      "Epoch 2/2\n",
      " - 0s - loss: 115.3265 - val_loss: 101.6689\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 106.7869 - val_loss: 102.3168\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.8794 - val_loss: 102.3257\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 103.0266 - val_loss: 103.6087\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.0719 - val_loss: 101.6231\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.6053 - val_loss: 101.4306\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.5141 - val_loss: 100.6823\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.2475 - val_loss: 102.5603\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.2641 - val_loss: 101.1482\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.4568 - val_loss: 102.1438\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.0792 - val_loss: 101.5847\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.9500 - val_loss: 100.8496\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.2822 - val_loss: 101.5795\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3713 - val_loss: 102.0119\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.6670 - val_loss: 101.8194\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.6337 - val_loss: 102.0899\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6606 - val_loss: 101.8046\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.2558 - val_loss: 102.2712\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.4490 - val_loss: 103.6835\n",
      "MAPE:  17.922505687892098\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 2890858.1948 - val_loss: 107.8216\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1460164.3963 - val_loss: 105.6929\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1378738.5568 - val_loss: 106.4253\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1008930.2525 - val_loss: 107.5869\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 937771.5985 - val_loss: 106.4040\n",
      "Epoch 2/2\n",
      " - 0s - loss: 564078.4652 - val_loss: 107.4542\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1080074.2004 - val_loss: 106.3875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 565388.3853 - val_loss: 104.2556\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 570926.3631 - val_loss: 106.1954\n",
      "Epoch 2/2\n",
      " - 0s - loss: 615544.6908 - val_loss: 103.5694\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 577448.8622 - val_loss: 103.7747\n",
      "Epoch 2/2\n",
      " - 0s - loss: 539879.0134 - val_loss: 103.2460\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 516324.7865 - val_loss: 103.8638\n",
      "Epoch 2/2\n",
      " - 0s - loss: 458811.6819 - val_loss: 103.8118\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 518580.6728 - val_loss: 101.5154\n",
      "Epoch 2/2\n",
      " - 0s - loss: 482830.4242 - val_loss: 102.7264\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 355361.5744 - val_loss: 104.5046\n",
      "Epoch 2/2\n",
      " - 0s - loss: 396527.0769 - val_loss: 101.5507\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 428824.9419 - val_loss: 102.4926\n",
      "Epoch 2/2\n",
      " - 0s - loss: 694402.0297 - val_loss: 101.1887\n",
      "MAPE:  59.69570301855961\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 105.8598 - val_loss: 97.4327\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.2426 - val_loss: 98.2635\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 100.7840 - val_loss: 98.9630\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.4040 - val_loss: 99.0712\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.7226 - val_loss: 99.1463\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.4973 - val_loss: 99.4891\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.8757 - val_loss: 98.6737\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3283 - val_loss: 98.4292\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2410 - val_loss: 98.2084\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2968 - val_loss: 98.0042\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1867 - val_loss: 98.9711\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7880 - val_loss: 99.4381\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.0053 - val_loss: 99.3887\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.1896 - val_loss: 99.8768\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7205 - val_loss: 100.1744\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6279 - val_loss: 100.6021\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8674 - val_loss: 100.2947\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.1120 - val_loss: 100.4763\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7869 - val_loss: 100.5793\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.3793 - val_loss: 101.5329\n",
      "MAPE:  36.39197494214381\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 107.4163 - val_loss: 95.3670\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.3569 - val_loss: 95.9187\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.2567 - val_loss: 94.7590\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.7881 - val_loss: 94.0745\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.0626 - val_loss: 95.0720\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.1044 - val_loss: 96.4000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3648 - val_loss: 94.7011\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6226 - val_loss: 96.2459\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1853 - val_loss: 92.9117\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6003 - val_loss: 93.3753\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.6706 - val_loss: 95.6875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4228 - val_loss: 93.9522\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.0441 - val_loss: 94.2243\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.7792 - val_loss: 96.3419\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.5965 - val_loss: 92.4239\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.3399 - val_loss: 93.1722\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.0706 - val_loss: 92.6052\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.2167 - val_loss: 92.5482\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1987 - val_loss: 92.3118\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.0251 - val_loss: 90.5864\n",
      "MAPE:  115.38567537912516\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 102.4482 - val_loss: 97.2153\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5414 - val_loss: 95.8110\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.4267 - val_loss: 95.8048\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.8004 - val_loss: 96.2806\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.1273 - val_loss: 96.2210\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.5055 - val_loss: 95.8956\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.3982 - val_loss: 96.0885\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.8466 - val_loss: 95.8923\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.2570 - val_loss: 95.7213\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.4877 - val_loss: 95.5333\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.8765 - val_loss: 95.7664\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.4616 - val_loss: 95.2947\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.7481 - val_loss: 95.0886\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.8008 - val_loss: 95.1673\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.8705 - val_loss: 94.7634\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.9929 - val_loss: 94.7608\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.1685 - val_loss: 94.5451\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.7900 - val_loss: 94.3759\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.7020 - val_loss: 95.1837\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.8312 - val_loss: 94.9643\n",
      "MAPE:  73.7473051456966\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 110.6079 - val_loss: 105.8661\n",
      "Epoch 2/2\n",
      " - 0s - loss: 110.2730 - val_loss: 102.5238\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 106.0966 - val_loss: 102.9366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 0s - loss: 102.2263 - val_loss: 103.4709\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 103.1491 - val_loss: 100.5958\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.7199 - val_loss: 99.6021\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.2125 - val_loss: 100.9800\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6818 - val_loss: 98.5928\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.9785 - val_loss: 99.5311\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1793 - val_loss: 101.0744\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.8947 - val_loss: 100.9560\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.2491 - val_loss: 99.8760\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.9786 - val_loss: 97.4832\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2199 - val_loss: 96.3825\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.3503 - val_loss: 98.2187\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2935 - val_loss: 100.4520\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.7254 - val_loss: 97.4422\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6292 - val_loss: 98.2790\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3173 - val_loss: 98.7380\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2727 - val_loss: 96.1115\n",
      "MAPE:  72.2023643401802\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 104.5139 - val_loss: 116.4119\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.4841 - val_loss: 113.1622\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.7972 - val_loss: 109.2715\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1491 - val_loss: 107.2550\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.2638 - val_loss: 109.2198\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.0869 - val_loss: 108.5252\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.5324 - val_loss: 110.1899\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5352 - val_loss: 110.5539\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.2130 - val_loss: 112.0742\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.9170 - val_loss: 113.3757\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.5941 - val_loss: 117.9018\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9212 - val_loss: 119.6031\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.0269 - val_loss: 120.7631\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.7959 - val_loss: 121.6867\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4401 - val_loss: 124.4560\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1563 - val_loss: 126.1050\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7912 - val_loss: 131.6433\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3983 - val_loss: 133.4096\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1800 - val_loss: 133.0527\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7274 - val_loss: 136.8747\n",
      "MAPE:  137.56594242966463\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 113.2927 - val_loss: 98.7529\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.8127 - val_loss: 101.8957\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.6783 - val_loss: 102.6305\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.8976 - val_loss: 101.0485\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.8279 - val_loss: 101.0476\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.4435 - val_loss: 101.2842\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.6249 - val_loss: 100.0813\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5470 - val_loss: 99.8154\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.1060 - val_loss: 102.1153\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5671 - val_loss: 101.5887\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.9324 - val_loss: 101.5246\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5371 - val_loss: 100.1317\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.5176 - val_loss: 101.7080\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0144 - val_loss: 102.7099\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0747 - val_loss: 102.0320\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2196 - val_loss: 102.1970\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.7160 - val_loss: 102.5391\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.1137 - val_loss: 101.0272\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.5440 - val_loss: 101.3190\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5720 - val_loss: 99.8057\n",
      "MAPE:  14.857844398917832\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 96.6432 - val_loss: 89.7970\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.2136 - val_loss: 70.7588\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 62.5797 - val_loss: 48.6683\n",
      "Epoch 2/2\n",
      " - 0s - loss: 53.0255 - val_loss: 37.1376\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 40.8044 - val_loss: 32.2237\n",
      "Epoch 2/2\n",
      " - 0s - loss: 37.8100 - val_loss: 32.4421\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 34.7674 - val_loss: 31.2204\n",
      "Epoch 2/2\n",
      " - 0s - loss: 35.0770 - val_loss: 31.8850\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 32.0645 - val_loss: 31.2742\n",
      "Epoch 2/2\n",
      " - 0s - loss: 33.3520 - val_loss: 31.9294\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 30.7409 - val_loss: 31.6823\n",
      "Epoch 2/2\n",
      " - 0s - loss: 32.3579 - val_loss: 32.1639\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 30.1823 - val_loss: 31.9756\n",
      "Epoch 2/2\n",
      " - 0s - loss: 32.1227 - val_loss: 31.7127\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 29.8566 - val_loss: 31.8148\n",
      "Epoch 2/2\n",
      " - 0s - loss: 31.7532 - val_loss: 32.8053\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 29.4425 - val_loss: 31.7054\n",
      "Epoch 2/2\n",
      " - 0s - loss: 31.5510 - val_loss: 32.5491\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 30.0859 - val_loss: 31.8535\n",
      "Epoch 2/2\n",
      " - 0s - loss: 32.7642 - val_loss: 32.3534\n",
      "MAPE:  153.16523425976283\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 969210.7502 - val_loss: 95.9773\n",
      "Epoch 2/2\n",
      " - 0s - loss: 743152.1594 - val_loss: 96.2582\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 614990.5018 - val_loss: 96.1734\n",
      "Epoch 2/2\n",
      " - 0s - loss: 553948.5039 - val_loss: 96.2939\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 425000.4310 - val_loss: 96.4305\n",
      "Epoch 2/2\n",
      " - 0s - loss: 403987.2921 - val_loss: 97.0522\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 461275.5005 - val_loss: 97.0818\n",
      "Epoch 2/2\n",
      " - 0s - loss: 320440.1235 - val_loss: 96.9933\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 477344.4738 - val_loss: 97.1862\n",
      "Epoch 2/2\n",
      " - 0s - loss: 282667.6416 - val_loss: 96.9595\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 388488.3318 - val_loss: 97.0536\n",
      "Epoch 2/2\n",
      " - 0s - loss: 251798.9611 - val_loss: 97.3768\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 372736.5334 - val_loss: 97.2718\n",
      "Epoch 2/2\n",
      " - 0s - loss: 277663.3192 - val_loss: 97.4151\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 459305.8483 - val_loss: 97.3019\n",
      "Epoch 2/2\n",
      " - 0s - loss: 200549.9106 - val_loss: 96.7226\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 333545.6336 - val_loss: 97.2607\n",
      "Epoch 2/2\n",
      " - 0s - loss: 309677.5472 - val_loss: 97.4134\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 229516.2215 - val_loss: 97.2528\n",
      "Epoch 2/2\n",
      " - 0s - loss: 295357.6609 - val_loss: 97.2926\n",
      "MAPE:  13.419765597385902\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 100.1642 - val_loss: 110.6044\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.6511 - val_loss: 108.0681\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.8590 - val_loss: 107.3398\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.9259 - val_loss: 107.6451\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7775 - val_loss: 106.3763\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.9009 - val_loss: 107.4092\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1743 - val_loss: 107.0910\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.1010 - val_loss: 106.2934\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.8473 - val_loss: 106.0075\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6609 - val_loss: 106.7325\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.1239 - val_loss: 108.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 0s - loss: 94.1215 - val_loss: 106.3598\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.8122 - val_loss: 108.5506\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1122 - val_loss: 108.7810\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.3194 - val_loss: 107.3181\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5929 - val_loss: 108.3299\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.7386 - val_loss: 111.5409\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.2252 - val_loss: 113.5379\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.6116 - val_loss: 115.2366\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.8126 - val_loss: 111.2253\n",
      "MAPE:  97.54161314664488\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 91.0552 - val_loss: 79.2400\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.0842 - val_loss: 44.3159\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 53.9496 - val_loss: 36.2140\n",
      "Epoch 2/2\n",
      " - 0s - loss: 51.9439 - val_loss: 39.2754\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 46.3543 - val_loss: 27.8343\n",
      "Epoch 2/2\n",
      " - 0s - loss: 47.1615 - val_loss: 30.7427\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 46.8296 - val_loss: 30.2723\n",
      "Epoch 2/2\n",
      " - 0s - loss: 48.4163 - val_loss: 34.8419\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 44.2650 - val_loss: 31.4053\n",
      "Epoch 2/2\n",
      " - 0s - loss: 46.8307 - val_loss: 34.6854\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 44.7742 - val_loss: 33.8091\n",
      "Epoch 2/2\n",
      " - 0s - loss: 45.8274 - val_loss: 35.4563\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 44.2560 - val_loss: 33.4812\n",
      "Epoch 2/2\n",
      " - 0s - loss: 45.9967 - val_loss: 35.1752\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 43.9277 - val_loss: 32.8915\n",
      "Epoch 2/2\n",
      " - 0s - loss: 46.0812 - val_loss: 36.6669\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 43.0558 - val_loss: 33.3266\n",
      "Epoch 2/2\n",
      " - 0s - loss: 45.6203 - val_loss: 35.7644\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 43.6426 - val_loss: 34.7054\n",
      "Epoch 2/2\n",
      " - 0s - loss: 45.3987 - val_loss: 36.0281\n",
      "MAPE:  110.68810442384651\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 100.6390 - val_loss: 104.1485\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.5424 - val_loss: 103.5552\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.4854 - val_loss: 104.5656\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5780 - val_loss: 104.3449\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.0149 - val_loss: 102.7502\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1656 - val_loss: 102.7500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.0418 - val_loss: 102.1598\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0027 - val_loss: 101.5646\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7588 - val_loss: 100.9278\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6012 - val_loss: 100.9199\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1303 - val_loss: 101.3875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.9509 - val_loss: 100.4740\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1672 - val_loss: 101.3149\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6540 - val_loss: 101.3988\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.1529 - val_loss: 101.1437\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8266 - val_loss: 101.2790\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.0643 - val_loss: 101.1101\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.8317 - val_loss: 100.2503\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9128 - val_loss: 101.1441\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7078 - val_loss: 101.2926\n",
      "MAPE:  45.755821290894374\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 99.6108 - val_loss: 98.7104\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.8748 - val_loss: 98.9650\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.1730 - val_loss: 99.0723\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.6654 - val_loss: 98.3670\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7110 - val_loss: 98.3400\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0176 - val_loss: 97.8053\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.8780 - val_loss: 98.1956\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1589 - val_loss: 98.5170\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.2477 - val_loss: 98.2946\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0363 - val_loss: 97.3266\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7407 - val_loss: 97.7639\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2857 - val_loss: 97.6069\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3010 - val_loss: 97.4976\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.1777 - val_loss: 97.1848\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.7918 - val_loss: 97.3739\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5561 - val_loss: 97.5220\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4434 - val_loss: 96.8511\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5719 - val_loss: 96.7782\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.7463 - val_loss: 96.6826\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.2538 - val_loss: 96.3546\n",
      "MAPE:  22.997131209617365\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 100.4425 - val_loss: 98.6406\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.1257 - val_loss: 97.8465\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.5771 - val_loss: 98.0218\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.0578 - val_loss: 99.2945\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.6552 - val_loss: 99.5790\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.8208 - val_loss: 100.2298\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.3838 - val_loss: 100.4020\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.9454 - val_loss: 100.5601\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.6616 - val_loss: 100.6347\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.4482 - val_loss: 101.3587\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.1223 - val_loss: 101.3146\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.1491 - val_loss: 101.5735\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.5963 - val_loss: 101.2857\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.3860 - val_loss: 100.9865\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.5924 - val_loss: 101.4930\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.4570 - val_loss: 100.8582\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.9687 - val_loss: 101.0324\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.6381 - val_loss: 101.1296\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.2688 - val_loss: 101.5302\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.9562 - val_loss: 101.1484\n",
      "MAPE:  11.618025324782703\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 106.6136 - val_loss: 104.1885\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.2535 - val_loss: 106.5921\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3941 - val_loss: 106.8975\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.9027 - val_loss: 108.0239\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5269 - val_loss: 109.9717\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4261 - val_loss: 112.0512\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.3440 - val_loss: 111.5857\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6184 - val_loss: 111.0253\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1733 - val_loss: 110.8955\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.3065 - val_loss: 113.0210\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1239 - val_loss: 113.4095\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6363 - val_loss: 113.1671\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.7365 - val_loss: 114.0648\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6413 - val_loss: 113.8391\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.8152 - val_loss: 112.1309\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5635 - val_loss: 113.2396\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.9270 - val_loss: 115.1318\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.2810 - val_loss: 116.2899\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.9735 - val_loss: 115.3537\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4755 - val_loss: 116.7468\n",
      "MAPE:  16.960867126537696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 141.9299 - val_loss: 102.7120\n",
      "Epoch 2/2\n",
      " - 0s - loss: 113.0055 - val_loss: 104.9080\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 111.7161 - val_loss: 102.5239\n",
      "Epoch 2/2\n",
      " - 0s - loss: 107.7918 - val_loss: 99.7424\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 108.0261 - val_loss: 102.0107\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.5302 - val_loss: 98.2288\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.4841 - val_loss: 102.7535\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.7121 - val_loss: 98.0149\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 105.0926 - val_loss: 102.1474\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.0795 - val_loss: 100.3628\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.6410 - val_loss: 100.4305\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.9702 - val_loss: 102.6917\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.4237 - val_loss: 100.3422\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.8694 - val_loss: 99.4280\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.4944 - val_loss: 101.2685\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.4575 - val_loss: 99.8134\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.3451 - val_loss: 99.6136\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2520 - val_loss: 98.6716\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.6153 - val_loss: 101.1862\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4133 - val_loss: 97.1406\n",
      "MAPE:  24.28815533392402\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 100.2286 - val_loss: 101.1318\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.3622 - val_loss: 102.5744\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.7247 - val_loss: 103.7413\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2838 - val_loss: 105.1193\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.5917 - val_loss: 106.1505\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.7630 - val_loss: 106.7709\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.8670 - val_loss: 108.0203\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.9881 - val_loss: 108.6492\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.5285 - val_loss: 109.2793\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6378 - val_loss: 110.5454\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1690 - val_loss: 110.9489\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0112 - val_loss: 110.7812\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.2666 - val_loss: 112.1475\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7480 - val_loss: 112.7271\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3601 - val_loss: 111.9887\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3374 - val_loss: 112.9872\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9450 - val_loss: 112.9761\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8989 - val_loss: 111.7889\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.6076 - val_loss: 111.9935\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.2357 - val_loss: 112.6877\n",
      "MAPE:  42.03611479164013\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 102.7294 - val_loss: 124.2272\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.2959 - val_loss: 127.5585\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.5527 - val_loss: 128.3847\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.0549 - val_loss: 127.6002\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.9187 - val_loss: 130.9648\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9881 - val_loss: 130.1973\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.8445 - val_loss: 127.6696\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.3679 - val_loss: 125.3067\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.4624 - val_loss: 126.0793\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3480 - val_loss: 126.4711\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3043 - val_loss: 126.1756\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1136 - val_loss: 128.9011\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4608 - val_loss: 129.6504\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.1309 - val_loss: 129.1728\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.8361 - val_loss: 125.7030\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5201 - val_loss: 125.6608\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.1273 - val_loss: 128.2048\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4189 - val_loss: 130.2784\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.8063 - val_loss: 131.6115\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4421 - val_loss: 132.4998\n",
      "MAPE:  33.68086488315408\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 100.5192 - val_loss: 98.4350\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4281 - val_loss: 98.2544\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.6361 - val_loss: 98.0948\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0694 - val_loss: 98.2627\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3679 - val_loss: 98.4308\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4811 - val_loss: 98.2071\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.7135 - val_loss: 98.8151\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.9759 - val_loss: 99.1357\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.3094 - val_loss: 98.5923\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1294 - val_loss: 98.8156\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.5121 - val_loss: 99.0355\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.9636 - val_loss: 99.7833\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.3727 - val_loss: 99.3100\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.9278 - val_loss: 100.1321\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.7826 - val_loss: 99.8789\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.8793 - val_loss: 99.5961\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.8139 - val_loss: 100.0684\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.9078 - val_loss: 100.3155\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.6802 - val_loss: 100.5210\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.3024 - val_loss: 101.2842\n",
      "MAPE:  74.9284711615097\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 101.2901 - val_loss: 97.7584\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.3097 - val_loss: 97.8124\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.7038 - val_loss: 97.3521\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2657 - val_loss: 96.0962\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.6546 - val_loss: 95.5441\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8113 - val_loss: 94.8223\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9756 - val_loss: 94.4469\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5480 - val_loss: 94.0939\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4996 - val_loss: 92.8796\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4330 - val_loss: 91.8976\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.5058 - val_loss: 90.7345\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6306 - val_loss: 89.4279\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.2485 - val_loss: 88.0092\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.1711 - val_loss: 86.3194\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.6136 - val_loss: 83.4902\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.2038 - val_loss: 84.7500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.4863 - val_loss: 82.7663\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.1825 - val_loss: 81.1429\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.7203 - val_loss: 78.9514\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.7126 - val_loss: 79.1738\n",
      "MAPE:  242.4438366534876\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 102.6592 - val_loss: 97.8435\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5658 - val_loss: 96.4718\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9589 - val_loss: 94.1895\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.7088 - val_loss: 91.9305\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.4588 - val_loss: 89.7536\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.6182 - val_loss: 86.9151\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.2080 - val_loss: 82.7991\n",
      "Epoch 2/2\n",
      " - 0s - loss: 80.3860 - val_loss: 78.7297\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.2173 - val_loss: 71.1384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 0s - loss: 75.3647 - val_loss: 64.6248\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 70.0794 - val_loss: 54.9238\n",
      "Epoch 2/2\n",
      " - 0s - loss: 75.3425 - val_loss: 52.5604\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 65.2992 - val_loss: 43.7233\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.2137 - val_loss: 45.4581\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 67.2759 - val_loss: 40.6007\n",
      "Epoch 2/2\n",
      " - 0s - loss: 69.6336 - val_loss: 41.5711\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 62.5765 - val_loss: 40.3448\n",
      "Epoch 2/2\n",
      " - 0s - loss: 78.9223 - val_loss: 40.1104\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 61.3061 - val_loss: 37.4863\n",
      "Epoch 2/2\n",
      " - 0s - loss: 68.2693 - val_loss: 37.0550\n",
      "MAPE:  72.81702066915605\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 105.6512 - val_loss: 136.7085\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.1461 - val_loss: 144.7215\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.0081 - val_loss: 143.1014\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.2375 - val_loss: 144.8965\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.8407 - val_loss: 151.7793\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.8554 - val_loss: 149.9099\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.3858 - val_loss: 145.8435\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.0064 - val_loss: 153.2824\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.8641 - val_loss: 155.0536\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.0570 - val_loss: 153.6222\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.9566 - val_loss: 158.4971\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.9336 - val_loss: 156.8823\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.6164 - val_loss: 165.4280\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.3604 - val_loss: 163.0348\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.4259 - val_loss: 161.8060\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.8277 - val_loss: 170.0649\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.8460 - val_loss: 171.2195\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.3967 - val_loss: 170.1478\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.8503 - val_loss: 168.3695\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.7499 - val_loss: 179.2703\n",
      "MAPE:  38.460858160769206\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 104.7112 - val_loss: 118.7468\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3839 - val_loss: 115.7969\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9386 - val_loss: 114.7841\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7772 - val_loss: 115.3544\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.8776 - val_loss: 116.2306\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1242 - val_loss: 116.6409\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.8642 - val_loss: 117.7583\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.1455 - val_loss: 117.7720\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.6185 - val_loss: 118.1043\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.5769 - val_loss: 121.1961\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.7636 - val_loss: 123.1676\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.1915 - val_loss: 126.1231\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.1497 - val_loss: 132.4265\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.6797 - val_loss: 136.7188\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.4837 - val_loss: 139.5835\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.9562 - val_loss: 141.7932\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.9718 - val_loss: 149.5294\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.2893 - val_loss: 149.2829\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.7753 - val_loss: 153.4727\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.7952 - val_loss: 153.4881\n",
      "MAPE:  15.58741318835477\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 112.6039 - val_loss: 103.7886\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.3240 - val_loss: 103.9341\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.0725 - val_loss: 103.3356\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.4349 - val_loss: 102.5423\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3868 - val_loss: 103.5500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.1163 - val_loss: 104.2271\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4567 - val_loss: 104.1653\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7759 - val_loss: 102.8337\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.5941 - val_loss: 103.2055\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3135 - val_loss: 103.3606\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.6147 - val_loss: 99.8449\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3069 - val_loss: 99.7858\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.0994 - val_loss: 100.9321\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6413 - val_loss: 99.5078\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.7028 - val_loss: 98.4305\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6756 - val_loss: 100.0701\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.0209 - val_loss: 97.7467\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4885 - val_loss: 98.7603\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.1679 - val_loss: 98.0449\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6371 - val_loss: 96.4330\n",
      "MAPE:  28.46555331522549\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 97.5798 - val_loss: 89.6655\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.9295 - val_loss: 86.1375\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.4743 - val_loss: 82.2858\n",
      "Epoch 2/2\n",
      " - 0s - loss: 68.5223 - val_loss: 79.7713\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 64.2121 - val_loss: 77.8953\n",
      "Epoch 2/2\n",
      " - 0s - loss: 63.5924 - val_loss: 77.0489\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 63.1319 - val_loss: 75.6993\n",
      "Epoch 2/2\n",
      " - 0s - loss: 61.6883 - val_loss: 74.2821\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 60.5445 - val_loss: 76.7552\n",
      "Epoch 2/2\n",
      " - 0s - loss: 60.1821 - val_loss: 76.6181\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 59.9264 - val_loss: 77.0263\n",
      "Epoch 2/2\n",
      " - 0s - loss: 61.2509 - val_loss: 76.4895\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 59.7332 - val_loss: 78.1361\n",
      "Epoch 2/2\n",
      " - 0s - loss: 59.5786 - val_loss: 77.5284\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 59.2583 - val_loss: 77.7142\n",
      "Epoch 2/2\n",
      " - 0s - loss: 59.3822 - val_loss: 78.7146\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 59.2602 - val_loss: 79.9343\n",
      "Epoch 2/2\n",
      " - 0s - loss: 58.9727 - val_loss: 79.3206\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 59.3158 - val_loss: 79.6448\n",
      "Epoch 2/2\n",
      " - 0s - loss: 59.8551 - val_loss: 77.9603\n",
      "MAPE:  102.63079628120848\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 103.2029 - val_loss: 120.9216\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9012 - val_loss: 131.4036\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1874 - val_loss: 137.0395\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7669 - val_loss: 139.5174\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.0500 - val_loss: 138.4888\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.0758 - val_loss: 143.0296\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.6837 - val_loss: 145.8968\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.2288 - val_loss: 147.4940\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.6369 - val_loss: 150.8179\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.1129 - val_loss: 154.5289\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.2923 - val_loss: 153.7374\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.0225 - val_loss: 155.6802\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.4692 - val_loss: 161.2514\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.1771 - val_loss: 160.3219\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.8140 - val_loss: 157.8410\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.5578 - val_loss: 156.6690\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.6229 - val_loss: 160.0951\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.9209 - val_loss: 161.3248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.4864 - val_loss: 160.5111\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.7775 - val_loss: 159.9478\n",
      "MAPE:  60.69589843676467\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 124.8479 - val_loss: 100.2982\n",
      "Epoch 2/2\n",
      " - 0s - loss: 123.6852 - val_loss: 99.8391\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 109.1896 - val_loss: 100.5782\n",
      "Epoch 2/2\n",
      " - 0s - loss: 109.1432 - val_loss: 101.0467\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 105.7043 - val_loss: 101.0102\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.4021 - val_loss: 100.8321\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.7245 - val_loss: 100.8632\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.1224 - val_loss: 100.9201\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.6362 - val_loss: 101.0066\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.5762 - val_loss: 100.5473\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.4571 - val_loss: 100.3749\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.1178 - val_loss: 100.5997\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.4901 - val_loss: 100.0078\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2197 - val_loss: 100.3096\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.4259 - val_loss: 100.3171\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3708 - val_loss: 100.0441\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.2067 - val_loss: 100.4162\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4299 - val_loss: 100.0964\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1699 - val_loss: 100.5803\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4327 - val_loss: 100.2881\n",
      "MAPE:  24.18429440215163\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 105.8993 - val_loss: 104.8257\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6383 - val_loss: 95.2771\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1150 - val_loss: 87.0391\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.1525 - val_loss: 80.6916\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.4118 - val_loss: 75.5995\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.0475 - val_loss: 71.8014\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.1187 - val_loss: 69.7228\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.7840 - val_loss: 69.8614\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 79.1042 - val_loss: 70.5701\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.7297 - val_loss: 74.3683\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.4764 - val_loss: 77.2758\n",
      "Epoch 2/2\n",
      " - 0s - loss: 76.0666 - val_loss: 77.1257\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.8135 - val_loss: 77.2015\n",
      "Epoch 2/2\n",
      " - 0s - loss: 75.5407 - val_loss: 80.9671\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.8757 - val_loss: 86.1392\n",
      "Epoch 2/2\n",
      " - 0s - loss: 75.6953 - val_loss: 83.8412\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 72.7132 - val_loss: 83.1020\n",
      "Epoch 2/2\n",
      " - 0s - loss: 71.0838 - val_loss: 84.4799\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 72.2045 - val_loss: 80.3483\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.9701 - val_loss: 79.6536\n",
      "MAPE:  25.18224220424059\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 114.0258 - val_loss: 97.9459\n",
      "Epoch 2/2\n",
      " - 0s - loss: 107.1490 - val_loss: 98.3950\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.2333 - val_loss: 97.3824\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.4255 - val_loss: 97.2273\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3990 - val_loss: 97.3813\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5020 - val_loss: 97.4859\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.2193 - val_loss: 97.1414\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8253 - val_loss: 96.3052\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3765 - val_loss: 97.0942\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4757 - val_loss: 97.9734\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.0602 - val_loss: 96.9457\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.4754 - val_loss: 97.0681\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.5817 - val_loss: 97.5610\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.9282 - val_loss: 97.5205\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.0313 - val_loss: 97.8319\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.7884 - val_loss: 97.7374\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.1990 - val_loss: 97.8151\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.5454 - val_loss: 97.8870\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.8984 - val_loss: 98.2907\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.2171 - val_loss: 97.9162\n",
      "MAPE:  174.91834392226647\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 113.2543 - val_loss: 110.1175\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.2827 - val_loss: 106.5844\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 103.1910 - val_loss: 104.1807\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.5185 - val_loss: 100.6278\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.6509 - val_loss: 102.4254\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.1642 - val_loss: 103.0720\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.9966 - val_loss: 100.9074\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.9371 - val_loss: 104.5763\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.5790 - val_loss: 103.9897\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.8138 - val_loss: 103.5931\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7297 - val_loss: 105.7829\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4187 - val_loss: 103.4407\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3540 - val_loss: 105.1977\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2590 - val_loss: 102.7635\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.4226 - val_loss: 104.7717\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7327 - val_loss: 104.4057\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7771 - val_loss: 104.5287\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6545 - val_loss: 103.7240\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.3111 - val_loss: 102.5895\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2453 - val_loss: 105.3945\n",
      "MAPE:  9.96909449036106\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 206.0621 - val_loss: 97.5901\n",
      "Epoch 2/2\n",
      " - 0s - loss: 128.4719 - val_loss: 96.1895\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 158.2748 - val_loss: 93.7637\n",
      "Epoch 2/2\n",
      " - 0s - loss: 141.5507 - val_loss: 93.8525\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 135.1991 - val_loss: 92.4872\n",
      "Epoch 2/2\n",
      " - 0s - loss: 111.3158 - val_loss: 92.8846\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 116.3090 - val_loss: 92.7615\n",
      "Epoch 2/2\n",
      " - 0s - loss: 119.2018 - val_loss: 93.7492\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 114.6898 - val_loss: 92.6842\n",
      "Epoch 2/2\n",
      " - 0s - loss: 111.2584 - val_loss: 93.2138\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 109.8375 - val_loss: 94.9287\n",
      "Epoch 2/2\n",
      " - 0s - loss: 110.7398 - val_loss: 92.0012\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 112.7937 - val_loss: 94.6382\n",
      "Epoch 2/2\n",
      " - 0s - loss: 113.9940 - val_loss: 93.0721\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 108.0125 - val_loss: 93.3742\n",
      "Epoch 2/2\n",
      " - 0s - loss: 115.1606 - val_loss: 92.8343\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.8188 - val_loss: 94.2205\n",
      "Epoch 2/2\n",
      " - 0s - loss: 110.8330 - val_loss: 93.2236\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 120.9937 - val_loss: 93.4210\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.2075 - val_loss: 92.2975\n",
      "MAPE:  75.58706160851835\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 108.4755 - val_loss: 99.0864\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.3634 - val_loss: 99.4412\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.4090 - val_loss: 99.4900\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.4393 - val_loss: 99.6744\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.7862 - val_loss: 99.7895\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.6046 - val_loss: 100.0109\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 98.3895 - val_loss: 99.7485\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.0035 - val_loss: 100.0089\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0224 - val_loss: 100.3226\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5804 - val_loss: 100.0632\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3785 - val_loss: 99.8188\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9932 - val_loss: 100.0642\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.4267 - val_loss: 100.0080\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4929 - val_loss: 99.8390\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.8608 - val_loss: 100.2640\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.1414 - val_loss: 100.2960\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9157 - val_loss: 100.4734\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5127 - val_loss: 99.9670\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.6377 - val_loss: 101.2255\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8224 - val_loss: 101.2031\n",
      "MAPE:  6.8006807172166175\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 108.7964 - val_loss: 125.1978\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.7278 - val_loss: 122.5056\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.6436 - val_loss: 131.3658\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.4920 - val_loss: 128.6195\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4035 - val_loss: 127.9350\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3485 - val_loss: 133.1264\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7987 - val_loss: 131.4987\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5850 - val_loss: 138.7417\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3942 - val_loss: 132.5645\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2413 - val_loss: 136.9824\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9475 - val_loss: 131.5332\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2719 - val_loss: 133.7954\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7329 - val_loss: 131.5246\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6107 - val_loss: 134.4395\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0992 - val_loss: 131.2842\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.8630 - val_loss: 131.0765\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.2414 - val_loss: 134.1382\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0499 - val_loss: 137.9902\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1952 - val_loss: 136.5587\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.9012 - val_loss: 136.2187\n",
      "MAPE:  11.102986828582814\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 103.9080 - val_loss: 103.3395\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.2020 - val_loss: 104.4421\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4040 - val_loss: 105.2002\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.7532 - val_loss: 106.4078\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.8864 - val_loss: 107.3217\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.6206 - val_loss: 108.0745\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.9836 - val_loss: 109.3259\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5836 - val_loss: 110.2234\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1282 - val_loss: 111.6069\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7419 - val_loss: 112.3231\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.0091 - val_loss: 113.0483\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2557 - val_loss: 113.5180\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4516 - val_loss: 113.7069\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4827 - val_loss: 114.4892\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9861 - val_loss: 114.6139\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5767 - val_loss: 115.6830\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.6854 - val_loss: 115.5870\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0051 - val_loss: 117.5407\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.5552 - val_loss: 116.7417\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.0544 - val_loss: 118.0380\n",
      "MAPE:  55.95512836528559\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 1625701.3445 - val_loss: 101.9345\n",
      "Epoch 2/2\n",
      " - 0s - loss: 945859.3332 - val_loss: 101.2863\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 658057.5016 - val_loss: 101.5331\n",
      "Epoch 2/2\n",
      " - 0s - loss: 635421.5200 - val_loss: 100.9742\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 407960.8534 - val_loss: 101.1626\n",
      "Epoch 2/2\n",
      " - 0s - loss: 300515.2436 - val_loss: 100.8622\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 471654.5288 - val_loss: 101.2275\n",
      "Epoch 2/2\n",
      " - 0s - loss: 451207.1662 - val_loss: 101.2402\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 422831.9878 - val_loss: 100.8968\n",
      "Epoch 2/2\n",
      " - 0s - loss: 280862.1091 - val_loss: 100.1936\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 323984.2290 - val_loss: 100.8535\n",
      "Epoch 2/2\n",
      " - 0s - loss: 439997.2297 - val_loss: 100.8181\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 301458.4521 - val_loss: 100.6931\n",
      "Epoch 2/2\n",
      " - 0s - loss: 427667.2242 - val_loss: 101.1293\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 445998.1054 - val_loss: 102.1116\n",
      "Epoch 2/2\n",
      " - 0s - loss: 409960.4244 - val_loss: 101.4720\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 322447.4885 - val_loss: 101.3325\n",
      "Epoch 2/2\n",
      " - 0s - loss: 458835.4353 - val_loss: 101.3371\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 316797.6915 - val_loss: 101.0099\n",
      "Epoch 2/2\n",
      " - 0s - loss: 233903.4568 - val_loss: 100.9664\n",
      "MAPE:  25.67879013184581\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 97.1993 - val_loss: 93.9863\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8436 - val_loss: 91.7400\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.8158 - val_loss: 90.5827\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1930 - val_loss: 90.2213\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.3321 - val_loss: 90.0241\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1624 - val_loss: 89.8039\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.2183 - val_loss: 89.7100\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6851 - val_loss: 89.7284\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.5036 - val_loss: 89.2698\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.4628 - val_loss: 88.8049\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.9792 - val_loss: 88.7457\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.9953 - val_loss: 89.0160\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.6219 - val_loss: 88.6227\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.9838 - val_loss: 89.2144\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.0314 - val_loss: 89.1307\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.9137 - val_loss: 88.0848\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.9329 - val_loss: 88.0395\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.5139 - val_loss: 87.3832\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1066 - val_loss: 86.4682\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.2072 - val_loss: 86.6227\n",
      "MAPE:  139.09850500131995\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 6s - loss: 99.6932 - val_loss: 101.5384\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.3323 - val_loss: 107.2794\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.5654 - val_loss: 112.5142\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6585 - val_loss: 122.1902\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.4193 - val_loss: 126.5697\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.6074 - val_loss: 137.3473\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.8768 - val_loss: 144.3907\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.5226 - val_loss: 151.4049\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.8748 - val_loss: 156.8713\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.0736 - val_loss: 159.1529\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.5421 - val_loss: 156.5428\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.4055 - val_loss: 167.7623\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.2160 - val_loss: 170.4034\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.3332 - val_loss: 168.3210\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 84.3218 - val_loss: 168.6316\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.1040 - val_loss: 171.2194\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81.9987 - val_loss: 180.6761\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.7746 - val_loss: 181.0609\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.9562 - val_loss: 181.1681\n",
      "Epoch 2/2\n",
      " - 0s - loss: 80.5321 - val_loss: 171.8603\n",
      "MAPE:  8.298842238596974\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 4614130.7065 - val_loss: 1071376.2875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 2969629.0326 - val_loss: 1170005.2750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1914354.0285 - val_loss: 1377282.0688\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1825569.8560 - val_loss: 1261137.5437\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1733085.9076 - val_loss: 1049766.4875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1484841.2690 - val_loss: 1078696.8500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1291673.8702 - val_loss: 931819.9812\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1306697.8193 - val_loss: 959536.5000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1296287.4701 - val_loss: 1063050.0375\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1246161.3179 - val_loss: 993365.6000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1192275.3723 - val_loss: 1061500.5500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1389875.7201 - val_loss: 958371.4563\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 879273.5177 - val_loss: 865278.8031\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1075145.1685 - val_loss: 794783.2781\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 839822.8995 - val_loss: 730133.7500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 743907.2863 - val_loss: 580707.3953\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 797966.8383 - val_loss: 581819.5531\n",
      "Epoch 2/2\n",
      " - 0s - loss: 972295.9966 - val_loss: 625136.3469\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 793304.6311 - val_loss: 414480.3125\n",
      "Epoch 2/2\n",
      " - 0s - loss: 817367.7272 - val_loss: 544536.4125\n",
      "MAPE:  27.650377226909995\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 805388.2519 - val_loss: 381583.0781\n",
      "Epoch 2/2\n",
      " - 0s - loss: 757464.8645 - val_loss: 462743.3812\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 523099.4796 - val_loss: 618209.9812\n",
      "Epoch 2/2\n",
      " - 0s - loss: 357508.5050 - val_loss: 520531.0859\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 273455.9020 - val_loss: 655105.0281\n",
      "Epoch 2/2\n",
      " - 0s - loss: 285796.8868 - val_loss: 625179.5094\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 390873.2728 - val_loss: 688404.2227\n",
      "Epoch 2/2\n",
      " - 0s - loss: 225559.1187 - val_loss: 841314.4844\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 148674.9782 - val_loss: 819054.8719\n",
      "Epoch 2/2\n",
      " - 0s - loss: 390767.7657 - val_loss: 837298.3156\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 185276.1450 - val_loss: 790648.9313\n",
      "Epoch 2/2\n",
      " - 0s - loss: 327254.0150 - val_loss: 606419.2937\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 363570.5789 - val_loss: 611973.8594\n",
      "Epoch 2/2\n",
      " - 0s - loss: 304139.7906 - val_loss: 541511.5094\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 267407.0099 - val_loss: 654353.3047\n",
      "Epoch 2/2\n",
      " - 0s - loss: 265566.1274 - val_loss: 592229.7063\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 297745.3532 - val_loss: 700899.8125\n",
      "Epoch 2/2\n",
      " - 0s - loss: 277514.0608 - val_loss: 597645.7500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 180286.7654 - val_loss: 693961.8375\n",
      "Epoch 2/2\n",
      " - 0s - loss: 267149.7002 - val_loss: 573533.9812\n",
      "MAPE:  31.964121114255445\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 102.3916 - val_loss: 491074.3934\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5723 - val_loss: 467393.5368\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.8837 - val_loss: 542730.7453\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.7702 - val_loss: 561478.6374\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.6983 - val_loss: 585955.6881\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.7480 - val_loss: 689214.6330\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.3590 - val_loss: 827228.5239\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.7686 - val_loss: 844945.0432\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.5590 - val_loss: 824489.0774\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6681 - val_loss: 887914.5261\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.5279 - val_loss: 831844.6379\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.4323 - val_loss: 890611.1264\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.2762 - val_loss: 976619.7006\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6728 - val_loss: 1078383.0825\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.2627 - val_loss: 1062006.9064\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.5006 - val_loss: 1038608.3890\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.1099 - val_loss: 1079152.6250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.0250 - val_loss: 1041939.0394\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.4210 - val_loss: 1080348.4104\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.4574 - val_loss: 1130603.8040\n",
      "MAPE:  20.89729162879964\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 117.9652 - val_loss: 99.1462\n",
      "Epoch 2/2\n",
      " - 0s - loss: 108.2757 - val_loss: 101.4019\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.6493 - val_loss: 100.8196\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.8752 - val_loss: 101.6818\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.2704 - val_loss: 102.2996\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.0183 - val_loss: 101.9549\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9527 - val_loss: 102.2457\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6082 - val_loss: 102.3184\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.0527 - val_loss: 103.0990\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.4447 - val_loss: 104.0644\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.8537 - val_loss: 102.7932\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.8189 - val_loss: 103.9572\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4022 - val_loss: 102.3474\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3877 - val_loss: 103.5626\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.4659 - val_loss: 103.7018\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.4742 - val_loss: 102.3544\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.6691 - val_loss: 102.3370\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0783 - val_loss: 102.8282\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1008 - val_loss: 102.6335\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6393 - val_loss: 102.8367\n",
      "MAPE:  17.919169076090814\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 8s - loss: 99.6823 - val_loss: 96.4588\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.3892 - val_loss: 95.2499\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3754 - val_loss: 93.9758\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.6451 - val_loss: 93.0766\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.0720 - val_loss: 92.3564\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6321 - val_loss: 94.1222\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9617 - val_loss: 93.4498\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7771 - val_loss: 93.2713\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8076 - val_loss: 93.1305\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5482 - val_loss: 92.3524\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.0154 - val_loss: 92.4138\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.2984 - val_loss: 93.0992\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.0849 - val_loss: 92.9135\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1029 - val_loss: 93.9444\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.5370 - val_loss: 93.7460\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4834 - val_loss: 93.4551\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.0648 - val_loss: 93.2892\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.0913 - val_loss: 93.9731\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 93.5177 - val_loss: 94.5620\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.4659 - val_loss: 93.5164\n",
      "MAPE:  27.924322355881987\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 1557316.4405 - val_loss: 593157.0629\n",
      "Epoch 2/2\n",
      " - 0s - loss: 976410.6273 - val_loss: 398135.1515\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 624242.8647 - val_loss: 409379.0883\n",
      "Epoch 2/2\n",
      " - 0s - loss: 517164.0398 - val_loss: 583390.5580\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 459419.5851 - val_loss: 465163.1164\n",
      "Epoch 2/2\n",
      " - 0s - loss: 312596.6716 - val_loss: 609891.2433\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 521361.7752 - val_loss: 677503.6634\n",
      "Epoch 2/2\n",
      " - 0s - loss: 467830.1751 - val_loss: 672722.2839\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 511503.4384 - val_loss: 564979.5872\n",
      "Epoch 2/2\n",
      " - 0s - loss: 469522.0087 - val_loss: 534996.4742\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 300068.7340 - val_loss: 533969.7086\n",
      "Epoch 2/2\n",
      " - 0s - loss: 308484.4975 - val_loss: 475354.5050\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 340569.2723 - val_loss: 474914.3927\n",
      "Epoch 2/2\n",
      " - 0s - loss: 434441.2210 - val_loss: 455549.5034\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 328482.2707 - val_loss: 499081.4658\n",
      "Epoch 2/2\n",
      " - 0s - loss: 375179.9002 - val_loss: 538170.5929\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 331667.6642 - val_loss: 648296.5798\n",
      "Epoch 2/2\n",
      " - 0s - loss: 253825.0710 - val_loss: 535790.7518\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 332210.2396 - val_loss: 618660.2110\n",
      "Epoch 2/2\n",
      " - 0s - loss: 554027.3854 - val_loss: 544326.6065\n",
      "MAPE:  37.495373542537564\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 108.2592 - val_loss: 104.1104\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.7763 - val_loss: 100.4754\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.9691 - val_loss: 98.7861\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.8846 - val_loss: 98.4620\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.9582 - val_loss: 96.1906\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5751 - val_loss: 97.2340\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.4058 - val_loss: 96.7280\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.6401 - val_loss: 95.6532\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0471 - val_loss: 95.6230\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7293 - val_loss: 96.6864\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0347 - val_loss: 95.9730\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5700 - val_loss: 95.0655\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7819 - val_loss: 96.1126\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5202 - val_loss: 94.5796\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7384 - val_loss: 94.7471\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4240 - val_loss: 96.9994\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8256 - val_loss: 95.5138\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.8625 - val_loss: 96.8592\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.5484 - val_loss: 96.1296\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.9346 - val_loss: 96.3968\n",
      "MAPE:  7.216305504177366\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 159.4814 - val_loss: 137.8135\n",
      "Epoch 2/2\n",
      " - 0s - loss: 126.4539 - val_loss: 120.5892\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 125.7341 - val_loss: 117.0066\n",
      "Epoch 2/2\n",
      " - 0s - loss: 113.8815 - val_loss: 111.8771\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 119.7007 - val_loss: 118.6689\n",
      "Epoch 2/2\n",
      " - 0s - loss: 114.5786 - val_loss: 120.3135\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 113.5840 - val_loss: 128.1144\n",
      "Epoch 2/2\n",
      " - 0s - loss: 109.3143 - val_loss: 128.2404\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 109.6376 - val_loss: 125.6383\n",
      "Epoch 2/2\n",
      " - 0s - loss: 113.2295 - val_loss: 123.9144\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 111.2517 - val_loss: 137.4284\n",
      "Epoch 2/2\n",
      " - 0s - loss: 107.6527 - val_loss: 134.0806\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 107.8133 - val_loss: 138.7602\n",
      "Epoch 2/2\n",
      " - 0s - loss: 107.4875 - val_loss: 146.7792\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 110.4653 - val_loss: 142.4696\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.0550 - val_loss: 139.2326\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 109.2558 - val_loss: 136.2649\n",
      "Epoch 2/2\n",
      " - 0s - loss: 108.6077 - val_loss: 144.5259\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.6199 - val_loss: 144.0474\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.1668 - val_loss: 144.4581\n",
      "MAPE:  38.694984790251794\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 151.2659 - val_loss: 113.7728\n",
      "Epoch 2/2\n",
      " - 0s - loss: 135.7554 - val_loss: 113.1519\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 127.3159 - val_loss: 112.8623\n",
      "Epoch 2/2\n",
      " - 0s - loss: 124.8010 - val_loss: 112.3476\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 119.4399 - val_loss: 112.1064\n",
      "Epoch 2/2\n",
      " - 0s - loss: 110.4536 - val_loss: 111.2782\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 112.3351 - val_loss: 111.0433\n",
      "Epoch 2/2\n",
      " - 0s - loss: 110.2905 - val_loss: 111.5940\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 106.0682 - val_loss: 109.2487\n",
      "Epoch 2/2\n",
      " - 0s - loss: 108.2859 - val_loss: 106.9374\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.0813 - val_loss: 105.5187\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.4207 - val_loss: 106.3873\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.9172 - val_loss: 106.9860\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.0300 - val_loss: 107.9837\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.2461 - val_loss: 107.1590\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.6133 - val_loss: 106.1965\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.8546 - val_loss: 104.9971\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.5360 - val_loss: 104.1086\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.4301 - val_loss: 104.5110\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.0323 - val_loss: 101.9755\n",
      "MAPE:  32.38730052925799\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 107.3882 - val_loss: 99.9926\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.2267 - val_loss: 98.1123\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.2271 - val_loss: 96.0047\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8023 - val_loss: 94.2746\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9420 - val_loss: 92.3184\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5799 - val_loss: 90.3827\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.8385 - val_loss: 88.3159\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.5778 - val_loss: 87.2475\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.6368 - val_loss: 84.9996\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.7034 - val_loss: 82.9803\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.9622 - val_loss: 80.9529\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.7966 - val_loss: 78.6176\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.7782 - val_loss: 76.4140\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6580 - val_loss: 77.8420\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.5841 - val_loss: 73.7124\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.9541 - val_loss: 73.0857\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.6562 - val_loss: 68.3429\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.8557 - val_loss: 64.2868\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 79.2271 - val_loss: 58.2437\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.4001 - val_loss: 60.2747\n",
      "MAPE:  23.273551770638\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 107.0049 - val_loss: 103.3311\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.3239 - val_loss: 105.5110\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.8508 - val_loss: 116.2648\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.4378 - val_loss: 124.9995\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 84.4540 - val_loss: 130.9698\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.0631 - val_loss: 131.0952\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.0823 - val_loss: 133.0309\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.3424 - val_loss: 134.3757\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 79.4163 - val_loss: 134.8479\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.5642 - val_loss: 136.8657\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 80.2560 - val_loss: 134.2685\n",
      "Epoch 2/2\n",
      " - 0s - loss: 78.5511 - val_loss: 135.5161\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.7856 - val_loss: 136.5031\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.3344 - val_loss: 135.9973\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81.3715 - val_loss: 133.3013\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.5216 - val_loss: 134.4459\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.0168 - val_loss: 133.4018\n",
      "Epoch 2/2\n",
      " - 0s - loss: 78.1848 - val_loss: 135.2332\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 80.3045 - val_loss: 137.2001\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.1305 - val_loss: 133.5086\n",
      "MAPE:  48.002298912670064\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 966070.4367 - val_loss: 101.5789\n",
      "Epoch 2/2\n",
      " - 0s - loss: 593579.4294 - val_loss: 101.1649\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 429921.9797 - val_loss: 100.0233\n",
      "Epoch 2/2\n",
      " - 0s - loss: 718719.7409 - val_loss: 100.1967\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 538298.6416 - val_loss: 99.4676\n",
      "Epoch 2/2\n",
      " - 0s - loss: 336677.6886 - val_loss: 99.6201\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 391027.5038 - val_loss: 99.2273\n",
      "Epoch 2/2\n",
      " - 0s - loss: 271114.6303 - val_loss: 98.5881\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 311027.8831 - val_loss: 99.2926\n",
      "Epoch 2/2\n",
      " - 0s - loss: 262685.2427 - val_loss: 98.4265\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 392132.3370 - val_loss: 98.3051\n",
      "Epoch 2/2\n",
      " - 0s - loss: 331018.8124 - val_loss: 97.9277\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 427592.5625 - val_loss: 97.4346\n",
      "Epoch 2/2\n",
      " - 0s - loss: 325010.0378 - val_loss: 97.1202\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 238295.4479 - val_loss: 97.4014\n",
      "Epoch 2/2\n",
      " - 0s - loss: 282077.8391 - val_loss: 96.3161\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 405960.3008 - val_loss: 96.5357\n",
      "Epoch 2/2\n",
      " - 0s - loss: 230513.7301 - val_loss: 95.5105\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 401158.2494 - val_loss: 96.4996\n",
      "Epoch 2/2\n",
      " - 0s - loss: 288892.7318 - val_loss: 95.9656\n",
      "MAPE:  29.117688005804254\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 99.2253 - val_loss: 93.0936\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.1744 - val_loss: 85.7836\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.6384 - val_loss: 78.3006\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.2259 - val_loss: 71.4529\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.5011 - val_loss: 68.4237\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.0335 - val_loss: 67.7798\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 80.8563 - val_loss: 67.4050\n",
      "Epoch 2/2\n",
      " - 0s - loss: 80.0042 - val_loss: 68.3494\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 78.5651 - val_loss: 71.3064\n",
      "Epoch 2/2\n",
      " - 0s - loss: 78.8704 - val_loss: 70.0992\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 78.0828 - val_loss: 70.2215\n",
      "Epoch 2/2\n",
      " - 0s - loss: 78.5550 - val_loss: 72.0109\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.2780 - val_loss: 72.4476\n",
      "Epoch 2/2\n",
      " - 0s - loss: 77.1786 - val_loss: 72.1803\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.4424 - val_loss: 71.7916\n",
      "Epoch 2/2\n",
      " - 0s - loss: 77.0888 - val_loss: 73.4818\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 75.4505 - val_loss: 73.4543\n",
      "Epoch 2/2\n",
      " - 0s - loss: 77.3330 - val_loss: 76.6243\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.2144 - val_loss: 72.0441\n",
      "Epoch 2/2\n",
      " - 0s - loss: 78.0508 - val_loss: 74.6086\n",
      "MAPE:  62.373638012447586\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 106.9495 - val_loss: 108.5738\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.8907 - val_loss: 104.9475\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.9113 - val_loss: 103.1356\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.9505 - val_loss: 102.9005\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.7845 - val_loss: 102.7680\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.4956 - val_loss: 102.6096\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.4025 - val_loss: 100.7308\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.9855 - val_loss: 101.2071\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1081 - val_loss: 99.2088\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4661 - val_loss: 100.0572\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4300 - val_loss: 99.4945\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5579 - val_loss: 98.7348\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.9536 - val_loss: 95.9434\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.7212 - val_loss: 95.2531\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1711 - val_loss: 93.4302\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.0388 - val_loss: 93.4278\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.5218 - val_loss: 94.1572\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5893 - val_loss: 94.0632\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.7174 - val_loss: 93.2133\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.7738 - val_loss: 92.4984\n",
      "MAPE:  62.42932672806391\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 124.7835 - val_loss: 99.5855\n",
      "Epoch 2/2\n",
      " - 0s - loss: 111.0285 - val_loss: 105.9654\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4746 - val_loss: 116.4364\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.3074 - val_loss: 125.4306\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.0999 - val_loss: 133.6315\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.9687 - val_loss: 140.7970\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.2500 - val_loss: 145.2961\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6981 - val_loss: 148.3878\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.4821 - val_loss: 153.5337\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.5876 - val_loss: 156.2222\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.3480 - val_loss: 156.3924\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.1104 - val_loss: 156.8742\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.4344 - val_loss: 159.7025\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.8755 - val_loss: 159.1768\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.0099 - val_loss: 161.5166\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.9011 - val_loss: 158.1246\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.3345 - val_loss: 158.5173\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.7132 - val_loss: 156.6625\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.3920 - val_loss: 158.8644\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.8667 - val_loss: 158.7789\n",
      "MAPE:  26.070179431061124\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 103.0062 - val_loss: 120.1174\n",
      "Epoch 2/2\n",
      " - 0s - loss: 121.2601 - val_loss: 117.8434\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 115.3281 - val_loss: 116.8347\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.1597 - val_loss: 115.2265\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 105.0295 - val_loss: 115.0972\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.2968 - val_loss: 114.9632\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.0280 - val_loss: 114.7515\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.8796 - val_loss: 114.9697\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.3722 - val_loss: 111.1108\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9809 - val_loss: 112.5825\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.2187 - val_loss: 113.1167\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.6438 - val_loss: 112.5796\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7345 - val_loss: 111.0797\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6042 - val_loss: 110.4982\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2068 - val_loss: 111.3449\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4329 - val_loss: 112.0003\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4932 - val_loss: 114.0428\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7109 - val_loss: 115.2845\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4058 - val_loss: 114.6974\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5382 - val_loss: 117.0809\n",
      "MAPE:  19.495521815040767\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 119.1925 - val_loss: 106.6078\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.6358 - val_loss: 107.8993\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 110.0228 - val_loss: 107.1592\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.4029 - val_loss: 106.2817\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 106.0268 - val_loss: 103.5978\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.7794 - val_loss: 102.5064\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.7532 - val_loss: 102.9027\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.7413 - val_loss: 103.7899\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.7034 - val_loss: 103.8835\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.6339 - val_loss: 105.2088\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.7513 - val_loss: 104.5999\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6137 - val_loss: 103.0105\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.9009 - val_loss: 104.5429\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1639 - val_loss: 102.9857\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.4939 - val_loss: 103.5713\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.0594 - val_loss: 103.6114\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.9861 - val_loss: 102.0120\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6664 - val_loss: 103.9381\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.4768 - val_loss: 102.5101\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.8043 - val_loss: 102.0881\n",
      "MAPE:  5.8440471616978185\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 100.2286 - val_loss: 96.0957\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.9897 - val_loss: 93.2033\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.1380 - val_loss: 91.8440\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.6945 - val_loss: 94.6365\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.1390 - val_loss: 99.0816\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.9234 - val_loss: 101.9622\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.9236 - val_loss: 102.5929\n",
      "Epoch 2/2\n",
      " - 0s - loss: 77.2512 - val_loss: 105.9361\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 75.7402 - val_loss: 106.1679\n",
      "Epoch 2/2\n",
      " - 0s - loss: 76.0494 - val_loss: 110.5941\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 74.7587 - val_loss: 109.7113\n",
      "Epoch 2/2\n",
      " - 0s - loss: 76.2188 - val_loss: 110.6240\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.4503 - val_loss: 110.4845\n",
      "Epoch 2/2\n",
      " - 0s - loss: 75.5336 - val_loss: 108.8308\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 75.0885 - val_loss: 108.5876\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.5590 - val_loss: 109.2635\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 74.8177 - val_loss: 111.7587\n",
      "Epoch 2/2\n",
      " - 0s - loss: 75.1350 - val_loss: 110.6373\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.8340 - val_loss: 110.6880\n",
      "Epoch 2/2\n",
      " - 0s - loss: 73.7764 - val_loss: 111.6764\n",
      "MAPE:  5.147171705926173\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 9s - loss: 120.8960 - val_loss: 98.0074\n",
      "Epoch 2/2\n",
      " - 0s - loss: 126.0897 - val_loss: 97.6609\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.8411 - val_loss: 97.1112\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.4035 - val_loss: 96.9973\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.7370 - val_loss: 97.0829\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.4725 - val_loss: 97.2163\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.7039 - val_loss: 97.6162\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.7880 - val_loss: 97.3657\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.8149 - val_loss: 96.8502\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4284 - val_loss: 96.6607\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.0709 - val_loss: 96.7057\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.9155 - val_loss: 96.8619\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.5737 - val_loss: 96.3171\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6205 - val_loss: 96.5239\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.7055 - val_loss: 96.0158\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.0029 - val_loss: 96.7688\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.3318 - val_loss: 96.4271\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6720 - val_loss: 95.9722\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.3490 - val_loss: 96.1665\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.5679 - val_loss: 96.1823\n",
      "MAPE:  9.119417910482898\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 113.9223 - val_loss: 115.8944\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.8931 - val_loss: 123.8222\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.1571 - val_loss: 131.1667\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.9050 - val_loss: 132.9560\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.0903 - val_loss: 133.1679\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3817 - val_loss: 133.2077\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.3941 - val_loss: 134.8992\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.4299 - val_loss: 135.6613\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.4731 - val_loss: 136.6135\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2579 - val_loss: 136.3916\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1521 - val_loss: 136.9010\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.6082 - val_loss: 135.3461\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3199 - val_loss: 136.5874\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7183 - val_loss: 140.0283\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9995 - val_loss: 131.3847\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2465 - val_loss: 139.5274\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1747 - val_loss: 137.2514\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.1691 - val_loss: 138.7049\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0970 - val_loss: 136.8795\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.3599 - val_loss: 136.9010\n",
      "MAPE:  8.34575826150014\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 109.6141 - val_loss: 100.1865\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.7697 - val_loss: 98.5941\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.7386 - val_loss: 98.3095\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.8334 - val_loss: 97.1804\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.1234 - val_loss: 96.1984\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2109 - val_loss: 99.2566\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.9878 - val_loss: 99.6229\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5230 - val_loss: 101.8739\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.2865 - val_loss: 100.0059\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.6690 - val_loss: 101.1915\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7645 - val_loss: 98.4589\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.7996 - val_loss: 100.1902\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.0231 - val_loss: 98.5830\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4431 - val_loss: 99.1981\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.1476 - val_loss: 101.6764\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.1230 - val_loss: 99.2888\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.2618 - val_loss: 100.0385\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.8749 - val_loss: 100.1404\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7232 - val_loss: 99.6072\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.9295 - val_loss: 98.5711\n",
      "MAPE:  13.224909099244849\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 10s - loss: 101.1993 - val_loss: 104.7548\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.8988 - val_loss: 105.7877\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.2182 - val_loss: 105.7135\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.0430 - val_loss: 104.5364\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.1551 - val_loss: 103.8009\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3808 - val_loss: 103.4557\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.0314 - val_loss: 104.4162\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.9730 - val_loss: 105.4614\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.0089 - val_loss: 105.2511\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2980 - val_loss: 105.0081\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.2542 - val_loss: 105.0410\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2353 - val_loss: 105.7945\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1059 - val_loss: 106.4280\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.3260 - val_loss: 105.9181\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.6991 - val_loss: 107.9994\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7054 - val_loss: 107.8824\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.3242 - val_loss: 107.3566\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4471 - val_loss: 108.0546\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.8396 - val_loss: 109.1716\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.5780 - val_loss: 107.8531\n",
      "MAPE:  15.929596562586724\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 107.4980 - val_loss: 102.2521\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.3271 - val_loss: 102.7879\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.7373 - val_loss: 103.8243\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.3100 - val_loss: 104.5755\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.2197 - val_loss: 104.7461\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.8358 - val_loss: 105.1764\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3507 - val_loss: 105.4793\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2708 - val_loss: 105.6051\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.4448 - val_loss: 104.9583\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4666 - val_loss: 104.7841\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.3063 - val_loss: 105.2596\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7746 - val_loss: 105.2738\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.5791 - val_loss: 106.0143\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2105 - val_loss: 105.6528\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.0674 - val_loss: 105.5817\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.2849 - val_loss: 105.8670\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7138 - val_loss: 106.3623\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.2935 - val_loss: 106.2081\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.5136 - val_loss: 105.1683\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7539 - val_loss: 105.0058\n",
      "MAPE:  18.285614234119844\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 13s - loss: 96.1983 - val_loss: 88.4334\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6001 - val_loss: 82.1392\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.6444 - val_loss: 74.8338\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.0042 - val_loss: 67.2909\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.4155 - val_loss: 60.7930\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.5937 - val_loss: 58.0435\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.5012 - val_loss: 52.9226\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.2983 - val_loss: 60.0821\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 74.9797 - val_loss: 52.7060\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.0769 - val_loss: 55.9437\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 75.7887 - val_loss: 54.6078\n",
      "Epoch 2/2\n",
      " - 0s - loss: 80.4446 - val_loss: 54.8484\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.3044 - val_loss: 53.2421\n",
      "Epoch 2/2\n",
      " - 0s - loss: 76.9796 - val_loss: 51.0818\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 78.9079 - val_loss: 54.4694\n",
      "Epoch 2/2\n",
      " - 0s - loss: 80.9041 - val_loss: 51.0678\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.8390 - val_loss: 49.8366\n",
      "Epoch 2/2\n",
      " - 0s - loss: 78.1041 - val_loss: 50.3562\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 72.0390 - val_loss: 49.7673\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.2142 - val_loss: 49.1294\n",
      "MAPE:  34.463659039537035\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 109.0902 - val_loss: 101.1346\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.6743 - val_loss: 100.3300\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.0458 - val_loss: 99.4887\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9858 - val_loss: 98.4074\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.6012 - val_loss: 98.3468\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.1004 - val_loss: 98.2093\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1130 - val_loss: 97.7825\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.0722 - val_loss: 97.8773\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7224 - val_loss: 97.4062\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.4348 - val_loss: 97.4378\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1584 - val_loss: 96.6508\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.9285 - val_loss: 97.7875\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.2567 - val_loss: 97.8808\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3871 - val_loss: 96.8351\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3774 - val_loss: 96.7038\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3121 - val_loss: 96.2119\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5168 - val_loss: 97.1884\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7391 - val_loss: 96.2502\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5914 - val_loss: 96.9199\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4927 - val_loss: 96.3077\n",
      "MAPE:  7.080733804223866\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 134.3110 - val_loss: 150.3602\n",
      "Epoch 2/2\n",
      " - 0s - loss: 126.0357 - val_loss: 143.5188\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 107.3416 - val_loss: 136.0315\n",
      "Epoch 2/2\n",
      " - 0s - loss: 107.7380 - val_loss: 132.6073\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.7026 - val_loss: 136.9756\n",
      "Epoch 2/2\n",
      " - 0s - loss: 109.1037 - val_loss: 131.2453\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 108.3447 - val_loss: 135.9890\n",
      "Epoch 2/2\n",
      " - 0s - loss: 108.1782 - val_loss: 133.9307\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 108.0386 - val_loss: 136.5615\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.9654 - val_loss: 136.6200\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 108.2950 - val_loss: 141.1832\n",
      "Epoch 2/2\n",
      " - 0s - loss: 108.1294 - val_loss: 139.6692\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.0685 - val_loss: 145.0825\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.8432 - val_loss: 141.6146\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 107.0863 - val_loss: 141.0458\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.3596 - val_loss: 145.3434\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 107.1024 - val_loss: 137.5389\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.2236 - val_loss: 143.2518\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.0674 - val_loss: 140.5070\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.6367 - val_loss: 140.9985\n",
      "MAPE:  21.516664813712673\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 101.7427 - val_loss: 101.6848\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.1798 - val_loss: 102.4294\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4556 - val_loss: 103.5673\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.9271 - val_loss: 104.8129\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.6089 - val_loss: 106.1616\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7707 - val_loss: 104.9507\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9007 - val_loss: 105.5462\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8463 - val_loss: 105.9788\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.6613 - val_loss: 106.7532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 0s - loss: 93.9149 - val_loss: 105.9676\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3101 - val_loss: 105.9790\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.9061 - val_loss: 105.6749\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4923 - val_loss: 104.2968\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1251 - val_loss: 105.0633\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9199 - val_loss: 106.4502\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.9913 - val_loss: 104.5762\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.3627 - val_loss: 106.0591\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.9895 - val_loss: 105.9312\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.4986 - val_loss: 105.4653\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1863 - val_loss: 104.4104\n",
      "MAPE:  12.685433285934536\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 101.5532 - val_loss: 102.5172\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.2916 - val_loss: 102.2193\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.6493 - val_loss: 102.7157\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.8087 - val_loss: 102.9831\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.2759 - val_loss: 103.6297\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9464 - val_loss: 103.8873\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.2901 - val_loss: 104.4037\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.7655 - val_loss: 105.3836\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9143 - val_loss: 105.9422\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.6349 - val_loss: 105.9836\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.6397 - val_loss: 106.2036\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0723 - val_loss: 107.5032\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2998 - val_loss: 106.4950\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0170 - val_loss: 107.2416\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1128 - val_loss: 106.8346\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6000 - val_loss: 107.3917\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.2076 - val_loss: 107.2356\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8243 - val_loss: 106.1942\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7512 - val_loss: 107.5798\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.9703 - val_loss: 106.9227\n",
      "MAPE:  14.405324546609762\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 3596336.7682 - val_loss: 97.2184\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1560839.6888 - val_loss: 97.2569\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1328323.9295 - val_loss: 98.6166\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1080196.3574 - val_loss: 98.8336\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1126531.5558 - val_loss: 99.3945\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1119384.1897 - val_loss: 99.6389\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 655574.6340 - val_loss: 98.7994\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1122087.9616 - val_loss: 99.9923\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 724511.1967 - val_loss: 99.8290\n",
      "Epoch 2/2\n",
      " - 0s - loss: 768039.2393 - val_loss: 98.4704\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 840960.1619 - val_loss: 101.1750\n",
      "Epoch 2/2\n",
      " - 0s - loss: 611639.1481 - val_loss: 99.4496\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 629416.3169 - val_loss: 100.7767\n",
      "Epoch 2/2\n",
      " - 0s - loss: 589799.4005 - val_loss: 99.6733\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 554085.3849 - val_loss: 101.4858\n",
      "Epoch 2/2\n",
      " - 0s - loss: 528244.8557 - val_loss: 100.7465\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 642897.3334 - val_loss: 100.5322\n",
      "Epoch 2/2\n",
      " - 0s - loss: 476643.3264 - val_loss: 99.1055\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 453123.8731 - val_loss: 100.6286\n",
      "Epoch 2/2\n",
      " - 0s - loss: 445000.3542 - val_loss: 99.2542\n",
      "MAPE:  11.326343853748703\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 99.8668 - val_loss: 96.2943\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6465 - val_loss: 93.6074\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.3546 - val_loss: 93.7208\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.5102 - val_loss: 93.2276\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.8497 - val_loss: 92.4396\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6703 - val_loss: 91.1438\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.7118 - val_loss: 91.8083\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.2633 - val_loss: 91.5130\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.4765 - val_loss: 90.1596\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.2799 - val_loss: 91.3033\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.9539 - val_loss: 91.0480\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.6453 - val_loss: 90.7069\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.8961 - val_loss: 89.9352\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.6943 - val_loss: 90.6970\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.5937 - val_loss: 90.3898\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.7539 - val_loss: 90.9666\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.0267 - val_loss: 90.8573\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.1026 - val_loss: 89.8667\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.0194 - val_loss: 91.0032\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.1716 - val_loss: 89.5145\n",
      "MAPE:  12.949200196037935\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 620712.0455 - val_loss: 1673527.2937\n",
      "Epoch 2/2\n",
      " - 0s - loss: 324073.4914 - val_loss: 2148444.2000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 267196.3914 - val_loss: 2487091.1781\n",
      "Epoch 2/2\n",
      " - 0s - loss: 291705.9222 - val_loss: 2851371.4375\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 197994.8264 - val_loss: 3237395.7250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 216437.9280 - val_loss: 3360228.8250\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 236586.0029 - val_loss: 3496539.5000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 216576.2866 - val_loss: 3621108.7000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 371539.0081 - val_loss: 3593151.4750\n",
      "Epoch 2/2\n",
      " - 0s - loss: 171318.2283 - val_loss: 3514597.9500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 356984.8838 - val_loss: 3657840.9250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 205020.2170 - val_loss: 3702644.5500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 241547.7321 - val_loss: 3755741.6000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 279366.8840 - val_loss: 3901223.6000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 202712.6063 - val_loss: 3936417.3500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 137394.2084 - val_loss: 3967230.1500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 227142.9479 - val_loss: 3958854.3500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 222194.5520 - val_loss: 3972197.3500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 260519.8645 - val_loss: 3880104.5500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 177248.4219 - val_loss: 4051118.8000\n",
      "MAPE:  30.865528328408697\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 14s - loss: 563038.2187 - val_loss: 2654139.5250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 511043.2345 - val_loss: 2518632.2313\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 410481.2238 - val_loss: 2215545.5465\n",
      "Epoch 2/2\n",
      " - 0s - loss: 237997.1941 - val_loss: 2445102.3625\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 331940.3302 - val_loss: 2793715.6625\n",
      "Epoch 2/2\n",
      " - 0s - loss: 155421.1488 - val_loss: 2840402.9937\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 225916.0454 - val_loss: 2989777.8312\n",
      "Epoch 2/2\n",
      " - 0s - loss: 243414.5201 - val_loss: 3131150.1000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 211264.8789 - val_loss: 3217164.6594\n",
      "Epoch 2/2\n",
      " - 0s - loss: 240258.1427 - val_loss: 3234584.4562\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 254586.0386 - val_loss: 3378483.2109\n",
      "Epoch 2/2\n",
      " - 0s - loss: 149844.1171 - val_loss: 3006006.7406\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 478240.5025 - val_loss: 3104403.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 0s - loss: 245654.7483 - val_loss: 2996551.6875\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 175294.4742 - val_loss: 3140923.8500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 118661.2316 - val_loss: 3168634.1500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 343864.8790 - val_loss: 3027064.7000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 219542.7449 - val_loss: 3078301.8750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 162229.7323 - val_loss: 3100927.8750\n",
      "Epoch 2/2\n",
      " - 0s - loss: 243003.3601 - val_loss: 3063124.9000\n",
      "MAPE:  41.68453238182146\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 12s - loss: 107.7790 - val_loss: 139.4424\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.8619 - val_loss: 129.1593\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.9597 - val_loss: 122.0930\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5330 - val_loss: 118.1083\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1369 - val_loss: 114.1351\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.6130 - val_loss: 115.7436\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.1844 - val_loss: 118.4296\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.2697 - val_loss: 120.2218\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1588 - val_loss: 122.6328\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6352 - val_loss: 125.2248\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1212 - val_loss: 129.2146\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.3105 - val_loss: 132.2169\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.1232 - val_loss: 135.6628\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6942 - val_loss: 134.7071\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.3199 - val_loss: 139.4097\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.7055 - val_loss: 141.9767\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.2945 - val_loss: 145.8807\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.3088 - val_loss: 147.7748\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.4176 - val_loss: 148.6053\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.1256 - val_loss: 155.1495\n",
      "MAPE:  21.367688014831213\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 12s - loss: 98.5237 - val_loss: 100.0376\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7168 - val_loss: 97.2766\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.8974 - val_loss: 94.1972\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.9953 - val_loss: 91.6814\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.9429 - val_loss: 91.8938\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.3234 - val_loss: 92.9507\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.3306 - val_loss: 94.3923\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.8945 - val_loss: 95.8287\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 79.9952 - val_loss: 97.6361\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.9601 - val_loss: 98.5459\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 80.1295 - val_loss: 98.4588\n",
      "Epoch 2/2\n",
      " - 0s - loss: 78.6512 - val_loss: 99.3127\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.9171 - val_loss: 99.9468\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.5423 - val_loss: 100.8942\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 79.4474 - val_loss: 99.7475\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.4815 - val_loss: 100.8279\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.7046 - val_loss: 100.8696\n",
      "Epoch 2/2\n",
      " - 0s - loss: 75.9766 - val_loss: 100.5761\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 76.5079 - val_loss: 101.7353\n",
      "Epoch 2/2\n",
      " - 0s - loss: 76.8650 - val_loss: 102.5956\n",
      "MAPE:  20.354316408346453\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 12s - loss: 105.6077 - val_loss: 100.0037\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.5253 - val_loss: 98.8918\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.8757 - val_loss: 98.0837\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5735 - val_loss: 98.5486\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.7099 - val_loss: 99.1559\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5500 - val_loss: 99.5531\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.8649 - val_loss: 100.3790\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5756 - val_loss: 100.2074\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.6551 - val_loss: 99.6412\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0062 - val_loss: 100.5846\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.8979 - val_loss: 100.6689\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.1117 - val_loss: 100.8231\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9560 - val_loss: 101.1518\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.3075 - val_loss: 102.0480\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4408 - val_loss: 103.1994\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1037 - val_loss: 102.1802\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1219 - val_loss: 101.8719\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6639 - val_loss: 103.8175\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9699 - val_loss: 103.7428\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6918 - val_loss: 102.3722\n",
      "MAPE:  24.139922371651096\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 10s - loss: 108.2730 - val_loss: 101.4082\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.9006 - val_loss: 101.3600\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.8928 - val_loss: 101.7835\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.3922 - val_loss: 101.0347\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.4189 - val_loss: 100.6543\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2706 - val_loss: 100.2982\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9167 - val_loss: 101.0339\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.9728 - val_loss: 100.8755\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.5346 - val_loss: 100.2992\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6153 - val_loss: 101.3313\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9119 - val_loss: 101.2740\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0372 - val_loss: 100.5160\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.2564 - val_loss: 100.4565\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7917 - val_loss: 101.8301\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2497 - val_loss: 101.6602\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.1524 - val_loss: 101.8281\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5235 - val_loss: 102.2121\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.2288 - val_loss: 102.7319\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8876 - val_loss: 101.9307\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6109 - val_loss: 100.9733\n",
      "MAPE:  12.22199827842073\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 14s - loss: 64970.2058 - val_loss: 865761.2609\n",
      "Epoch 2/2\n",
      " - 0s - loss: 194987.6272 - val_loss: 1168248.4625\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 60560.1246 - val_loss: 1304279.8250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 57028.1005 - val_loss: 1386719.3875\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 51365.7976 - val_loss: 1473559.9250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99355.8109 - val_loss: 1508182.1750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 45215.5923 - val_loss: 1632185.6000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91082.1793 - val_loss: 1824911.5125\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81153.3742 - val_loss: 1950616.3125\n",
      "Epoch 2/2\n",
      " - 0s - loss: 112768.0193 - val_loss: 2033703.6875\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 30284.9602 - val_loss: 2172734.4875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 76628.7822 - val_loss: 2290673.7125\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 33729.6369 - val_loss: 2344597.3875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 71838.3184 - val_loss: 2390699.3500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 37173.1738 - val_loss: 2379879.2375\n",
      "Epoch 2/2\n",
      " - 0s - loss: 32144.7492 - val_loss: 2413995.6750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 51386.6255 - val_loss: 2440551.4625\n",
      "Epoch 2/2\n",
      " - 0s - loss: 71833.5839 - val_loss: 2612844.9125\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 33362.8241 - val_loss: 2637582.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 0s - loss: 57838.4732 - val_loss: 2651329.8687\n",
      "MAPE:  7.741239527146268\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 14s - loss: 101.3746 - val_loss: 99.2763\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1321 - val_loss: 98.5890\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4785 - val_loss: 97.2553\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5398 - val_loss: 96.3379\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7960 - val_loss: 95.1184\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5587 - val_loss: 93.2750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.8681 - val_loss: 93.3743\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.7736 - val_loss: 93.0126\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1337 - val_loss: 92.3606\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.1757 - val_loss: 92.8142\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.6949 - val_loss: 92.8390\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.0559 - val_loss: 92.4154\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.0675 - val_loss: 91.4286\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.4822 - val_loss: 91.9736\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.3162 - val_loss: 92.2342\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.2831 - val_loss: 91.5401\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.9539 - val_loss: 90.8919\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6802 - val_loss: 92.4250\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.5759 - val_loss: 90.9290\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.7732 - val_loss: 91.0731\n",
      "MAPE:  9.25306074517948\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 14s - loss: 101.8773 - val_loss: 98.5434\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1878 - val_loss: 98.3225\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.9588 - val_loss: 97.4180\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2997 - val_loss: 97.2603\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7810 - val_loss: 96.1102\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7900 - val_loss: 96.1189\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5947 - val_loss: 95.5191\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3687 - val_loss: 96.0109\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5314 - val_loss: 95.5647\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7952 - val_loss: 94.7330\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4768 - val_loss: 93.9201\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3735 - val_loss: 94.4943\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7058 - val_loss: 94.6570\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.8188 - val_loss: 93.5997\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.0913 - val_loss: 93.8786\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4732 - val_loss: 93.0285\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4532 - val_loss: 93.4886\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.8342 - val_loss: 93.3235\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.6951 - val_loss: 91.9458\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.0174 - val_loss: 92.3095\n",
      "MAPE:  9.324099659644586\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 14s - loss: 98.6278 - val_loss: 1685743.5813\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4728 - val_loss: 1262180.5500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9890 - val_loss: 1285823.7875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.1500 - val_loss: 1231636.8125\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4843 - val_loss: 1287336.0250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.1547 - val_loss: 1398137.6500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.5058 - val_loss: 1574357.7812\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.2225 - val_loss: 1420512.8062\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.0715 - val_loss: 1395799.6000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1240 - val_loss: 1516130.4625\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.1441 - val_loss: 1454147.8313\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.4822 - val_loss: 1551188.1750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.9099 - val_loss: 1577113.1992\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.7164 - val_loss: 1609420.9156\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.6475 - val_loss: 1820168.3813\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.4391 - val_loss: 1199837.8422\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1730 - val_loss: 1249635.1313\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.1292 - val_loss: 1212095.5398\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.2820 - val_loss: 1445052.4656\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.8325 - val_loss: 1490647.6500\n",
      "MAPE:  14.499682386629775\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 105.2106 - val_loss: 98.3471\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.0314 - val_loss: 97.4314\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.2421 - val_loss: 99.2306\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0906 - val_loss: 101.1370\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.0111 - val_loss: 103.1809\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.3057 - val_loss: 105.5912\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.2877 - val_loss: 107.3468\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.2334 - val_loss: 109.0183\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.8359 - val_loss: 111.4549\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.8438 - val_loss: 110.3378\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.9224 - val_loss: 110.3320\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.6702 - val_loss: 111.0755\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.1072 - val_loss: 111.9270\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.4477 - val_loss: 114.0387\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.9701 - val_loss: 115.0915\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.4533 - val_loss: 116.9816\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.6923 - val_loss: 114.6735\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.9343 - val_loss: 115.2712\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.1694 - val_loss: 116.6008\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.1269 - val_loss: 116.3061\n",
      "MAPE:  32.17974632874597\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 104.1405 - val_loss: 98.6918\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.5790 - val_loss: 99.8205\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.7473 - val_loss: 99.1336\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.4411 - val_loss: 100.1585\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0288 - val_loss: 99.5613\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4869 - val_loss: 99.6391\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.6511 - val_loss: 100.6672\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3163 - val_loss: 99.5634\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8549 - val_loss: 99.5148\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5546 - val_loss: 99.8076\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5030 - val_loss: 100.2681\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2135 - val_loss: 100.9386\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8751 - val_loss: 101.0517\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2003 - val_loss: 99.4347\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.5666 - val_loss: 100.2810\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5310 - val_loss: 101.2902\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7229 - val_loss: 100.8641\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7497 - val_loss: 101.7459\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7379 - val_loss: 102.9084\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0630 - val_loss: 101.7265\n",
      "MAPE:  23.920658214696854\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 11s - loss: 658704.1952 - val_loss: 1024739.0437\n",
      "Epoch 2/2\n",
      " - 0s - loss: 448803.6740 - val_loss: 1226082.7812\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 398208.8183 - val_loss: 1284622.0469\n",
      "Epoch 2/2\n",
      " - 0s - loss: 292912.6994 - val_loss: 1554343.0562\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 235573.9890 - val_loss: 1689762.8375\n",
      "Epoch 2/2\n",
      " - 0s - loss: 168302.9031 - val_loss: 1830121.4750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 355069.2294 - val_loss: 2009245.0000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 230404.2311 - val_loss: 2170106.1250\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 161336.9973 - val_loss: 2258400.0000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 251076.5547 - val_loss: 2192185.3750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 171021.2109 - val_loss: 2249591.3250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 372025.9646 - val_loss: 2356803.2000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 215282.3776 - val_loss: 2408801.1250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 270037.2548 - val_loss: 2419191.9000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 246980.4420 - val_loss: 2509523.8000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 259472.3927 - val_loss: 2448900.0750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 232355.7385 - val_loss: 2350520.1000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 322256.0621 - val_loss: 2346302.1500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 163497.2508 - val_loss: 2415735.4500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 224407.6123 - val_loss: 2581413.4250\n",
      "MAPE:  19.730662872028066\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 12s - loss: 107.0963 - val_loss: 101.5928\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.7566 - val_loss: 100.1111\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.7994 - val_loss: 99.4472\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.1403 - val_loss: 99.4397\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.2070 - val_loss: 99.4874\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6939 - val_loss: 98.8763\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.1868 - val_loss: 99.6360\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.9939 - val_loss: 99.3227\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.8777 - val_loss: 99.0110\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1213 - val_loss: 98.2914\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.8907 - val_loss: 100.6965\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5915 - val_loss: 100.7062\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.0006 - val_loss: 99.9510\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6733 - val_loss: 99.3434\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3190 - val_loss: 99.5543\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.0134 - val_loss: 99.2489\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.6516 - val_loss: 100.0456\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5637 - val_loss: 100.4115\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.8865 - val_loss: 101.6635\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2331 - val_loss: 102.2236\n",
      "MAPE:  8.660256795148706\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 15s - loss: 110.5203 - val_loss: 114.4362\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.8768 - val_loss: 114.2714\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 107.0252 - val_loss: 113.0365\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.1733 - val_loss: 112.1258\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.5179 - val_loss: 108.9841\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.8890 - val_loss: 108.5069\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.1466 - val_loss: 107.6423\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.1760 - val_loss: 107.6372\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.5195 - val_loss: 106.0093\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.2105 - val_loss: 106.6246\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.0275 - val_loss: 106.3991\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.6281 - val_loss: 104.9057\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.2152 - val_loss: 104.5058\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.0493 - val_loss: 105.3430\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3473 - val_loss: 105.4372\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2001 - val_loss: 104.7569\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.8034 - val_loss: 103.9493\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8122 - val_loss: 104.2947\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9375 - val_loss: 104.1710\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5988 - val_loss: 104.2279\n",
      "MAPE:  9.887832773391493\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 12s - loss: 98.8564 - val_loss: 100.4023\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0767 - val_loss: 102.4974\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.2117 - val_loss: 106.6069\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.2046 - val_loss: 116.3651\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.0402 - val_loss: 122.6837\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.3658 - val_loss: 128.3086\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.1478 - val_loss: 137.2968\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.3108 - val_loss: 145.9480\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.9446 - val_loss: 144.7291\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.6845 - val_loss: 137.0534\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.4215 - val_loss: 159.1691\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.8083 - val_loss: 150.7879\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.8334 - val_loss: 146.4642\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.6245 - val_loss: 143.4899\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81.0806 - val_loss: 153.2311\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.2564 - val_loss: 148.7916\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 80.7397 - val_loss: 150.2168\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.6224 - val_loss: 147.1590\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.4978 - val_loss: 157.7082\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.0372 - val_loss: 148.4657\n",
      "MAPE:  8.144697737281797\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 12s - loss: 104.1737 - val_loss: 103.0847\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.5547 - val_loss: 104.3864\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.6425 - val_loss: 108.4365\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.0954 - val_loss: 111.9671\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.5792 - val_loss: 115.7463\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.8955 - val_loss: 118.2765\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.7673 - val_loss: 121.6207\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5585 - val_loss: 123.8145\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3448 - val_loss: 123.2550\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.0978 - val_loss: 123.9782\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.5689 - val_loss: 125.1433\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4489 - val_loss: 124.5356\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.6968 - val_loss: 125.2294\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.9747 - val_loss: 125.6068\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.4299 - val_loss: 127.3190\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5837 - val_loss: 126.9126\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8152 - val_loss: 125.7691\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6585 - val_loss: 125.5538\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.5090 - val_loss: 124.7958\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9209 - val_loss: 125.6154\n",
      "MAPE:  8.314694566719155\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 12s - loss: 1367122.1858 - val_loss: 107.5295\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1438123.2502 - val_loss: 102.1700\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1099874.2424 - val_loss: 102.1502\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1019627.9682 - val_loss: 102.9143\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 537311.5611 - val_loss: 98.7225\n",
      "Epoch 2/2\n",
      " - 0s - loss: 848010.5218 - val_loss: 98.5889\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 704977.0058 - val_loss: 106.3812\n",
      "Epoch 2/2\n",
      " - 0s - loss: 745101.8578 - val_loss: 103.4510\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 483336.5974 - val_loss: 100.4288\n",
      "Epoch 2/2\n",
      " - 0s - loss: 483789.2566 - val_loss: 102.7298\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 537527.6246 - val_loss: 101.5328\n",
      "Epoch 2/2\n",
      " - 0s - loss: 567502.4250 - val_loss: 100.5120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 380076.0614 - val_loss: 98.3273\n",
      "Epoch 2/2\n",
      " - 0s - loss: 480808.2654 - val_loss: 103.7767\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 383648.6120 - val_loss: 103.1725\n",
      "Epoch 2/2\n",
      " - 0s - loss: 379676.4010 - val_loss: 104.8338\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 384233.8441 - val_loss: 98.2785\n",
      "Epoch 2/2\n",
      " - 0s - loss: 340218.8236 - val_loss: 96.5757\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 614427.9206 - val_loss: 97.2975\n",
      "Epoch 2/2\n",
      " - 0s - loss: 353636.9574 - val_loss: 98.1658\n",
      "MAPE:  9.44193869066552\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 12s - loss: 98.5141 - val_loss: 104.6061\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.9307 - val_loss: 101.0829\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.6005 - val_loss: 100.1232\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.3859 - val_loss: 101.3303\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.6154 - val_loss: 102.6948\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6874 - val_loss: 102.6630\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.7848 - val_loss: 105.7711\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.3413 - val_loss: 108.6710\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.5166 - val_loss: 112.0774\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.2678 - val_loss: 113.2853\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.8192 - val_loss: 116.5155\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.1015 - val_loss: 116.1287\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.9834 - val_loss: 117.3387\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.2909 - val_loss: 123.0233\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.0810 - val_loss: 129.8971\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.9328 - val_loss: 129.9030\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.4995 - val_loss: 136.5593\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.8375 - val_loss: 139.8516\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.2162 - val_loss: 141.8595\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.8932 - val_loss: 140.6072\n",
      "MAPE:  6.843165485639616\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 13s - loss: 102.4667 - val_loss: 100.3567\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.6666 - val_loss: 100.8596\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4486 - val_loss: 100.6163\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.0848 - val_loss: 99.5345\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7527 - val_loss: 98.4085\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4507 - val_loss: 97.4667\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.4519 - val_loss: 97.8337\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5265 - val_loss: 97.9549\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7968 - val_loss: 97.7705\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2793 - val_loss: 98.6975\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.2417 - val_loss: 98.7532\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6927 - val_loss: 99.4279\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7382 - val_loss: 99.3076\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.2756 - val_loss: 100.0654\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3758 - val_loss: 100.7161\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5549 - val_loss: 100.8465\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.7571 - val_loss: 101.2756\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7203 - val_loss: 101.5483\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4449 - val_loss: 101.6269\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6853 - val_loss: 100.5118\n",
      "MAPE:  8.601092872783363\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 12s - loss: 498055.7116 - val_loss: 525867.0344\n",
      "Epoch 2/2\n",
      " - 0s - loss: 616004.8028 - val_loss: 590447.5277\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 287320.2732 - val_loss: 731703.5594\n",
      "Epoch 2/2\n",
      " - 0s - loss: 367968.2367 - val_loss: 887056.4000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 217661.1128 - val_loss: 987902.2125\n",
      "Epoch 2/2\n",
      " - 0s - loss: 290370.6720 - val_loss: 885191.4047\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 321714.6363 - val_loss: 881669.9766\n",
      "Epoch 2/2\n",
      " - 0s - loss: 263362.1159 - val_loss: 1023894.1062\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 168337.5938 - val_loss: 918975.2312\n",
      "Epoch 2/2\n",
      " - 0s - loss: 356599.7930 - val_loss: 782644.6453\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 187227.5701 - val_loss: 832901.4563\n",
      "Epoch 2/2\n",
      " - 0s - loss: 335332.3438 - val_loss: 846139.1766\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 240395.3513 - val_loss: 736392.2063\n",
      "Epoch 2/2\n",
      " - 0s - loss: 284413.4546 - val_loss: 756230.9328\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 153800.2392 - val_loss: 759316.4062\n",
      "Epoch 2/2\n",
      " - 0s - loss: 283116.9731 - val_loss: 642602.6453\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 200016.6624 - val_loss: 674297.8219\n",
      "Epoch 2/2\n",
      " - 0s - loss: 285016.9975 - val_loss: 657955.8219\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 160400.4681 - val_loss: 704773.8469\n",
      "Epoch 2/2\n",
      " - 0s - loss: 305310.9817 - val_loss: 779444.8375\n",
      "MAPE:  14.42346179846455\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 13s - loss: 99.9599 - val_loss: 111.3910\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5290 - val_loss: 102.4706\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2246 - val_loss: 102.1170\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8201 - val_loss: 104.0246\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3662 - val_loss: 104.3257\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7312 - val_loss: 107.5199\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.6171 - val_loss: 108.1166\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.9591 - val_loss: 109.3857\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.5589 - val_loss: 113.5042\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6100 - val_loss: 114.0701\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.3391 - val_loss: 115.0653\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.3797 - val_loss: 116.1915\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.5575 - val_loss: 119.9671\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1283 - val_loss: 120.5672\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.7792 - val_loss: 116.5452\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.2564 - val_loss: 119.9835\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.3225 - val_loss: 118.8204\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.5194 - val_loss: 119.4387\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.0916 - val_loss: 120.6715\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.0830 - val_loss: 121.5030\n",
      "MAPE:  22.708172780169583\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 13s - loss: 1177306.7591 - val_loss: 1468126.2250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 558896.0117 - val_loss: 1421571.9574\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 384645.4476 - val_loss: 1514066.6531\n",
      "Epoch 2/2\n",
      " - 0s - loss: 444664.5684 - val_loss: 1271352.4310\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 415645.7851 - val_loss: 1596202.0406\n",
      "Epoch 2/2\n",
      " - 0s - loss: 496714.3547 - val_loss: 1305369.0688\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 347904.8334 - val_loss: 1216332.8000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 522174.8339 - val_loss: 1126121.7812\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 259229.0432 - val_loss: 1425945.1938\n",
      "Epoch 2/2\n",
      " - 0s - loss: 530719.3157 - val_loss: 1019718.7453\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 313934.6056 - val_loss: 993249.8711\n",
      "Epoch 2/2\n",
      " - 0s - loss: 487061.7823 - val_loss: 1061662.2937\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 275534.6802 - val_loss: 1016739.0437\n",
      "Epoch 2/2\n",
      " - 0s - loss: 400322.6373 - val_loss: 921476.7469\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 241351.7791 - val_loss: 780005.8438\n",
      "Epoch 2/2\n",
      " - 0s - loss: 457927.5695 - val_loss: 983093.4000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 246795.1156 - val_loss: 761538.8125\n",
      "Epoch 2/2\n",
      " - 0s - loss: 408527.0287 - val_loss: 954826.1000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 248719.9629 - val_loss: 713618.5031\n",
      "Epoch 2/2\n",
      " - 0s - loss: 343280.4623 - val_loss: 930084.9187\n",
      "MAPE:  46.625021161652924\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 13s - loss: 100.6374 - val_loss: 97.9248\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.6174 - val_loss: 95.8146\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.0960 - val_loss: 95.0737\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5911 - val_loss: 93.3202\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.7992 - val_loss: 95.2807\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.2586 - val_loss: 96.1178\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.9632 - val_loss: 97.8119\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.9511 - val_loss: 97.7657\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.9673 - val_loss: 98.4230\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.9466 - val_loss: 99.0015\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.8546 - val_loss: 100.1273\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.3982 - val_loss: 99.5986\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.7060 - val_loss: 100.1822\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.7118 - val_loss: 101.1564\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.8101 - val_loss: 101.6499\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.4904 - val_loss: 101.9190\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.8591 - val_loss: 103.2634\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.0855 - val_loss: 101.9935\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.4948 - val_loss: 101.7576\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.4517 - val_loss: 103.1272\n",
      "MAPE:  45.72301396199909\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 13s - loss: 107.0429 - val_loss: 132.4897\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.7671 - val_loss: 137.4802\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7060 - val_loss: 139.3662\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.9796 - val_loss: 138.8270\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.9009 - val_loss: 142.1582\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.8788 - val_loss: 147.0056\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.7013 - val_loss: 146.8638\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.0371 - val_loss: 150.0244\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.9041 - val_loss: 151.1617\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.6893 - val_loss: 155.4301\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.5908 - val_loss: 155.0787\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.0154 - val_loss: 150.4534\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.7128 - val_loss: 148.7228\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.4521 - val_loss: 152.6461\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.4724 - val_loss: 151.4125\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.1701 - val_loss: 151.1405\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.2220 - val_loss: 151.4504\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.4706 - val_loss: 153.6644\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.6394 - val_loss: 153.4473\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.1727 - val_loss: 152.3671\n",
      "MAPE:  39.9898964651671\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 13s - loss: 114.7179 - val_loss: 104.2797\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.9320 - val_loss: 100.7873\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 106.6149 - val_loss: 100.8829\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.1167 - val_loss: 101.8156\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.7674 - val_loss: 100.6567\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.4585 - val_loss: 99.5770\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.3059 - val_loss: 100.7252\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.4969 - val_loss: 99.7896\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.1222 - val_loss: 98.5045\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.6845 - val_loss: 99.5415\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.8012 - val_loss: 96.3950\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2716 - val_loss: 101.5120\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.5555 - val_loss: 96.7878\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2915 - val_loss: 98.0885\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3383 - val_loss: 99.8274\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.8755 - val_loss: 100.3852\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3815 - val_loss: 97.7133\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.4797 - val_loss: 101.6271\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.7889 - val_loss: 99.5438\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.7088 - val_loss: 98.8437\n",
      "MAPE:  29.823963603294846\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 13s - loss: 75120.6382 - val_loss: 102.1482\n",
      "Epoch 2/2\n",
      " - 0s - loss: 158462.8068 - val_loss: 104.1724\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 151496.5334 - val_loss: 101.2718\n",
      "Epoch 2/2\n",
      " - 0s - loss: 130602.8370 - val_loss: 101.9457\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 149401.9658 - val_loss: 100.0389\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94494.9566 - val_loss: 100.6425\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 114322.3171 - val_loss: 98.2459\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94262.4453 - val_loss: 99.1551\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 119096.9385 - val_loss: 98.6291\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83255.4444 - val_loss: 99.0991\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97859.0270 - val_loss: 98.0092\n",
      "Epoch 2/2\n",
      " - 0s - loss: 112342.9049 - val_loss: 93.8963\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 127700.0760 - val_loss: 96.5495\n",
      "Epoch 2/2\n",
      " - 0s - loss: 71802.7621 - val_loss: 96.2706\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 135104.3183 - val_loss: 96.0188\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82214.0909 - val_loss: 97.8709\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 140315.0344 - val_loss: 95.4027\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90457.0586 - val_loss: 91.5845\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 138132.8657 - val_loss: 94.7367\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101995.5476 - val_loss: 95.1365\n",
      "MAPE:  40.28713165087547\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 14s - loss: 97.8118 - val_loss: 100.6481\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.7023 - val_loss: 93.6654\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.1990 - val_loss: 87.6077\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.7109 - val_loss: 85.9976\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 78.2062 - val_loss: 84.5155\n",
      "Epoch 2/2\n",
      " - 0s - loss: 77.3826 - val_loss: 82.4238\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 75.9631 - val_loss: 80.8367\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.7361 - val_loss: 81.4692\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 74.3833 - val_loss: 81.5471\n",
      "Epoch 2/2\n",
      " - 0s - loss: 73.6910 - val_loss: 81.2841\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.8032 - val_loss: 81.1988\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.2091 - val_loss: 81.7025\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.6665 - val_loss: 82.0963\n",
      "Epoch 2/2\n",
      " - 0s - loss: 73.6181 - val_loss: 82.2923\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.5221 - val_loss: 82.0508\n",
      "Epoch 2/2\n",
      " - 0s - loss: 73.4600 - val_loss: 81.8740\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.1254 - val_loss: 82.2908\n",
      "Epoch 2/2\n",
      " - 0s - loss: 73.3564 - val_loss: 82.2160\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 72.7172 - val_loss: 81.7455\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.9595 - val_loss: 82.2400\n",
      "MAPE:  55.200543341837985\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 14s - loss: 3445278.8866 - val_loss: 1487255.6205\n",
      "Epoch 2/2\n",
      " - 0s - loss: 2586491.5622 - val_loss: 1467402.6268\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 1312529.5836 - val_loss: 1656322.2403\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1024134.5848 - val_loss: 1881341.4583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 638841.7258 - val_loss: 2117491.1085\n",
      "Epoch 2/2\n",
      " - 0s - loss: 861203.3183 - val_loss: 2188757.5565\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 887247.5418 - val_loss: 2537451.2459\n",
      "Epoch 2/2\n",
      " - 0s - loss: 839917.1557 - val_loss: 2544971.7186\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 681627.6757 - val_loss: 2859908.0645\n",
      "Epoch 2/2\n",
      " - 0s - loss: 569045.5301 - val_loss: 3030563.6007\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 601416.4899 - val_loss: 2956110.3978\n",
      "Epoch 2/2\n",
      " - 0s - loss: 581619.1493 - val_loss: 3234978.3531\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 334397.4179 - val_loss: 3386661.5500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 545560.3770 - val_loss: 3529056.1594\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 541807.9596 - val_loss: 3497457.8749\n",
      "Epoch 2/2\n",
      " - 0s - loss: 390683.4149 - val_loss: 3662703.3776\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 478625.5907 - val_loss: 3522529.6225\n",
      "Epoch 2/2\n",
      " - 0s - loss: 419796.0734 - val_loss: 3567744.3276\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 301737.4297 - val_loss: 3612323.0117\n",
      "Epoch 2/2\n",
      " - 0s - loss: 316623.5746 - val_loss: 3616198.8296\n",
      "MAPE:  38.65635219603195\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 13s - loss: 117.1890 - val_loss: 103.6679\n",
      "Epoch 2/2\n",
      " - 0s - loss: 107.8202 - val_loss: 101.7615\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 108.0125 - val_loss: 103.2784\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.5601 - val_loss: 102.9456\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 103.7369 - val_loss: 101.3578\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.4377 - val_loss: 102.1092\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.2595 - val_loss: 102.3313\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.7144 - val_loss: 104.2635\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.4500 - val_loss: 105.5678\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2297 - val_loss: 103.8814\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.8956 - val_loss: 103.7784\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5733 - val_loss: 104.3478\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3489 - val_loss: 104.1723\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2529 - val_loss: 103.6091\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4050 - val_loss: 106.6184\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5229 - val_loss: 108.3618\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.6164 - val_loss: 108.3639\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.3779 - val_loss: 105.3015\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0611 - val_loss: 107.2415\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1820 - val_loss: 106.7757\n",
      "MAPE:  16.430742567839474\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 15s - loss: 103.4667 - val_loss: 96.7389\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.2087 - val_loss: 96.0799\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.0741 - val_loss: 97.9959\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4098 - val_loss: 98.5047\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2001 - val_loss: 100.7937\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2916 - val_loss: 100.7131\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5333 - val_loss: 101.0786\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0802 - val_loss: 103.1344\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9748 - val_loss: 103.1846\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5533 - val_loss: 103.0654\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.7057 - val_loss: 104.0851\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7862 - val_loss: 106.9053\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9193 - val_loss: 108.2029\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.9717 - val_loss: 107.3069\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.5674 - val_loss: 107.7096\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.9697 - val_loss: 109.7221\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.0614 - val_loss: 109.8485\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.4920 - val_loss: 111.0585\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1795 - val_loss: 106.4696\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.0088 - val_loss: 109.3532\n",
      "MAPE:  22.20142792616655\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 99.8977 - val_loss: 1097321.5813\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.1495 - val_loss: 1057538.5375\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.8715 - val_loss: 1050272.2500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7688 - val_loss: 1065320.4031\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7468 - val_loss: 1479704.7625\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.3909 - val_loss: 1715674.8625\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4276 - val_loss: 2059450.6875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7604 - val_loss: 2464545.3750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.9641 - val_loss: 2697416.1250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.2520 - val_loss: 2859251.8000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.9769 - val_loss: 2651268.9000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.2299 - val_loss: 2789936.7500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1911 - val_loss: 3087336.3875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.2844 - val_loss: 2848998.9750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.8979 - val_loss: 2727331.8687\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.0444 - val_loss: 2728428.2687\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.9320 - val_loss: 2563723.3219\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.3923 - val_loss: 2611206.6875\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.5859 - val_loss: 2725303.4500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.3014 - val_loss: 2957847.0000\n",
      "MAPE:  10.095155525331325\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 103.4939 - val_loss: 102.8827\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.4264 - val_loss: 101.5708\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.6650 - val_loss: 100.1883\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5389 - val_loss: 98.9135\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.4801 - val_loss: 98.8601\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.2740 - val_loss: 97.5236\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.7931 - val_loss: 96.5627\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.2459 - val_loss: 97.1002\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.9055 - val_loss: 95.8850\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.0768 - val_loss: 94.4304\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.1942 - val_loss: 95.3573\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.7524 - val_loss: 93.1313\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.4901 - val_loss: 94.4206\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.8796 - val_loss: 95.4145\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.4740 - val_loss: 92.6227\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.4588 - val_loss: 94.2009\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.4475 - val_loss: 97.8509\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.5040 - val_loss: 96.5008\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.4369 - val_loss: 98.0563\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.5971 - val_loss: 98.1252\n",
      "MAPE:  11.705398059467925\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 14s - loss: 114.8463 - val_loss: 114.4517\n",
      "Epoch 2/2\n",
      " - 0s - loss: 110.1718 - val_loss: 113.7131\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 105.2562 - val_loss: 111.2393\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.9560 - val_loss: 110.6170\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.7812 - val_loss: 110.5630\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.3790 - val_loss: 106.5621\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.5135 - val_loss: 107.8301\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9634 - val_loss: 106.3409\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7934 - val_loss: 106.6435\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4080 - val_loss: 104.9737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.1759 - val_loss: 105.0386\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.1657 - val_loss: 103.1202\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4498 - val_loss: 105.1688\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5932 - val_loss: 103.8172\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2350 - val_loss: 101.7143\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2210 - val_loss: 102.7879\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9080 - val_loss: 102.4724\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0169 - val_loss: 102.3219\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.1424 - val_loss: 102.5997\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.0331 - val_loss: 101.6185\n",
      "MAPE:  11.313988178583086\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 21s - loss: 105.2489 - val_loss: 100.8275\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.0426 - val_loss: 102.6449\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.2912 - val_loss: 103.8654\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3270 - val_loss: 103.3932\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.2241 - val_loss: 104.4313\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6720 - val_loss: 104.2178\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9807 - val_loss: 105.4846\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1203 - val_loss: 104.5583\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.8500 - val_loss: 104.6938\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.0671 - val_loss: 104.5098\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.0917 - val_loss: 105.3868\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.2236 - val_loss: 106.2261\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.8041 - val_loss: 107.1311\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.1365 - val_loss: 107.8872\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.5958 - val_loss: 108.6592\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6710 - val_loss: 107.7097\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.6733 - val_loss: 109.5990\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.7157 - val_loss: 111.4648\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.1352 - val_loss: 111.1900\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.7605 - val_loss: 113.1819\n",
      "MAPE:  12.288382271305519\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 15s - loss: 630352.1266 - val_loss: 93.9781\n",
      "Epoch 2/2\n",
      " - 0s - loss: 730959.8754 - val_loss: 95.3204\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 218188.7405 - val_loss: 93.1899\n",
      "Epoch 2/2\n",
      " - 0s - loss: 403541.4493 - val_loss: 93.2806\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 370227.7640 - val_loss: 94.1043\n",
      "Epoch 2/2\n",
      " - 0s - loss: 230582.5742 - val_loss: 90.9956\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 350436.5737 - val_loss: 94.4016\n",
      "Epoch 2/2\n",
      " - 0s - loss: 298474.3715 - val_loss: 91.8852\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 152484.8219 - val_loss: 94.7870\n",
      "Epoch 2/2\n",
      " - 0s - loss: 410519.1633 - val_loss: 92.6742\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 265513.3095 - val_loss: 92.8715\n",
      "Epoch 2/2\n",
      " - 0s - loss: 287289.3496 - val_loss: 94.7714\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 132251.6948 - val_loss: 93.7471\n",
      "Epoch 2/2\n",
      " - 0s - loss: 302964.6089 - val_loss: 92.7983\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 225079.2859 - val_loss: 95.3910\n",
      "Epoch 2/2\n",
      " - 0s - loss: 249594.8945 - val_loss: 94.8717\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 295248.1440 - val_loss: 94.2587\n",
      "Epoch 2/2\n",
      " - 0s - loss: 217747.4581 - val_loss: 95.7719\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 234439.0504 - val_loss: 94.1310\n",
      "Epoch 2/2\n",
      " - 0s - loss: 226887.5457 - val_loss: 94.7136\n",
      "MAPE:  64.66575236061455\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 14s - loss: 97.6102 - val_loss: 109.6079\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.9595 - val_loss: 105.5092\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.1100 - val_loss: 103.2192\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.0313 - val_loss: 102.6342\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.4321 - val_loss: 102.3962\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.5275 - val_loss: 101.3835\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.0755 - val_loss: 101.6249\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.0104 - val_loss: 102.2883\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.6712 - val_loss: 101.6917\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.3793 - val_loss: 101.6988\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.2268 - val_loss: 103.8198\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.3462 - val_loss: 104.7697\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.7621 - val_loss: 106.3661\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.5361 - val_loss: 106.3713\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.3821 - val_loss: 106.9999\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.9635 - val_loss: 108.3499\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.7390 - val_loss: 107.4898\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.6336 - val_loss: 109.4288\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.2354 - val_loss: 109.2745\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.0289 - val_loss: 111.5293\n",
      "MAPE:  25.607245830130754\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 14s - loss: 100.8197 - val_loss: 589139.7438\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.0233 - val_loss: 978065.6375\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.0102 - val_loss: 1003228.4313\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5795 - val_loss: 1093438.9875\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9164 - val_loss: 1343096.5875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3496 - val_loss: 1273263.4859\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4893 - val_loss: 1182857.8375\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7219 - val_loss: 1538925.5500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.6412 - val_loss: 1520710.4250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8839 - val_loss: 1218292.4500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8613 - val_loss: 1677003.7500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.9391 - val_loss: 1686672.3687\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.6359 - val_loss: 1450187.5250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0859 - val_loss: 1746756.2500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.6748 - val_loss: 2002293.7000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6184 - val_loss: 1585387.2250\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.6283 - val_loss: 1713072.2000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5297 - val_loss: 1756207.8375\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4732 - val_loss: 1589563.2250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5221 - val_loss: 1969756.1125\n",
      "MAPE:  14.041910888943201\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 98.2643 - val_loss: 89.9043\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.8052 - val_loss: 86.4944\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.6389 - val_loss: 83.7411\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5050 - val_loss: 79.7339\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.2696 - val_loss: 76.4549\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.8105 - val_loss: 75.3220\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.0057 - val_loss: 75.1237\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.9213 - val_loss: 74.3092\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.7143 - val_loss: 74.0168\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.5488 - val_loss: 74.0499\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.1876 - val_loss: 73.5007\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.2543 - val_loss: 71.7923\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.3016 - val_loss: 71.2925\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.4724 - val_loss: 71.2441\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.1242 - val_loss: 71.7934\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.6183 - val_loss: 70.9106\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 86.9625 - val_loss: 70.6344\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.6649 - val_loss: 70.8821\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.9671 - val_loss: 69.7279\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.5311 - val_loss: 70.9359\n",
      "MAPE:  27.661305755076317\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 15s - loss: 102.6396 - val_loss: 103.5408\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.3367 - val_loss: 105.5110\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.8817 - val_loss: 107.6465\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2769 - val_loss: 107.9085\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.5018 - val_loss: 106.5819\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6753 - val_loss: 106.0613\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.7954 - val_loss: 104.8624\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.8100 - val_loss: 102.0322\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.2668 - val_loss: 99.3144\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.5801 - val_loss: 95.0963\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.1938 - val_loss: 95.7512\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.6816 - val_loss: 93.2164\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.8890 - val_loss: 89.8468\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.6186 - val_loss: 93.1061\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.5569 - val_loss: 92.1030\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.9070 - val_loss: 96.0799\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.0202 - val_loss: 93.2461\n",
      "Epoch 2/2\n",
      " - 0s - loss: 84.3645 - val_loss: 97.0136\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 80.9628 - val_loss: 97.1813\n",
      "Epoch 2/2\n",
      " - 0s - loss: 80.6179 - val_loss: 95.4178\n",
      "MAPE:  46.516278242266374\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 15s - loss: 505389.3577 - val_loss: 1579805.7875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 397173.6728 - val_loss: 1648392.9688\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 303433.3598 - val_loss: 1628388.0047\n",
      "Epoch 2/2\n",
      " - 0s - loss: 204586.8326 - val_loss: 1516428.8703\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 175663.2728 - val_loss: 1561676.2563\n",
      "Epoch 2/2\n",
      " - 0s - loss: 159935.7703 - val_loss: 1587434.4594\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 213023.0370 - val_loss: 1592425.5562\n",
      "Epoch 2/2\n",
      " - 0s - loss: 199330.0515 - val_loss: 1566980.4375\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 144811.4300 - val_loss: 1527898.1531\n",
      "Epoch 2/2\n",
      " - 0s - loss: 378497.9732 - val_loss: 1519017.6500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 227440.6293 - val_loss: 1564117.3625\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103296.6909 - val_loss: 1581429.2281\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 144188.0900 - val_loss: 1540707.0109\n",
      "Epoch 2/2\n",
      " - 0s - loss: 128110.7950 - val_loss: 1501765.8047\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 120171.4363 - val_loss: 1367662.9187\n",
      "Epoch 2/2\n",
      " - 0s - loss: 166794.8570 - val_loss: 1323687.7625\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 174657.7524 - val_loss: 1266016.6078\n",
      "Epoch 2/2\n",
      " - 0s - loss: 176508.4332 - val_loss: 1242564.5688\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 119270.8410 - val_loss: 1217144.9219\n",
      "Epoch 2/2\n",
      " - 0s - loss: 169472.4236 - val_loss: 1192563.5297\n",
      "MAPE:  30.712500048776793\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 100.8029 - val_loss: 101.5279\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.8283 - val_loss: 101.9337\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.4882 - val_loss: 103.0766\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3785 - val_loss: 103.6490\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4810 - val_loss: 106.1653\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7632 - val_loss: 109.8868\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.8464 - val_loss: 109.9801\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6507 - val_loss: 110.8917\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.0937 - val_loss: 111.2326\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6327 - val_loss: 113.7482\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.6183 - val_loss: 119.6625\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.5986 - val_loss: 120.3386\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.8506 - val_loss: 120.2056\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.4844 - val_loss: 122.2050\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.3145 - val_loss: 128.0806\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.4015 - val_loss: 121.2321\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.5347 - val_loss: 121.1970\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.9588 - val_loss: 125.6669\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.7128 - val_loss: 124.4784\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.3727 - val_loss: 123.4058\n",
      "MAPE:  20.66861597737175\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 103.2323 - val_loss: 121.9655\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2537 - val_loss: 132.0566\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.5774 - val_loss: 134.5272\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.1161 - val_loss: 136.9329\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9753 - val_loss: 136.8193\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.8739 - val_loss: 136.4200\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3671 - val_loss: 138.5069\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0323 - val_loss: 139.0480\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.0412 - val_loss: 138.2230\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.8730 - val_loss: 137.3151\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.1614 - val_loss: 138.6060\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.0294 - val_loss: 138.1490\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.2783 - val_loss: 136.6195\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6584 - val_loss: 137.9335\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.9432 - val_loss: 138.8076\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.9322 - val_loss: 138.6411\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.9098 - val_loss: 136.8895\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.7997 - val_loss: 135.5194\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.9169 - val_loss: 139.1290\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.8657 - val_loss: 140.8994\n",
      "MAPE:  13.91637438467947\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 118.8105 - val_loss: 129.0968\n",
      "Epoch 2/2\n",
      " - 0s - loss: 108.5463 - val_loss: 124.3452\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 109.3919 - val_loss: 125.4684\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.8863 - val_loss: 129.9650\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.8899 - val_loss: 124.9016\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.1853 - val_loss: 119.0443\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.5137 - val_loss: 122.9347\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.7609 - val_loss: 118.7725\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.6509 - val_loss: 113.2816\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.9590 - val_loss: 108.4476\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9577 - val_loss: 111.6845\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.9865 - val_loss: 110.8856\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.5727 - val_loss: 113.4788\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.7007 - val_loss: 115.5060\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2450 - val_loss: 117.7842\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.0436 - val_loss: 108.1075\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.9580 - val_loss: 111.4112\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6225 - val_loss: 107.4399\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.6867 - val_loss: 120.8487\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.9025 - val_loss: 117.7138\n",
      "MAPE:  20.380465324694907\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 104.6082 - val_loss: 109.9553\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.3990 - val_loss: 114.5829\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 97.4308 - val_loss: 120.1823\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.8284 - val_loss: 122.6024\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2958 - val_loss: 124.6702\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5958 - val_loss: 126.7022\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3611 - val_loss: 128.3222\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2624 - val_loss: 130.2825\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7574 - val_loss: 131.7590\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6429 - val_loss: 131.8948\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7729 - val_loss: 132.8393\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.7717 - val_loss: 133.3397\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.7082 - val_loss: 134.8146\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6896 - val_loss: 135.6923\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.6389 - val_loss: 135.3848\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6446 - val_loss: 136.3126\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.7036 - val_loss: 137.9001\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.7765 - val_loss: 138.6967\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.4497 - val_loss: 137.6749\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6741 - val_loss: 137.5255\n",
      "MAPE:  21.548394322824503\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 118.5177 - val_loss: 106.5793\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.8150 - val_loss: 104.8113\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.3880 - val_loss: 105.8176\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.8374 - val_loss: 107.2201\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.5286 - val_loss: 108.3163\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2191 - val_loss: 108.7325\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7961 - val_loss: 109.7506\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8808 - val_loss: 110.5903\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.4726 - val_loss: 111.5278\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.0006 - val_loss: 113.3827\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.8221 - val_loss: 111.8098\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.0252 - val_loss: 112.1022\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.6086 - val_loss: 110.9111\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0213 - val_loss: 112.3768\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.8437 - val_loss: 111.8667\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5393 - val_loss: 113.7645\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.1325 - val_loss: 113.5308\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4996 - val_loss: 113.7643\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.9914 - val_loss: 115.4045\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6804 - val_loss: 116.4934\n",
      "MAPE:  34.18864040106342\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 123.5893 - val_loss: 110.2348\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.2912 - val_loss: 112.0067\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 109.0336 - val_loss: 112.7547\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.2016 - val_loss: 111.9661\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 103.8311 - val_loss: 113.0570\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.4114 - val_loss: 113.7892\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.3547 - val_loss: 113.2583\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.2820 - val_loss: 114.2287\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 103.3949 - val_loss: 114.1560\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1168 - val_loss: 115.5810\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.8482 - val_loss: 114.4365\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.5899 - val_loss: 116.7777\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.1978 - val_loss: 117.1206\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.9729 - val_loss: 116.9993\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.0720 - val_loss: 118.4835\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.7889 - val_loss: 121.0894\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.8197 - val_loss: 121.6264\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.7284 - val_loss: 120.7444\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.7959 - val_loss: 121.4891\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2771 - val_loss: 123.4094\n",
      "MAPE:  39.6016514030176\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 101.6760 - val_loss: 104.8403\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.5784 - val_loss: 107.5842\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.9949 - val_loss: 107.6730\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6866 - val_loss: 107.5341\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.6195 - val_loss: 106.4960\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.0111 - val_loss: 104.7738\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.1830 - val_loss: 105.9274\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.6882 - val_loss: 105.2274\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.6041 - val_loss: 103.0983\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.1336 - val_loss: 103.3942\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.9131 - val_loss: 104.2739\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.4732 - val_loss: 100.5740\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.9573 - val_loss: 101.4944\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.9833 - val_loss: 101.6337\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.0192 - val_loss: 100.7359\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.6074 - val_loss: 99.1822\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.0058 - val_loss: 97.0430\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.2472 - val_loss: 96.4843\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.8392 - val_loss: 97.3291\n",
      "Epoch 2/2\n",
      " - 0s - loss: 80.6105 - val_loss: 93.4356\n",
      "MAPE:  33.379862188262294\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 19s - loss: 158.7294 - val_loss: 165.4637\n",
      "Epoch 2/2\n",
      " - 0s - loss: 122.0806 - val_loss: 215.2800\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 125.4765 - val_loss: 260.3944\n",
      "Epoch 2/2\n",
      " - 0s - loss: 108.6153 - val_loss: 301.3337\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 110.9633 - val_loss: 332.6726\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.0725 - val_loss: 356.8077\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.6968 - val_loss: 377.9578\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.2196 - val_loss: 401.4099\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.8259 - val_loss: 423.3398\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1919 - val_loss: 441.7168\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.3480 - val_loss: 463.8443\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.3052 - val_loss: 476.5260\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.2681 - val_loss: 496.3479\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.5758 - val_loss: 509.0048\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.3628 - val_loss: 521.4255\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4981 - val_loss: 531.4373\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.3353 - val_loss: 540.0504\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.0187 - val_loss: 551.9364\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.8137 - val_loss: 552.8121\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.8501 - val_loss: 553.8262\n",
      "MAPE:  32.24666649101536\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 22s - loss: 146.6264 - val_loss: 131.7024\n",
      "Epoch 2/2\n",
      " - 0s - loss: 133.8040 - val_loss: 140.3001\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 120.0701 - val_loss: 142.8361\n",
      "Epoch 2/2\n",
      " - 0s - loss: 108.6082 - val_loss: 144.3145\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.4746 - val_loss: 146.8669\n",
      "Epoch 2/2\n",
      " - 0s - loss: 108.7418 - val_loss: 148.4404\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 109.0723 - val_loss: 147.3384\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.8152 - val_loss: 145.0525\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 104.7670 - val_loss: 142.9860\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.5708 - val_loss: 141.7214\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 104.1467 - val_loss: 144.7507\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.4580 - val_loss: 146.6784\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 105.7055 - val_loss: 149.4536\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.6074 - val_loss: 151.8591\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.0672 - val_loss: 155.0295\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.5326 - val_loss: 157.6055\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.8754 - val_loss: 161.4873\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.3658 - val_loss: 160.1089\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.5110 - val_loss: 159.7000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5622 - val_loss: 161.1901\n",
      "MAPE:  34.222299467954116\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 109.8215 - val_loss: 106.4345\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.3130 - val_loss: 105.5102\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.8271 - val_loss: 104.5510\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.2775 - val_loss: 104.1223\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4973 - val_loss: 103.7134\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.0980 - val_loss: 102.5367\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.5741 - val_loss: 101.3605\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2983 - val_loss: 100.6048\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3293 - val_loss: 99.5740\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5744 - val_loss: 98.2187\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.4214 - val_loss: 97.1336\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8548 - val_loss: 95.6485\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.5633 - val_loss: 94.7576\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.3344 - val_loss: 93.4602\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.5365 - val_loss: 92.3964\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.1772 - val_loss: 90.9469\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.8156 - val_loss: 89.1738\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.4873 - val_loss: 88.0706\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.3566 - val_loss: 86.5718\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.7820 - val_loss: 85.2222\n",
      "MAPE:  25.819373488343363\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 103.4353 - val_loss: 97.1746\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2102 - val_loss: 95.7385\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.4994 - val_loss: 93.9371\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.9973 - val_loss: 91.9119\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.7850 - val_loss: 89.5315\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.8618 - val_loss: 87.6033\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.4541 - val_loss: 84.7085\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.7311 - val_loss: 82.1527\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.3957 - val_loss: 77.9868\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.4274 - val_loss: 73.7595\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81.4888 - val_loss: 68.2789\n",
      "Epoch 2/2\n",
      " - 0s - loss: 80.0732 - val_loss: 63.2783\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 74.8388 - val_loss: 56.8715\n",
      "Epoch 2/2\n",
      " - 0s - loss: 74.6873 - val_loss: 51.2381\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 75.1389 - val_loss: 47.1370\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.4380 - val_loss: 57.2014\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.6498 - val_loss: 52.0464\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.8687 - val_loss: 46.4737\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 72.2927 - val_loss: 42.9427\n",
      "Epoch 2/2\n",
      " - 0s - loss: 70.1694 - val_loss: 42.3007\n",
      "MAPE:  25.009590422230293\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 112.0028 - val_loss: 99.3173\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.3407 - val_loss: 99.6581\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.7151 - val_loss: 99.3603\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.2755 - val_loss: 99.7266\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.6323 - val_loss: 99.4723\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.3718 - val_loss: 100.4978\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.1400 - val_loss: 101.5406\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2386 - val_loss: 100.7551\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.2163 - val_loss: 101.2642\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7914 - val_loss: 101.2938\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3648 - val_loss: 101.6839\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5085 - val_loss: 102.7101\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2033 - val_loss: 103.0488\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.9409 - val_loss: 103.0702\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.5409 - val_loss: 103.1840\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.0020 - val_loss: 103.7149\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.6176 - val_loss: 104.2278\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4450 - val_loss: 104.2649\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.5649 - val_loss: 104.5748\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3168 - val_loss: 105.0974\n",
      "MAPE:  29.874006947720368\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 106.2659 - val_loss: 100.0671\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.6377 - val_loss: 97.8892\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.4398 - val_loss: 95.4296\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5503 - val_loss: 93.4918\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7623 - val_loss: 91.0625\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4718 - val_loss: 89.4226\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.6413 - val_loss: 89.9949\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.0789 - val_loss: 88.4938\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.3549 - val_loss: 87.0299\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.9761 - val_loss: 86.5054\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.2762 - val_loss: 86.1746\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.0031 - val_loss: 86.1607\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.3990 - val_loss: 85.7536\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6094 - val_loss: 84.9806\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.9218 - val_loss: 84.6576\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.6280 - val_loss: 84.1239\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.2727 - val_loss: 83.9190\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.0855 - val_loss: 83.9651\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.5899 - val_loss: 84.6350\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.0352 - val_loss: 84.2971\n",
      "MAPE:  29.153913889635202\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 943419.2151 - val_loss: 383267.4010\n",
      "Epoch 2/2\n",
      " - 0s - loss: 656743.8397 - val_loss: 449410.1553\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 589921.5225 - val_loss: 557600.0414\n",
      "Epoch 2/2\n",
      " - 0s - loss: 486426.7028 - val_loss: 539020.5571\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 421617.9869 - val_loss: 520460.3206\n",
      "Epoch 2/2\n",
      " - 0s - loss: 368094.3140 - val_loss: 441604.9943\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 354650.6284 - val_loss: 559797.3098\n",
      "Epoch 2/2\n",
      " - 0s - loss: 384742.5380 - val_loss: 580300.8427\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 504515.5232 - val_loss: 563935.2749\n",
      "Epoch 2/2\n",
      " - 0s - loss: 372779.0740 - val_loss: 528135.5694\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 395371.5322 - val_loss: 502336.5910\n",
      "Epoch 2/2\n",
      " - 0s - loss: 327559.2760 - val_loss: 532787.3399\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 317744.1432 - val_loss: 450801.5367\n",
      "Epoch 2/2\n",
      " - 0s - loss: 293058.6667 - val_loss: 461673.4870\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 334751.8402 - val_loss: 492333.3647\n",
      "Epoch 2/2\n",
      " - 0s - loss: 349453.9661 - val_loss: 512303.8801\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 191368.0850 - val_loss: 466943.0559\n",
      "Epoch 2/2\n",
      " - 0s - loss: 279711.3781 - val_loss: 495073.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 256911.4362 - val_loss: 403891.5930\n",
      "Epoch 2/2\n",
      " - 0s - loss: 254848.3048 - val_loss: 455667.0647\n",
      "MAPE:  26.318767178549248\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 106.4214 - val_loss: 100.2765\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.5000 - val_loss: 100.9062\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.8477 - val_loss: 101.3904\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3086 - val_loss: 101.5736\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9419 - val_loss: 101.5459\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.1841 - val_loss: 101.7183\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9795 - val_loss: 102.2294\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7856 - val_loss: 102.1648\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.2974 - val_loss: 101.6162\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.4716 - val_loss: 101.2318\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4559 - val_loss: 101.1028\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5107 - val_loss: 101.4547\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.2470 - val_loss: 101.3559\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.4541 - val_loss: 101.4507\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.4955 - val_loss: 101.9212\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1198 - val_loss: 102.1277\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.7886 - val_loss: 101.6196\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6680 - val_loss: 101.4326\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.9108 - val_loss: 101.3651\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.2200 - val_loss: 101.1784\n",
      "MAPE:  33.936583656352155\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 108.2283 - val_loss: 116.4052\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.3286 - val_loss: 120.1871\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.3715 - val_loss: 123.0776\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.0435 - val_loss: 122.6804\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.3833 - val_loss: 123.4268\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.5575 - val_loss: 121.3158\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.9154 - val_loss: 121.1937\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.1571 - val_loss: 122.8901\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4966 - val_loss: 122.6701\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.9479 - val_loss: 121.7474\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.9851 - val_loss: 122.0755\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.4379 - val_loss: 121.9543\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.2621 - val_loss: 123.2791\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.8287 - val_loss: 120.8226\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.7485 - val_loss: 120.9696\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6435 - val_loss: 120.8429\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.8983 - val_loss: 118.9405\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.0630 - val_loss: 118.1316\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.7165 - val_loss: 115.3910\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3769 - val_loss: 116.1283\n",
      "MAPE:  13.919898452801435\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 108.6173 - val_loss: 115.8140\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.5617 - val_loss: 118.5982\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.8908 - val_loss: 117.7402\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4116 - val_loss: 118.1743\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.9566 - val_loss: 117.1044\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6842 - val_loss: 116.6337\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1920 - val_loss: 116.2243\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.7397 - val_loss: 116.0845\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.2387 - val_loss: 118.0073\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.9485 - val_loss: 115.1257\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.3908 - val_loss: 114.4336\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.1659 - val_loss: 114.5953\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1054 - val_loss: 115.6864\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.3611 - val_loss: 114.4912\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.6434 - val_loss: 110.6881\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.9468 - val_loss: 110.9465\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.9562 - val_loss: 111.9415\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.3719 - val_loss: 112.7373\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.8070 - val_loss: 112.5655\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.5251 - val_loss: 114.7966\n",
      "MAPE:  15.50962580958142\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 18s - loss: 103.5629 - val_loss: 98.0570\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.3243 - val_loss: 98.1589\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.3540 - val_loss: 98.6701\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1584 - val_loss: 99.2672\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7966 - val_loss: 99.9203\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.1729 - val_loss: 100.4380\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.2031 - val_loss: 101.6936\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.7788 - val_loss: 103.1110\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.2616 - val_loss: 103.6407\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8955 - val_loss: 105.0919\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.6595 - val_loss: 106.6172\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.6725 - val_loss: 108.2760\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.6564 - val_loss: 109.2461\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0220 - val_loss: 109.2847\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.3452 - val_loss: 110.8930\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.6503 - val_loss: 112.5261\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1089 - val_loss: 112.6375\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.8411 - val_loss: 113.7487\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9829 - val_loss: 113.9643\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.9705 - val_loss: 113.7469\n",
      "MAPE:  29.802752196798586\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 101012.6849 - val_loss: 894108.8250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 125240.3468 - val_loss: 1051387.2563\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 156084.2549 - val_loss: 1125580.4750\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102059.5384 - val_loss: 1186751.7375\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94393.1695 - val_loss: 1230895.6750\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94256.5868 - val_loss: 1085772.5437\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 147922.7911 - val_loss: 1460417.3500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 73245.6171 - val_loss: 1397577.2750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 141418.3019 - val_loss: 1125650.2375\n",
      "Epoch 2/2\n",
      " - 0s - loss: 61257.7506 - val_loss: 1334147.8625\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 128114.0932 - val_loss: 1254620.6875\n",
      "Epoch 2/2\n",
      " - 0s - loss: 113192.5258 - val_loss: 1070042.9250\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 128694.4161 - val_loss: 1459834.5500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90044.5686 - val_loss: 1659219.4250\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 50367.2232 - val_loss: 1532556.3250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96766.1191 - val_loss: 1438167.2625\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85825.7613 - val_loss: 1360720.6500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103272.4746 - val_loss: 1368030.4250\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 110703.5301 - val_loss: 1428709.0750\n",
      "Epoch 2/2\n",
      " - 0s - loss: 44420.2422 - val_loss: 1388462.6750\n",
      "MAPE:  22.246860236570242\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 113.4946 - val_loss: 98.5820\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.6635 - val_loss: 99.9899\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.3040 - val_loss: 100.1563\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.3414 - val_loss: 100.7994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.7310 - val_loss: 100.3096\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.8775 - val_loss: 99.9101\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.9361 - val_loss: 98.0493\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.7966 - val_loss: 98.9576\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.7859 - val_loss: 99.4004\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2930 - val_loss: 99.5231\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7675 - val_loss: 99.7991\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5713 - val_loss: 97.6172\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4540 - val_loss: 97.5078\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7731 - val_loss: 98.2188\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.3420 - val_loss: 99.4747\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4079 - val_loss: 99.9040\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3653 - val_loss: 98.1866\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4683 - val_loss: 97.5878\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.2039 - val_loss: 97.8951\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.1621 - val_loss: 99.1855\n",
      "MAPE:  23.11969588603728\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 18s - loss: 117.6244 - val_loss: 108.8899\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.9722 - val_loss: 115.3446\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 101.0215 - val_loss: 118.4313\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.8725 - val_loss: 116.8190\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.5147 - val_loss: 120.5421\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5058 - val_loss: 120.4666\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3234 - val_loss: 117.9868\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.8487 - val_loss: 121.7148\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3871 - val_loss: 117.8322\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.1693 - val_loss: 120.9819\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.6798 - val_loss: 115.2797\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.9137 - val_loss: 117.9360\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.3530 - val_loss: 118.6681\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.5896 - val_loss: 118.8337\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4357 - val_loss: 115.4917\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.1100 - val_loss: 116.0046\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4405 - val_loss: 117.0817\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.4680 - val_loss: 114.6816\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.1222 - val_loss: 115.1189\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5224 - val_loss: 121.1993\n",
      "MAPE:  16.149390177058383\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 18s - loss: 124.5664 - val_loss: 106.7123\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.8425 - val_loss: 109.5832\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.8434 - val_loss: 109.2464\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.3729 - val_loss: 111.7739\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.2021 - val_loss: 112.3061\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6978 - val_loss: 113.0282\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.6109 - val_loss: 111.5088\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2519 - val_loss: 113.0055\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3955 - val_loss: 113.0308\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0291 - val_loss: 112.7152\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.8939 - val_loss: 113.8478\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.3906 - val_loss: 113.2338\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9179 - val_loss: 112.0995\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4902 - val_loss: 113.3167\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.0411 - val_loss: 112.7481\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7562 - val_loss: 112.2944\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.9755 - val_loss: 112.2130\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8344 - val_loss: 109.8361\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4745 - val_loss: 111.3645\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8390 - val_loss: 109.2314\n",
      "MAPE:  9.144433560923648\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 19s - loss: 99.8044 - val_loss: 110.9680\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.3700 - val_loss: 109.6541\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4238 - val_loss: 107.8172\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.7831 - val_loss: 106.1168\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.0846 - val_loss: 105.0583\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0474 - val_loss: 105.3038\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.0907 - val_loss: 105.2627\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8525 - val_loss: 109.5445\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.3891 - val_loss: 110.5713\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5969 - val_loss: 114.0059\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.3007 - val_loss: 112.8692\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.2783 - val_loss: 112.1032\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.5258 - val_loss: 114.9204\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.2180 - val_loss: 114.6006\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.1011 - val_loss: 114.5656\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.6215 - val_loss: 116.4154\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.9512 - val_loss: 114.2519\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.7068 - val_loss: 115.3826\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.8728 - val_loss: 115.8516\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.0755 - val_loss: 120.0039\n",
      "MAPE:  9.681274138729178\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 18s - loss: 134.3636 - val_loss: 99.9734\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.6618 - val_loss: 101.3722\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 123.3310 - val_loss: 98.1224\n",
      "Epoch 2/2\n",
      " - 0s - loss: 111.9208 - val_loss: 98.0813\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 112.1077 - val_loss: 95.8465\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.6806 - val_loss: 96.2048\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.6616 - val_loss: 95.0918\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.7724 - val_loss: 97.7860\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 105.5241 - val_loss: 95.4880\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.5880 - val_loss: 94.9941\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 103.7708 - val_loss: 95.0842\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5481 - val_loss: 96.7608\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 107.1184 - val_loss: 96.5805\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.9647 - val_loss: 95.0912\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 103.7089 - val_loss: 96.1370\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.0631 - val_loss: 94.8560\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 102.4792 - val_loss: 96.2751\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.4449 - val_loss: 94.5043\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.3064 - val_loss: 95.6956\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.8839 - val_loss: 94.7439\n",
      "MAPE:  6.822898433345231\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 18s - loss: 104.0463 - val_loss: 106.0149\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.4088 - val_loss: 104.7724\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.9954 - val_loss: 105.7012\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.6337 - val_loss: 107.5752\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.0083 - val_loss: 106.4959\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2547 - val_loss: 105.7642\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.1854 - val_loss: 105.1742\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3448 - val_loss: 105.1622\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9732 - val_loss: 105.6289\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3800 - val_loss: 107.0407\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1521 - val_loss: 106.3882\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8325 - val_loss: 107.8097\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 95.1115 - val_loss: 108.6098\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2621 - val_loss: 107.1407\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.5281 - val_loss: 108.1724\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6034 - val_loss: 108.8862\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7769 - val_loss: 110.7122\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.0918 - val_loss: 110.3247\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.2832 - val_loss: 110.0734\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0338 - val_loss: 108.9520\n",
      "MAPE:  12.130970714812065\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 19s - loss: 227225.6552 - val_loss: 107.6348\n",
      "Epoch 2/2\n",
      " - 0s - loss: 162883.6137 - val_loss: 107.8265\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 112481.7681 - val_loss: 107.9120\n",
      "Epoch 2/2\n",
      " - 0s - loss: 132526.5330 - val_loss: 107.0342\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 108068.5598 - val_loss: 107.2341\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99886.7216 - val_loss: 106.7409\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 72792.6246 - val_loss: 106.8239\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97746.2535 - val_loss: 106.7603\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 141597.0288 - val_loss: 106.0288\n",
      "Epoch 2/2\n",
      " - 0s - loss: 114812.3848 - val_loss: 106.4219\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 119621.3678 - val_loss: 106.1106\n",
      "Epoch 2/2\n",
      " - 0s - loss: 107153.2487 - val_loss: 106.1400\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 71173.9243 - val_loss: 106.1555\n",
      "Epoch 2/2\n",
      " - 0s - loss: 135123.4011 - val_loss: 106.3308\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91864.5703 - val_loss: 105.5794\n",
      "Epoch 2/2\n",
      " - 0s - loss: 138183.0109 - val_loss: 105.4532\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73598.1276 - val_loss: 105.5510\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100758.8358 - val_loss: 106.0201\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99385.8192 - val_loss: 105.0431\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99859.0371 - val_loss: 105.3127\n",
      "MAPE:  46.54693048649494\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 24s - loss: 192586.8075 - val_loss: 99.7114\n",
      "Epoch 2/2\n",
      " - 0s - loss: 177651.0984 - val_loss: 97.6666\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 190719.1785 - val_loss: 94.9435\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104096.1079 - val_loss: 92.9321\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 185706.4749 - val_loss: 89.8573\n",
      "Epoch 2/2\n",
      " - 0s - loss: 77784.4190 - val_loss: 87.9297\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 145786.0224 - val_loss: 85.6343\n",
      "Epoch 2/2\n",
      " - 0s - loss: 112272.7287 - val_loss: 83.2043\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 165664.0410 - val_loss: 81.0308\n",
      "Epoch 2/2\n",
      " - 0s - loss: 118878.9773 - val_loss: 79.7712\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 193294.2821 - val_loss: 77.2145\n",
      "Epoch 2/2\n",
      " - 0s - loss: 113871.6172 - val_loss: 75.7281\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 196827.0591 - val_loss: 74.2226\n",
      "Epoch 2/2\n",
      " - 0s - loss: 127217.7899 - val_loss: 73.9239\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 169552.5677 - val_loss: 71.8455\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102964.4054 - val_loss: 71.0951\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91464.9887 - val_loss: 69.8214\n",
      "Epoch 2/2\n",
      " - 0s - loss: 114933.6159 - val_loss: 68.8719\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 132220.8879 - val_loss: 67.0007\n",
      "Epoch 2/2\n",
      " - 0s - loss: 136318.9540 - val_loss: 67.0730\n",
      "MAPE:  67.39911583079822\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 18s - loss: 101.8355 - val_loss: 800215.0134\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.9649 - val_loss: 777766.3948\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.5292 - val_loss: 786566.1722\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.9014 - val_loss: 735172.1363\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3216 - val_loss: 692894.9061\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.1458 - val_loss: 596515.3249\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3957 - val_loss: 475519.5638\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.9339 - val_loss: 485569.0884\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.0455 - val_loss: 460403.2684\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8528 - val_loss: 322912.9020\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8493 - val_loss: 302562.1002\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0146 - val_loss: 232849.9080\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7915 - val_loss: 293669.7634\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4160 - val_loss: 373096.1872\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.9020 - val_loss: 401077.5792\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5762 - val_loss: 445571.8413\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.7740 - val_loss: 454271.9384\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.1434 - val_loss: 475442.1334\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.2419 - val_loss: 539881.9866\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.0999 - val_loss: 583686.9957\n",
      "MAPE:  12.320248160154096\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 19s - loss: 107.8061 - val_loss: 99.9354\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.9387 - val_loss: 100.8379\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.2198 - val_loss: 101.4717\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.3472 - val_loss: 102.6548\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.0368 - val_loss: 103.8563\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5187 - val_loss: 104.5875\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.0663 - val_loss: 105.0407\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.1819 - val_loss: 105.6184\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.4600 - val_loss: 105.7067\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3636 - val_loss: 105.9361\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7747 - val_loss: 105.8807\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5581 - val_loss: 105.6158\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3589 - val_loss: 105.8722\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3046 - val_loss: 105.8264\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.0976 - val_loss: 106.0015\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2877 - val_loss: 105.8828\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.6091 - val_loss: 105.3522\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6578 - val_loss: 105.3821\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.1989 - val_loss: 104.4768\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1887 - val_loss: 104.9872\n",
      "MAPE:  15.905644782609393\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 20s - loss: 683008.8746 - val_loss: 1306804.8547\n",
      "Epoch 2/2\n",
      " - 0s - loss: 518241.8242 - val_loss: 1678180.6094\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 584324.1356 - val_loss: 1702369.4250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 353352.4881 - val_loss: 1790450.1500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 481212.3363 - val_loss: 1824871.8125\n",
      "Epoch 2/2\n",
      " - 0s - loss: 401231.9515 - val_loss: 1724485.2125\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 431436.1288 - val_loss: 1813690.6500\n",
      "Epoch 2/2\n",
      " - 0s - loss: 297403.8238 - val_loss: 1717787.1250\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 309608.2464 - val_loss: 1994371.9625\n",
      "Epoch 2/2\n",
      " - 0s - loss: 275151.7716 - val_loss: 1999968.4750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 268490.5500 - val_loss: 1965100.6250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 223272.3036 - val_loss: 2115908.8500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 168880.4924 - val_loss: 2128378.1250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 267118.9041 - val_loss: 2345084.9250\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 207167.0869 - val_loss: 2343511.3250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 229050.7291 - val_loss: 2393174.4500\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 195362.1300 - val_loss: 2615061.5750\n",
      "Epoch 2/2\n",
      " - 0s - loss: 265805.0898 - val_loss: 2472591.9750\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 199471.2830 - val_loss: 2334121.3750\n",
      "Epoch 2/2\n",
      " - 0s - loss: 243352.7528 - val_loss: 2427305.9250\n",
      "MAPE:  13.783468327759884\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 22s - loss: 100.1801 - val_loss: 96.5916\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.8926 - val_loss: 94.8501\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.4345 - val_loss: 93.2840\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.4662 - val_loss: 91.3720\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5542 - val_loss: 88.5205\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6100 - val_loss: 85.8706\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1634 - val_loss: 82.6819\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.9460 - val_loss: 83.0675\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.1459 - val_loss: 84.6412\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2896 - val_loss: 80.5847\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.0666 - val_loss: 83.7117\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.4362 - val_loss: 84.7535\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.3727 - val_loss: 92.9181\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4893 - val_loss: 85.4439\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.5870 - val_loss: 88.0482\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.3459 - val_loss: 86.3150\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.0865 - val_loss: 93.9357\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.8528 - val_loss: 83.7138\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84.7728 - val_loss: 88.5149\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.1685 - val_loss: 90.8511\n",
      "MAPE:  69.30823514303233\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 111.7060 - val_loss: 101.4620\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.1779 - val_loss: 101.3433\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 103.8325 - val_loss: 100.7471\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.8638 - val_loss: 100.8256\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.1617 - val_loss: 100.2219\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.7391 - val_loss: 100.8465\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.5342 - val_loss: 101.2072\n",
      "Epoch 2/2\n",
      " - 0s - loss: 103.4786 - val_loss: 101.0436\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.7530 - val_loss: 100.9763\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.9238 - val_loss: 101.5308\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.9158 - val_loss: 101.5597\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.6727 - val_loss: 101.4221\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.6835 - val_loss: 101.8682\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.5782 - val_loss: 102.2860\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.6479 - val_loss: 101.5783\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5982 - val_loss: 102.0851\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.6859 - val_loss: 102.2103\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.0389 - val_loss: 102.0082\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.9531 - val_loss: 101.5876\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.0263 - val_loss: 102.2526\n",
      "MAPE:  124.62153009076427\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 106.2250 - val_loss: 103.8240\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.9834 - val_loss: 101.7421\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.6595 - val_loss: 99.4729\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.2026 - val_loss: 99.2147\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0155 - val_loss: 96.9105\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.7639 - val_loss: 95.7402\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.1848 - val_loss: 96.5212\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.5214 - val_loss: 97.4336\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.8685 - val_loss: 94.6103\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.3512 - val_loss: 94.9327\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.2823 - val_loss: 95.4595\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.8867 - val_loss: 94.5380\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.2734 - val_loss: 94.8238\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4351 - val_loss: 94.2868\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4192 - val_loss: 95.5337\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4752 - val_loss: 95.0470\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.7967 - val_loss: 94.2348\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.9824 - val_loss: 94.3055\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.6049 - val_loss: 95.3074\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.2027 - val_loss: 95.1336\n",
      "MAPE:  88.21184404914571\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 106.7979 - val_loss: 108.3781\n",
      "Epoch 2/2\n",
      " - 0s - loss: 101.7810 - val_loss: 105.8350\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.0491 - val_loss: 104.3644\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.8299 - val_loss: 103.5207\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.1056 - val_loss: 102.4642\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1908 - val_loss: 102.3846\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 100.7895 - val_loss: 101.6720\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.6082 - val_loss: 101.5348\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3798 - val_loss: 100.3545\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.5748 - val_loss: 101.1637\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.1599 - val_loss: 100.6001\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.9827 - val_loss: 100.2308\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.4788 - val_loss: 98.9086\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.8442 - val_loss: 98.7545\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5188 - val_loss: 99.8373\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.6502 - val_loss: 99.7054\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7703 - val_loss: 100.9636\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2859 - val_loss: 100.7802\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.1227 - val_loss: 101.0422\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8903 - val_loss: 100.3218\n",
      "MAPE:  80.93428176184906\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 855455.6630 - val_loss: 103.4746\n",
      "Epoch 2/2\n",
      " - 0s - loss: 867645.5162 - val_loss: 102.0781\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 368845.8288 - val_loss: 102.3950\n",
      "Epoch 2/2\n",
      " - 0s - loss: 571089.5120 - val_loss: 101.2519\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 382683.2692 - val_loss: 101.3513\n",
      "Epoch 2/2\n",
      " - 0s - loss: 310995.6335 - val_loss: 100.3746\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 249901.3577 - val_loss: 100.5029\n",
      "Epoch 2/2\n",
      " - 0s - loss: 320802.4317 - val_loss: 99.8314\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 313779.6693 - val_loss: 100.0912\n",
      "Epoch 2/2\n",
      " - 0s - loss: 212270.2242 - val_loss: 99.9549\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 350298.2152 - val_loss: 99.3996\n",
      "Epoch 2/2\n",
      " - 0s - loss: 221602.9643 - val_loss: 99.5284\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 372352.5132 - val_loss: 99.2649\n",
      "Epoch 2/2\n",
      " - 0s - loss: 152775.7933 - val_loss: 98.9169\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 317961.4553 - val_loss: 98.3247\n",
      "Epoch 2/2\n",
      " - 0s - loss: 189298.2836 - val_loss: 97.8519\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 352226.8378 - val_loss: 97.4226\n",
      "Epoch 2/2\n",
      " - 0s - loss: 276843.7859 - val_loss: 96.8741\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 194195.1021 - val_loss: 96.6938\n",
      "Epoch 2/2\n",
      " - 0s - loss: 238982.6071 - val_loss: 96.5662\n",
      "MAPE:  85.70574085894971\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 101.2581 - val_loss: 105.4853\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.0620 - val_loss: 103.9288\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.5812 - val_loss: 103.1759\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.7818 - val_loss: 102.4292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.5279 - val_loss: 102.0983\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.2714 - val_loss: 102.1551\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.2851 - val_loss: 101.5917\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4183 - val_loss: 101.0447\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.0858 - val_loss: 101.2502\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.9847 - val_loss: 101.4243\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.6483 - val_loss: 101.6789\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.3526 - val_loss: 102.0018\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.1685 - val_loss: 102.3023\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.1062 - val_loss: 102.6038\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.4577 - val_loss: 101.8995\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.4239 - val_loss: 102.6386\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.8582 - val_loss: 102.3293\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.1937 - val_loss: 102.4453\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.2293 - val_loss: 102.2501\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.5525 - val_loss: 102.4315\n",
      "MAPE:  118.0672906162811\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 99.9600 - val_loss: 108.5968\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5989 - val_loss: 108.0690\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.1710 - val_loss: 108.7390\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.2715 - val_loss: 108.3998\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.8219 - val_loss: 109.8917\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4616 - val_loss: 111.0876\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.6550 - val_loss: 112.5897\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.1427 - val_loss: 113.4809\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.1600 - val_loss: 116.9363\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.5036 - val_loss: 121.3704\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.3252 - val_loss: 126.2883\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.5630 - val_loss: 127.5401\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.6994 - val_loss: 129.7843\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.2841 - val_loss: 133.5089\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.5199 - val_loss: 139.7017\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.7610 - val_loss: 144.6725\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.8400 - val_loss: 147.3945\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.9486 - val_loss: 148.6350\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.7101 - val_loss: 148.7897\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.5751 - val_loss: 150.7477\n",
      "MAPE:  105.40632688396447\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 101.7843 - val_loss: 98.3706\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.1642 - val_loss: 94.9275\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.1376 - val_loss: 91.9576\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4392 - val_loss: 89.6463\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.7796 - val_loss: 86.2651\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.6085 - val_loss: 82.3766\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.7150 - val_loss: 78.2662\n",
      "Epoch 2/2\n",
      " - 0s - loss: 85.9297 - val_loss: 75.8687\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 83.5323 - val_loss: 73.2481\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.9200 - val_loss: 72.4598\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 82.5481 - val_loss: 75.5963\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.1447 - val_loss: 70.3840\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 79.6708 - val_loss: 74.5025\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.6681 - val_loss: 72.7920\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.6916 - val_loss: 74.5129\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.8806 - val_loss: 76.9055\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.4440 - val_loss: 82.2977\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.3046 - val_loss: 73.3783\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.2225 - val_loss: 73.4850\n",
      "Epoch 2/2\n",
      " - 0s - loss: 83.3073 - val_loss: 73.1274\n",
      "MAPE:  124.13884963911951\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 110.6317 - val_loss: 97.7572\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.6893 - val_loss: 97.1884\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.3882 - val_loss: 96.7079\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.2253 - val_loss: 96.0426\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.1249 - val_loss: 95.2081\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.4304 - val_loss: 94.3222\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.8974 - val_loss: 93.8434\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.3913 - val_loss: 92.5749\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8065 - val_loss: 92.0841\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.4602 - val_loss: 91.5905\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.9942 - val_loss: 90.5422\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.7449 - val_loss: 90.4877\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.8040 - val_loss: 89.6305\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.1097 - val_loss: 88.7930\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.3388 - val_loss: 88.9095\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.2184 - val_loss: 88.1697\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.6875 - val_loss: 87.6160\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.6409 - val_loss: 87.3121\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.7973 - val_loss: 87.2561\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.6060 - val_loss: 86.4607\n",
      "MAPE:  127.90001872959074\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 105.1045 - val_loss: 96.7592\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.8194 - val_loss: 92.8584\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.4724 - val_loss: 88.4328\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.4870 - val_loss: 83.9264\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81.9985 - val_loss: 78.9577\n",
      "Epoch 2/2\n",
      " - 0s - loss: 79.0406 - val_loss: 71.8727\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 77.0623 - val_loss: 66.0871\n",
      "Epoch 2/2\n",
      " - 0s - loss: 76.3820 - val_loss: 63.3243\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 73.9590 - val_loss: 58.2783\n",
      "Epoch 2/2\n",
      " - 0s - loss: 77.9844 - val_loss: 61.1689\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 69.7756 - val_loss: 56.0019\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.4111 - val_loss: 56.9512\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 68.6807 - val_loss: 58.5860\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.7193 - val_loss: 59.2487\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 66.2219 - val_loss: 62.2914\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.5594 - val_loss: 63.9301\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 67.1147 - val_loss: 59.5571\n",
      "Epoch 2/2\n",
      " - 0s - loss: 68.9630 - val_loss: 58.8980\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 68.1197 - val_loss: 60.3915\n",
      "Epoch 2/2\n",
      " - 0s - loss: 69.8506 - val_loss: 61.2626\n",
      "MAPE:  121.6409671802138\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 96.4169 - val_loss: 89.9195\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.2482 - val_loss: 80.9374\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 81.7965 - val_loss: 67.7246\n",
      "Epoch 2/2\n",
      " - 0s - loss: 71.2548 - val_loss: 54.3762\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 64.6686 - val_loss: 48.9421\n",
      "Epoch 2/2\n",
      " - 0s - loss: 60.5732 - val_loss: 46.4171\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 58.3018 - val_loss: 45.0163\n",
      "Epoch 2/2\n",
      " - 0s - loss: 57.6238 - val_loss: 43.8061\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 56.9987 - val_loss: 43.6524\n",
      "Epoch 2/2\n",
      " - 0s - loss: 56.7199 - val_loss: 42.8242\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 55.2946 - val_loss: 42.8617\n",
      "Epoch 2/2\n",
      " - 0s - loss: 55.5666 - val_loss: 42.7419\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 55.1200 - val_loss: 42.7849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 0s - loss: 55.2968 - val_loss: 42.9757\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 54.1336 - val_loss: 43.2222\n",
      "Epoch 2/2\n",
      " - 0s - loss: 57.5164 - val_loss: 42.6169\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 55.2385 - val_loss: 43.7487\n",
      "Epoch 2/2\n",
      " - 0s - loss: 54.8267 - val_loss: 44.3655\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 54.4392 - val_loss: 44.9848\n",
      "Epoch 2/2\n",
      " - 0s - loss: 54.3471 - val_loss: 44.1473\n",
      "MAPE:  95.42890029767483\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 94.5728 - val_loss: 88.0188\n",
      "Epoch 2/2\n",
      " - 0s - loss: 81.3247 - val_loss: 77.9738\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 67.1878 - val_loss: 69.1690\n",
      "Epoch 2/2\n",
      " - 0s - loss: 61.0845 - val_loss: 78.0930\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 53.2105 - val_loss: 86.6273\n",
      "Epoch 2/2\n",
      " - 0s - loss: 57.6865 - val_loss: 87.4948\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 52.3271 - val_loss: 93.8967\n",
      "Epoch 2/2\n",
      " - 0s - loss: 61.7614 - val_loss: 90.3247\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 51.5476 - val_loss: 91.3768\n",
      "Epoch 2/2\n",
      " - 0s - loss: 55.2635 - val_loss: 90.5767\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 52.7621 - val_loss: 89.9484\n",
      "Epoch 2/2\n",
      " - 0s - loss: 53.7319 - val_loss: 89.8976\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 51.1289 - val_loss: 90.5260\n",
      "Epoch 2/2\n",
      " - 0s - loss: 52.5718 - val_loss: 89.1453\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 50.8418 - val_loss: 89.3988\n",
      "Epoch 2/2\n",
      " - 0s - loss: 54.3841 - val_loss: 89.7661\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 49.4627 - val_loss: 92.2969\n",
      "Epoch 2/2\n",
      " - 0s - loss: 54.3065 - val_loss: 90.4442\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 49.5796 - val_loss: 89.4178\n",
      "Epoch 2/2\n",
      " - 0s - loss: 52.2398 - val_loss: 88.1260\n",
      "MAPE:  36.80713681495924\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 16s - loss: 102.1790 - val_loss: 103.5785\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.0004 - val_loss: 98.2192\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.5414 - val_loss: 94.5322\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3353 - val_loss: 91.7550\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.8155 - val_loss: 89.4247\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.9987 - val_loss: 87.6391\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.6002 - val_loss: 86.5071\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.3414 - val_loss: 85.6007\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.6289 - val_loss: 82.7562\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.7008 - val_loss: 82.0424\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.8418 - val_loss: 81.7243\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.3838 - val_loss: 80.2978\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.2511 - val_loss: 78.6498\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.4388 - val_loss: 79.1187\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.3843 - val_loss: 78.8939\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.8651 - val_loss: 79.3167\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 85.1631 - val_loss: 78.4220\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.2873 - val_loss: 78.4454\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.7414 - val_loss: 82.5081\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.2293 - val_loss: 79.5355\n",
      "MAPE:  13.299851369862356\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 128.7121 - val_loss: 342.1654\n",
      "Epoch 2/2\n",
      " - 0s - loss: 117.1465 - val_loss: 327.6470\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 119.8446 - val_loss: 308.7981\n",
      "Epoch 2/2\n",
      " - 0s - loss: 114.5865 - val_loss: 283.6671\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 113.4157 - val_loss: 276.4429\n",
      "Epoch 2/2\n",
      " - 0s - loss: 110.4139 - val_loss: 237.2983\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 113.9799 - val_loss: 248.9434\n",
      "Epoch 2/2\n",
      " - 0s - loss: 107.7201 - val_loss: 227.0529\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 115.4851 - val_loss: 249.4603\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.3734 - val_loss: 229.0449\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 108.1267 - val_loss: 217.4073\n",
      "Epoch 2/2\n",
      " - 0s - loss: 104.5379 - val_loss: 176.1904\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 112.9413 - val_loss: 198.7054\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.9452 - val_loss: 154.8152\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 108.4577 - val_loss: 196.4102\n",
      "Epoch 2/2\n",
      " - 0s - loss: 106.7516 - val_loss: 184.9675\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 110.6998 - val_loss: 243.5204\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105.2149 - val_loss: 210.1996\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 108.2609 - val_loss: 207.1318\n",
      "Epoch 2/2\n",
      " - 0s - loss: 111.5988 - val_loss: 190.1637\n",
      "MAPE:  12.273376524023574\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 109.5373 - val_loss: 106.0261\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.7550 - val_loss: 112.8450\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.5400 - val_loss: 120.2431\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.5310 - val_loss: 126.6983\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.2328 - val_loss: 131.5759\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.8957 - val_loss: 138.2774\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7690 - val_loss: 143.9727\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.9768 - val_loss: 149.9236\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.7722 - val_loss: 156.2325\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.8423 - val_loss: 159.5684\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.6315 - val_loss: 162.4818\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7694 - val_loss: 168.6493\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.6874 - val_loss: 171.5283\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.9775 - val_loss: 173.6941\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.4608 - val_loss: 174.7043\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.8253 - val_loss: 175.6927\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.0866 - val_loss: 172.2759\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.7268 - val_loss: 173.9368\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.4088 - val_loss: 175.1781\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5244 - val_loss: 176.5875\n",
      "MAPE:  8.70234933609261\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 234.7637 - val_loss: 127.1642\n",
      "Epoch 2/2\n",
      " - 0s - loss: 161.5939 - val_loss: 123.5589\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 159.5172 - val_loss: 127.2327\n",
      "Epoch 2/2\n",
      " - 0s - loss: 144.5623 - val_loss: 111.7077\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 150.6474 - val_loss: 117.8730\n",
      "Epoch 2/2\n",
      " - 0s - loss: 142.0439 - val_loss: 115.5861\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 146.0084 - val_loss: 114.2699\n",
      "Epoch 2/2\n",
      " - 0s - loss: 152.1368 - val_loss: 110.8777\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 139.4488 - val_loss: 116.9437\n",
      "Epoch 2/2\n",
      " - 0s - loss: 145.0568 - val_loss: 113.8036\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 141.4625 - val_loss: 113.5803\n",
      "Epoch 2/2\n",
      " - 0s - loss: 154.0494 - val_loss: 112.2270\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 136.9645 - val_loss: 109.6010\n",
      "Epoch 2/2\n",
      " - 0s - loss: 122.1201 - val_loss: 115.0067\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 137.4094 - val_loss: 116.0502\n",
      "Epoch 2/2\n",
      " - 0s - loss: 126.4009 - val_loss: 113.4289\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 140.0553 - val_loss: 116.1748\n",
      "Epoch 2/2\n",
      " - 0s - loss: 131.7604 - val_loss: 112.8471\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 132.1537 - val_loss: 122.0341\n",
      "Epoch 2/2\n",
      " - 0s - loss: 128.3261 - val_loss: 113.2422\n",
      "MAPE:  8.402740400882893\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 104.3598 - val_loss: 100.6936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 0s - loss: 99.5215 - val_loss: 98.7000\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.5837 - val_loss: 99.2245\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.1850 - val_loss: 101.6466\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0511 - val_loss: 101.6727\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.7503 - val_loss: 100.4899\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9589 - val_loss: 102.0632\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5648 - val_loss: 101.2306\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.3399 - val_loss: 101.3643\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.7358 - val_loss: 100.5158\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4958 - val_loss: 100.8396\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6741 - val_loss: 104.9234\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0928 - val_loss: 102.9228\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3898 - val_loss: 103.3699\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.2288 - val_loss: 104.7933\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.9559 - val_loss: 104.3098\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3976 - val_loss: 105.1245\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.0299 - val_loss: 105.9884\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95.5477 - val_loss: 104.0226\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.9532 - val_loss: 104.6223\n",
      "MAPE:  9.960854781662674\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 103.1534 - val_loss: 102.3162\n",
      "Epoch 2/2\n",
      " - 0s - loss: 102.0601 - val_loss: 101.5655\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.7061 - val_loss: 102.8426\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.9828 - val_loss: 103.3763\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 99.4276 - val_loss: 102.6637\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.1655 - val_loss: 103.6144\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.4681 - val_loss: 104.1706\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.5491 - val_loss: 103.4212\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.3013 - val_loss: 103.2664\n",
      "Epoch 2/2\n",
      " - 0s - loss: 99.0297 - val_loss: 103.1534\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9549 - val_loss: 104.3650\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.1741 - val_loss: 102.5907\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 98.1899 - val_loss: 104.4567\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6036 - val_loss: 103.5590\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 97.0509 - val_loss: 104.9876\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.8179 - val_loss: 103.6098\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.4362 - val_loss: 105.2567\n",
      "Epoch 2/2\n",
      " - 0s - loss: 96.3272 - val_loss: 105.1161\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.7634 - val_loss: 104.0415\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.3887 - val_loss: 103.3595\n",
      "MAPE:  16.859374898913227\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 98.0436 - val_loss: 99.2278\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.5207 - val_loss: 97.8356\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.8477 - val_loss: 97.6318\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.8185 - val_loss: 97.5717\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.6471 - val_loss: 97.0184\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.2419 - val_loss: 96.8776\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.8318 - val_loss: 96.9698\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.9272 - val_loss: 96.4608\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.2796 - val_loss: 96.0721\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.2611 - val_loss: 95.6187\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.2855 - val_loss: 94.3101\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.9559 - val_loss: 94.2575\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.3337 - val_loss: 93.5770\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.4911 - val_loss: 93.9441\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.4373 - val_loss: 93.9292\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.0737 - val_loss: 93.4910\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.7607 - val_loss: 93.7483\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.3752 - val_loss: 93.0229\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.8654 - val_loss: 93.5264\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.6874 - val_loss: 92.9933\n",
      "MAPE:  18.555904019864048\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 46497.4754 - val_loss: 158.7693\n",
      "Epoch 2/2\n",
      " - 0s - loss: 163604.1061 - val_loss: 153.1883\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90922.1415 - val_loss: 146.5262\n",
      "Epoch 2/2\n",
      " - 0s - loss: 125093.4242 - val_loss: 137.6790\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 47829.1134 - val_loss: 136.6421\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72494.7843 - val_loss: 147.7998\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 42528.7114 - val_loss: 165.7530\n",
      "Epoch 2/2\n",
      " - 0s - loss: 105006.8847 - val_loss: 168.7987\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 36986.7290 - val_loss: 180.3716\n",
      "Epoch 2/2\n",
      " - 0s - loss: 108630.6787 - val_loss: 192.0106\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 47164.4743 - val_loss: 196.2241\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89992.9707 - val_loss: 206.1882\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 122151.2528 - val_loss: 218.9080\n",
      "Epoch 2/2\n",
      " - 0s - loss: 78934.3702 - val_loss: 234.3984\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 43762.1307 - val_loss: 253.6162\n",
      "Epoch 2/2\n",
      " - 0s - loss: 69259.5104 - val_loss: 259.3998\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 95686.8517 - val_loss: 281.7247\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95987.0880 - val_loss: 293.7786\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 84137.5840 - val_loss: 296.2429\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89357.3791 - val_loss: 305.7965\n",
      "MAPE:  45.43652141071792\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 17s - loss: 101.4811 - val_loss: 119.0705\n",
      "Epoch 2/2\n",
      " - 0s - loss: 97.6005 - val_loss: 117.3523\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 94.4720 - val_loss: 115.6037\n",
      "Epoch 2/2\n",
      " - 0s - loss: 95.6886 - val_loss: 115.2970\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.1289 - val_loss: 115.0476\n",
      "Epoch 2/2\n",
      " - 0s - loss: 93.4206 - val_loss: 113.3755\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.4626 - val_loss: 111.0845\n",
      "Epoch 2/2\n",
      " - 0s - loss: 94.1445 - val_loss: 112.0874\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 92.6314 - val_loss: 113.5797\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5791 - val_loss: 113.7092\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.6512 - val_loss: 115.6876\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.5028 - val_loss: 115.8798\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.4473 - val_loss: 115.6887\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.0568 - val_loss: 117.6192\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.7214 - val_loss: 117.1134\n",
      "Epoch 2/2\n",
      " - 0s - loss: 92.1015 - val_loss: 117.4173\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.4684 - val_loss: 118.9820\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.3686 - val_loss: 120.6262\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.8748 - val_loss: 121.5490\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.6844 - val_loss: 120.6152\n",
      "MAPE:  67.50871626999033\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 18s - loss: 108.2434 - val_loss: 95.5723\n",
      "Epoch 2/2\n",
      " - 0s - loss: 100.2920 - val_loss: 92.5472\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 96.9807 - val_loss: 90.0220\n",
      "Epoch 2/2\n",
      " - 0s - loss: 90.2760 - val_loss: 85.2853\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.3730 - val_loss: 81.1250\n",
      "Epoch 2/2\n",
      " - 0s - loss: 82.0685 - val_loss: 75.8346\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 78.5556 - val_loss: 67.5294\n",
      "Epoch 2/2\n",
      " - 0s - loss: 72.8185 - val_loss: 57.0868\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 67.8022 - val_loss: 49.4510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      " - 0s - loss: 75.1877 - val_loss: 46.8333\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 67.1337 - val_loss: 43.8002\n",
      "Epoch 2/2\n",
      " - 0s - loss: 66.7575 - val_loss: 41.3240\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 63.1042 - val_loss: 40.4287\n",
      "Epoch 2/2\n",
      " - 0s - loss: 60.7553 - val_loss: 38.9258\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 64.1796 - val_loss: 39.7052\n",
      "Epoch 2/2\n",
      " - 0s - loss: 56.4800 - val_loss: 39.0668\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 55.7635 - val_loss: 36.2841\n",
      "Epoch 2/2\n",
      " - 0s - loss: 65.7099 - val_loss: 37.0600\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 60.4389 - val_loss: 35.5418\n",
      "Epoch 2/2\n",
      " - 0s - loss: 55.6702 - val_loss: 36.4980\n",
      "MAPE:  84.3524570013151\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 18s - loss: 107.1095 - val_loss: 132.9564\n",
      "Epoch 2/2\n",
      " - 0s - loss: 98.1013 - val_loss: 125.4760\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 93.8701 - val_loss: 131.2404\n",
      "Epoch 2/2\n",
      " - 0s - loss: 91.3137 - val_loss: 135.9363\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 89.3664 - val_loss: 137.6392\n",
      "Epoch 2/2\n",
      " - 0s - loss: 89.8692 - val_loss: 139.5534\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 90.3553 - val_loss: 139.2973\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.7082 - val_loss: 135.2546\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 91.1587 - val_loss: 135.5825\n",
      "Epoch 2/2\n",
      " - 0s - loss: 88.7130 - val_loss: 143.6468\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.0360 - val_loss: 141.8788\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.9787 - val_loss: 141.7163\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.9627 - val_loss: 146.6052\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.5061 - val_loss: 149.0137\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 87.5976 - val_loss: 152.3805\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.2824 - val_loss: 155.4629\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 88.1798 - val_loss: 156.1015\n",
      "Epoch 2/2\n",
      " - 0s - loss: 87.3535 - val_loss: 158.5516\n",
      "Train on 23 samples, validate on 5 samples\n",
      "Epoch 1/2\n",
      " - 0s - loss: 86.6998 - val_loss: 155.8300\n",
      "Epoch 2/2\n",
      " - 0s - loss: 86.2863 - val_loss: 158.4121\n",
      "MAPE:  106.28436627491024\n"
     ]
    }
   ],
   "source": [
    "for batch in keys[0:200]:\n",
    "    \n",
    "    train1, test = train_test_split(LstmDict(lstm_data)[batch], 18)\n",
    "#     decomposition = seasonal_decompose(train1)\n",
    "#     seasonal = decomposition.seasonal\n",
    "#     obs = train1-seasonal\n",
    "\n",
    "#     if test_for_stationarity(obs) > 0.05:\n",
    "\n",
    "#         data_diff = obs.diff().dropna()\n",
    "#         scaler, train = prepare_data(obs, n_lag, n_seq)\n",
    "#         #n_batch_train = train.shape[0]\n",
    "#         model, new_model = fit_lstm(train, n_lag, n_seq, n_batch_pred, nb_epoch, neurons)\n",
    "#         forecasts = make_forecasts(new_model, n_batch_pred, train, n_lag, n_seq)\n",
    "#         forecasts = inverse_transform(forecasts, scaler)\n",
    "#         forecast = forecasts[0].tolist()\n",
    "#         forecast = inverse_difference(obs, forecast)\n",
    "\n",
    "#     else:\n",
    "    scaler, train = prepare_data(train1, n_lag, n_seq)\n",
    "    #n_batch_train = train.shape[0]\n",
    "    model= fit_lstm(train, n_lag, n_seq, n_batch, nb_epoch, neurons)\n",
    "    forecasts = make_forecasts(model, n_batch, train, n_lag, n_seq)\n",
    "    forecasts = inverse_transform(forecasts, scaler)\n",
    "    forecast = forecasts[0].tolist()    \n",
    "    #forecast = np.exp(forecast)\n",
    "    error_mape = []\n",
    "    error_mape = evaluate_forecasts(test, forecast, n_lag, n_seq)\n",
    "    Lstm_errors[batch] = error_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.1376009685043"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(list(Lstm_errors.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N1402', 337.0726170137134),\n",
       " ('N1403', 212.55418930643066),\n",
       " ('N1404', 33.35299416933379),\n",
       " ('N1405', 44.71762810161807),\n",
       " ('N1406', 34.65730671320451),\n",
       " ('N1407', 213.6395243025414),\n",
       " ('N1408', 29.73784230312802),\n",
       " ('N1409', 52.75268274343541),\n",
       " ('N1410', 50.09470086613976),\n",
       " ('N1411', 22.745087401135596),\n",
       " ('N1412', 32.90830938880524),\n",
       " ('N1413', 910.8153966299291),\n",
       " ('N1414', 41.86157766101559),\n",
       " ('N1415', 97.73884498981835),\n",
       " ('N1416', 115.61154561450928),\n",
       " ('N1417', 258.62754046322294),\n",
       " ('N1418', 41.38332111056356),\n",
       " ('N1419', 30.906469014875153),\n",
       " ('N1420', 84.03525788149351),\n",
       " ('N1421', 67.524090664959),\n",
       " ('N1422', 99.9931800543388),\n",
       " ('N1423', 229.27509788172023),\n",
       " ('N1424', 52.836105565552316),\n",
       " ('N1425', 245.0476713132888),\n",
       " ('N1426', 14.41860089709862),\n",
       " ('N1427', 263.8804467735494),\n",
       " ('N1428', 37.08467344328791),\n",
       " ('N1429', 64.41380591393921),\n",
       " ('N1430', 14.083275295290774),\n",
       " ('N1431', 21.87491395694423),\n",
       " ('N1432', 214.9923190516511),\n",
       " ('N1433', 219.4915353012889),\n",
       " ('N1434', 103.6688816566093),\n",
       " ('N1435', 84.9346967002043),\n",
       " ('N1436', 154.4154167444984),\n",
       " ('N1437', 58.10419974298097),\n",
       " ('N1438', 93.94943100028634),\n",
       " ('N1439', 87.94635449683115),\n",
       " ('N1440', 17.922505687892098),\n",
       " ('N1441', 59.69570301855961),\n",
       " ('N1442', 36.39197494214381),\n",
       " ('N1443', 115.38567537912516),\n",
       " ('N1444', 73.7473051456966),\n",
       " ('N1445', 72.2023643401802),\n",
       " ('N1446', 137.56594242966463),\n",
       " ('N1447', 14.857844398917832),\n",
       " ('N1448', 153.16523425976283),\n",
       " ('N1449', 13.419765597385902),\n",
       " ('N1450', 97.54161314664488),\n",
       " ('N1451', 110.68810442384651),\n",
       " ('N1452', 45.755821290894374),\n",
       " ('N1453', 22.997131209617365),\n",
       " ('N1454', 11.618025324782703),\n",
       " ('N1455', 16.960867126537696),\n",
       " ('N1456', 24.28815533392402),\n",
       " ('N1457', 42.03611479164013),\n",
       " ('N1458', 33.68086488315408),\n",
       " ('N1459', 74.9284711615097),\n",
       " ('N1460', 242.4438366534876),\n",
       " ('N1461', 72.81702066915605),\n",
       " ('N1462', 38.460858160769206),\n",
       " ('N1463', 15.58741318835477),\n",
       " ('N1464', 28.46555331522549),\n",
       " ('N1465', 102.63079628120848),\n",
       " ('N1466', 60.69589843676467),\n",
       " ('N1467', 24.18429440215163),\n",
       " ('N1468', 25.18224220424059),\n",
       " ('N1469', 174.91834392226647),\n",
       " ('N1470', 9.96909449036106),\n",
       " ('N1471', 75.58706160851835),\n",
       " ('N1472', 6.8006807172166175),\n",
       " ('N1473', 11.102986828582814),\n",
       " ('N1474', 55.95512836528559),\n",
       " ('N1475', 25.67879013184581),\n",
       " ('N1476', 139.09850500131995),\n",
       " ('N1477', 8.298842238596974),\n",
       " ('N1478', 27.650377226909995),\n",
       " ('N1479', 31.964121114255445),\n",
       " ('N1480', 20.89729162879964),\n",
       " ('N1481', 17.919169076090814),\n",
       " ('N1482', 27.924322355881987),\n",
       " ('N1483', 37.495373542537564),\n",
       " ('N1484', 7.216305504177366),\n",
       " ('N1485', 38.694984790251794),\n",
       " ('N1486', 32.38730052925799),\n",
       " ('N1487', 23.273551770638),\n",
       " ('N1488', 48.002298912670064),\n",
       " ('N1489', 29.117688005804254),\n",
       " ('N1490', 62.373638012447586),\n",
       " ('N1491', 62.42932672806391),\n",
       " ('N1492', 26.070179431061124),\n",
       " ('N1493', 19.495521815040767),\n",
       " ('N1494', 5.8440471616978185),\n",
       " ('N1495', 5.147171705926173),\n",
       " ('N1496', 9.119417910482898),\n",
       " ('N1497', 8.34575826150014),\n",
       " ('N1498', 13.224909099244849),\n",
       " ('N1499', 15.929596562586724),\n",
       " ('N1500', 18.285614234119844),\n",
       " ('N1501', 34.463659039537035),\n",
       " ('N1502', 7.080733804223866),\n",
       " ('N1503', 21.516664813712673),\n",
       " ('N1504', 12.685433285934536),\n",
       " ('N1505', 14.405324546609762),\n",
       " ('N1506', 11.326343853748703),\n",
       " ('N1507', 12.949200196037935),\n",
       " ('N1508', 30.865528328408697),\n",
       " ('N1509', 41.68453238182146),\n",
       " ('N1510', 21.367688014831213),\n",
       " ('N1511', 20.354316408346453),\n",
       " ('N1512', 24.139922371651096),\n",
       " ('N1513', 12.22199827842073),\n",
       " ('N1514', 7.741239527146268),\n",
       " ('N1515', 9.25306074517948),\n",
       " ('N1516', 9.324099659644586),\n",
       " ('N1517', 14.499682386629775),\n",
       " ('N1518', 32.17974632874597),\n",
       " ('N1519', 23.920658214696854),\n",
       " ('N1520', 19.730662872028066),\n",
       " ('N1521', 8.660256795148706),\n",
       " ('N1522', 9.887832773391493),\n",
       " ('N1523', 8.144697737281797),\n",
       " ('N1524', 8.314694566719155),\n",
       " ('N1525', 9.44193869066552),\n",
       " ('N1526', 6.843165485639616),\n",
       " ('N1527', 8.601092872783363),\n",
       " ('N1528', 14.42346179846455),\n",
       " ('N1529', 22.708172780169583),\n",
       " ('N1530', 46.625021161652924),\n",
       " ('N1531', 45.72301396199909),\n",
       " ('N1532', 39.9898964651671),\n",
       " ('N1533', 29.823963603294846),\n",
       " ('N1534', 40.28713165087547),\n",
       " ('N1535', 55.200543341837985),\n",
       " ('N1536', 38.65635219603195),\n",
       " ('N1537', 16.430742567839474),\n",
       " ('N1538', 22.20142792616655),\n",
       " ('N1539', 10.095155525331325),\n",
       " ('N1540', 11.705398059467925),\n",
       " ('N1541', 11.313988178583086),\n",
       " ('N1542', 12.288382271305519),\n",
       " ('N1543', 64.66575236061455),\n",
       " ('N1544', 25.607245830130754),\n",
       " ('N1545', 14.041910888943201),\n",
       " ('N1546', 27.661305755076317),\n",
       " ('N1547', 46.516278242266374),\n",
       " ('N1548', 30.712500048776793),\n",
       " ('N1549', 20.66861597737175),\n",
       " ('N1550', 13.91637438467947),\n",
       " ('N1551', 20.380465324694907),\n",
       " ('N1552', 21.548394322824503),\n",
       " ('N1553', 34.18864040106342),\n",
       " ('N1554', 39.6016514030176),\n",
       " ('N1555', 33.379862188262294),\n",
       " ('N1556', 32.24666649101536),\n",
       " ('N1557', 34.222299467954116),\n",
       " ('N1558', 25.819373488343363),\n",
       " ('N1559', 25.009590422230293),\n",
       " ('N1560', 29.874006947720368),\n",
       " ('N1561', 29.153913889635202),\n",
       " ('N1562', 26.318767178549248),\n",
       " ('N1563', 33.936583656352155),\n",
       " ('N1564', 13.919898452801435),\n",
       " ('N1565', 15.50962580958142),\n",
       " ('N1566', 29.802752196798586),\n",
       " ('N1567', 22.246860236570242),\n",
       " ('N1568', 23.11969588603728),\n",
       " ('N1569', 16.149390177058383),\n",
       " ('N1570', 9.144433560923648),\n",
       " ('N1571', 9.681274138729178),\n",
       " ('N1572', 6.822898433345231),\n",
       " ('N1573', 12.130970714812065),\n",
       " ('N1574', 46.54693048649494),\n",
       " ('N1575', 67.39911583079822),\n",
       " ('N1576', 12.320248160154096),\n",
       " ('N1577', 15.905644782609393),\n",
       " ('N1578', 13.783468327759884),\n",
       " ('N1579', 69.30823514303233),\n",
       " ('N1580', 124.62153009076427),\n",
       " ('N1581', 88.21184404914571),\n",
       " ('N1582', 80.93428176184906),\n",
       " ('N1583', 85.70574085894971),\n",
       " ('N1584', 118.0672906162811),\n",
       " ('N1585', 105.40632688396447),\n",
       " ('N1586', 124.13884963911951),\n",
       " ('N1587', 127.90001872959074),\n",
       " ('N1588', 121.6409671802138),\n",
       " ('N1589', 95.42890029767483),\n",
       " ('N1590', 36.80713681495924),\n",
       " ('N1591', 13.299851369862356),\n",
       " ('N1592', 12.273376524023574),\n",
       " ('N1593', 8.70234933609261),\n",
       " ('N1594', 8.402740400882893),\n",
       " ('N1595', 9.960854781662674),\n",
       " ('N1596', 16.859374898913227),\n",
       " ('N1597', 18.555904019864048),\n",
       " ('N1598', 45.43652141071792),\n",
       " ('N1599', 67.50871626999033),\n",
       " ('N1600', 84.3524570013151),\n",
       " ('N1601', 106.28436627491024)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Lstm_errors.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8079.546875,\n",
       " 8192.46484375,\n",
       " 8162.70361328125,\n",
       " 8305.939453125,\n",
       " 8300.6025390625,\n",
       " 8414.6025390625,\n",
       " 8381.7802734375,\n",
       " 8519.1689453125,\n",
       " 8402.751953125,\n",
       " 8416.6923828125,\n",
       " 8427.1328125,\n",
       " 8319.447265625,\n",
       " 8319.9052734375,\n",
       " 8313.9443359375,\n",
       " 8413.9453125,\n",
       " 8359.4775390625,\n",
       " 8513.5244140625,\n",
       " 8745.685546875]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seasonality(data,n_period,n_seq):\n",
    "    seasonal=data\n",
    "    seasonality_forecast=[]\n",
    "   \n",
    "    if n_period==4:\n",
    "        seasonality_forecast = [None] * 8\n",
    "        for i in range (0,n_seq):\n",
    "            seasonality_forecast[i]= seasonal[i]\n",
    "            \n",
    "    if n_period==12:\n",
    "        seasonality_forecast = [None] * 18\n",
    "        for i in range (0,n_seq):\n",
    "            seasonality_forecast[i]= seasonal[i]\n",
    "            \n",
    "    return seasonality_forecast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcast_seasonal = seasonality(seasonal, 12, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcast = forecast + fcast_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "1979-04-01    8270.056019\n",
       "1979-05-01    8217.793432\n",
       "1979-06-01    8040.921090\n",
       "1979-07-01    7965.847208\n",
       "1979-08-01    7944.631127\n",
       "1979-09-01    8370.435757\n",
       "1979-10-01    8598.706084\n",
       "1979-11-01    8486.752163\n",
       "1979-12-01    8201.460171\n",
       "1980-01-01    8492.298749\n",
       "1980-02-01    8693.294734\n",
       "1980-03-01    8640.636965\n",
       "1980-04-01    8510.414417\n",
       "1980-05-01    8339.272924\n",
       "1980-06-01    8292.162789\n",
       "1980-07-01    8019.385294\n",
       "1980-08-01    8157.553002\n",
       "1980-09-01    8701.518764\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_forecasts(actual, forecast, n_lag, n_seq):\n",
    "\n",
    "   # rmse = np.sqrt(mean_squared_error(actual, forecast))\n",
    "    #print('RMSE: ',rmse)\n",
    "    mape = np.mean(np.abs((np.array(actual) - np.array(forecast)) / np.array(actual) )) * 100\n",
    "    print ('MAPE: ', mape)\n",
    "    return mape\n",
    "#evaluate_forecasts(test, fcast, n_lag, n_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example=pd.DataFrame(example)\n",
    "example['Forecast'] = example['value']\n",
    "for i in range(n_seq):\n",
    "    example['Forecast'][-(n_seq-i)]=fcast[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c5448c51d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(example[['Forecast', 'value']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
